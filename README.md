# Master Thesis for Computer Science degree at University of Genoa

### Abstract:

Deep learning has significantly impacted medical diagnosis, particularly in radiology, where interpreting visual data is central to clinical decision-making. By leveraging deep learning, diagnostic errors can be reduced, decision-making accelerated, and patient outcomes improved. In clinical routine, high-resolution 3D volumetric data from imaging modalities such as magnetic resonance imaging (MRI) and computed tomography (CT) are essential for accurate diagnostics, treatment planning, and precise surgical interventions. However, training deep learning models on full 3D volumes presents considerable challenges compared to 2D images, which are typically used in deep learning applications outside the medical domain. The high computational demands of 3D models, including substantial GPU memory requirements, long training times, and increased energy consumption, make their development and deployment costly. Many hospitals, particularly in resource-limited regions, lack the necessary infrastructure for real-time inference with 3D models, whereas 2D-based approaches can be deployed on standard workstations or even portable devices. This thesis explores a method that combines the spatial representation of 3D models with the efficiency of 2D pre-trained networks. Specifically, we propose Axial-Coronal-Sagittal (ACS) convolutions, which apply 2D convolutional kernels independently along three orthogonal planes, enabling the use of pre-trained 2D weights to capture 3D context. We compare this method to state-of-the-art 3D models and demonstrate comparable or even superior performance while significantly lowering computational costs. This approach reduces training and inference complexity, making deep learning for 3D medical imaging more accessible, particularly in environments with limited computational resources.
