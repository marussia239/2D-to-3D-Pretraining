{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image Classification with MONAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.4.dev2441\n",
      "Numpy version: 1.26.3\n",
      "Pytorch version: 2.2.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: cf815ed4e44a5b8ce67e894ab0bc2765279a1a59\n",
      "MONAI __file__: /mnt/hdd/<username>/.local/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: 0.25.2\n",
      "scipy version: 1.15.2\n",
      "Pillow version: 10.2.0\n",
      "Tensorboard version: 2.19.0\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.17.1\n",
      "tqdm version: 4.67.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 2.2.3\n",
      "einops version: 0.8.1\n",
      "transformers version: 4.49.0\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import time\n",
    "import psutil\n",
    "import shutil\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch, DataLoader, Dataset\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121, resnet, resnet18\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirst,\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirst,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    RandGaussianNoise,\n",
    "    RandAdjustContrast,\n",
    "    ScaleIntensity, \n",
    "    Transform,\n",
    "    ToTensor,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b7956c874942cfb6faeb31fda36f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "kagglehub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/plameneduardo/sarscov2-ctscan-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230M/230M [00:07<00:00, 30.4MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /mnt/hdd/marina/.cache/kagglehub/datasets/plameneduardo/sarscov2-ctscan-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"plameneduardo/sarscov2-ctscan-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getattr expected at least 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: getattr expected at least 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "getattr(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue working with OrganMNIST3d 64x64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /mnt/hdd/marina/.medmnist/organmnist3d_64.npz\n",
      "Using downloaded and verified file: /mnt/hdd/marina/.medmnist/organmnist3d_64.npz\n",
      "Using downloaded and verified file: /mnt/hdd/marina/.medmnist/organmnist3d_64.npz\n"
     ]
    }
   ],
   "source": [
    "data_flag = 'organmnist3d'\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 70\n",
    "BATCH_SIZE = 8\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "# load the data\n",
    "train_dataset = DataClass(split='train', download=download, size=64)\n",
    "val_dataset = DataClass(split='val', download=download, size=64)\n",
    "test_dataset = DataClass(split='test', download=download, size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/mnt/hdd/marina/.medmnist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset OrganMNIST3D of size 64 (organmnist3d_64)\n",
       "    Number of datapoints: 971\n",
       "    Root location: /mnt/hdd/marina/.medmnist\n",
       "    Split: train\n",
       "    Task: multi-class\n",
       "    Number of channels: 1\n",
       "    Meaning of labels: {'0': 'liver', '1': 'kidney-right', '2': 'kidney-left', '3': 'femur-right', '4': 'femur-left', '5': 'bladder', '6': 'heart', '7': 'lung-right', '8': 'lung-left', '9': 'spleen', '10': 'pancreas'}\n",
       "    Number of samples: {'train': 971, 'val': 161, 'test': 610}\n",
       "    Description: The source of the OrganMNIST3D is the same as that of the Organ{A,C,S}MNIST. Instead of 2D images, we directly use the 3D bounding boxes and process the images into 28×28×28 to perform multi-class classification of 11 body organs. The same 115 and 16 CT scans as the Organ{A,C,S}MNIST from the source training set are used as training and validation set, respectively, and the same 70 CT scans as the Organ{A,C,S}MNIST from the source test set are treated as the test set.\n",
       "    License: CC BY 4.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        ScaleIntensity(),\n",
    "        RandGaussianNoise(prob=0.5, mean=0.0, std=0.05),\n",
    "        RandAdjustContrast(gamma=(0.7, 1.3), prob=0.5),\n",
    "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        ToTensor(),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose([\n",
    "    ScaleIntensity(),\n",
    "    ToTensor(),\n",
    "    EnsureType(),\n",
    "])\n",
    "\n",
    "test_transforms = Compose([\n",
    "    ScaleIntensity(),\n",
    "    ToTensor(),\n",
    "    EnsureType(),\n",
    "])\n",
    "\n",
    "y_pred_trans = Compose([Activations(softmax=True)])\n",
    "y_trans = Compose([AsDiscrete(to_onehot=n_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _3D_Dataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.dataset[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return {'images': data, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_ = _3D_Dataset(train_dataset, transform=train_transforms)\n",
    "val_dataset_ = _3D_Dataset(val_dataset, transform=val_transforms)\n",
    "test_dataset_ = _3D_Dataset(test_dataset, transform=test_transforms)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset_, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(pretrained=False, spatial_dims=3, n_input_channels=1, num_classes=n_classes).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.00005)\n",
    "max_epochs = 110\n",
    "val_interval = 1\n",
    "auc_metric = ROCAUCMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
      "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ResNetBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResNetBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResNetBlock(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNetBlock(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResNetBlock(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNetBlock(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResNetBlock(\n",
      "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNetBlock(\n",
      "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.11it/s, train_loss=2.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average loss: 1.5370\n",
      "Saved new best metric model\n",
      "Current epoch: 1 | AUC: 0.9594 | Accuracy: 0.4658 | Best AUC: 0.9594 at epoch: 1\n",
      "----------\n",
      "epoch 2/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.09it/s, train_loss=0.795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 average loss: 1.0144\n",
      "Saved new best metric model\n",
      "Current epoch: 2 | AUC: 0.9766 | Accuracy: 0.6087 | Best AUC: 0.9766 at epoch: 2\n",
      "----------\n",
      "epoch 3/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.16it/s, train_loss=0.714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 average loss: 0.8279\n",
      "Saved new best metric model\n",
      "Current epoch: 3 | AUC: 0.9906 | Accuracy: 0.8261 | Best AUC: 0.9906 at epoch: 3\n",
      "----------\n",
      "epoch 4/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.15it/s, train_loss=1.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 average loss: 0.6839\n",
      "Current epoch: 4 | AUC: 0.9794 | Accuracy: 0.5590 | Best AUC: 0.9906 at epoch: 3\n",
      "----------\n",
      "epoch 5/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.09it/s, train_loss=1.39]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 average loss: 0.5928\n",
      "Current epoch: 5 | AUC: 0.9842 | Accuracy: 0.7143 | Best AUC: 0.9906 at epoch: 3\n",
      "----------\n",
      "epoch 6/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.15it/s, train_loss=0.852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 average loss: 0.5463\n",
      "Saved new best metric model\n",
      "Current epoch: 6 | AUC: 0.9908 | Accuracy: 0.7267 | Best AUC: 0.9908 at epoch: 6\n",
      "----------\n",
      "epoch 7/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.20it/s, train_loss=0.29] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 average loss: 0.5179\n",
      "Saved new best metric model\n",
      "Current epoch: 7 | AUC: 0.9954 | Accuracy: 0.8944 | Best AUC: 0.9954 at epoch: 7\n",
      "----------\n",
      "epoch 8/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.10it/s, train_loss=0.359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 average loss: 0.5101\n",
      "Current epoch: 8 | AUC: 0.9911 | Accuracy: 0.7640 | Best AUC: 0.9954 at epoch: 7\n",
      "----------\n",
      "epoch 9/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.09it/s, train_loss=0.313] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 average loss: 0.4512\n",
      "Saved new best metric model\n",
      "Current epoch: 9 | AUC: 0.9991 | Accuracy: 0.9317 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 10/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.10it/s, train_loss=0.367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 average loss: 0.4090\n",
      "Current epoch: 10 | AUC: 0.9987 | Accuracy: 0.9317 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 11/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.11it/s, train_loss=3.91]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 average loss: 0.4319\n",
      "Current epoch: 11 | AUC: 0.9974 | Accuracy: 0.8758 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 12/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.10it/s, train_loss=0.475] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 average loss: 0.4094\n",
      "Current epoch: 12 | AUC: 0.9958 | Accuracy: 0.8447 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 13/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.06it/s, train_loss=0.892] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 average loss: 0.3545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x7fc493b09630>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1277, in close\n",
      "    if self.last_print_t < self.start_t + self.delay:\n",
      "AttributeError: 'tqdm' object has no attribute 'last_print_t'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x7fc493b09630>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1277, in close\n",
      "    if self.last_print_t < self.start_t + self.delay:\n",
      "AttributeError: 'tqdm' object has no attribute 'last_print_t'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x7fc493b09630>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1277, in close\n",
      "    if self.last_print_t < self.start_t + self.delay:\n",
      "AttributeError: 'tqdm' object has no attribute 'last_print_t'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x7fc493b09630>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1277, in close\n",
      "    if self.last_print_t < self.start_t + self.delay:\n",
      "AttributeError: 'tqdm' object has no attribute 'last_print_t'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x7fc493b09630>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1277, in close\n",
      "    if self.last_print_t < self.start_t + self.delay:\n",
      "AttributeError: 'tqdm' object has no attribute 'last_print_t'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 13 | AUC: 0.9979 | Accuracy: 0.9130 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 14/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.11it/s, train_loss=2.55]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 average loss: 0.3550\n",
      "Current epoch: 14 | AUC: 0.9969 | Accuracy: 0.8199 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 15/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.04it/s, train_loss=0.379] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 average loss: 0.3306\n",
      "Current epoch: 15 | AUC: 0.9973 | Accuracy: 0.8944 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 16/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.06it/s, train_loss=0.0307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 average loss: 0.2969\n",
      "Current epoch: 16 | AUC: 0.9957 | Accuracy: 0.9193 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 17/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.99it/s, train_loss=0.0548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 average loss: 0.3214\n",
      "Current epoch: 17 | AUC: 0.9881 | Accuracy: 0.8012 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 18/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.06it/s, train_loss=0.697] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 average loss: 0.2893\n",
      "Current epoch: 18 | AUC: 0.9925 | Accuracy: 0.8509 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 19/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.03it/s, train_loss=1.62]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 average loss: 0.2544\n",
      "Current epoch: 19 | AUC: 0.9919 | Accuracy: 0.8385 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 20/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.98it/s, train_loss=0.501] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 average loss: 0.2588\n",
      "Current epoch: 20 | AUC: 0.9971 | Accuracy: 0.9130 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 21/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.98it/s, train_loss=0.596] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 average loss: 0.2512\n",
      "Current epoch: 21 | AUC: 0.9924 | Accuracy: 0.9068 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 22/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.03it/s, train_loss=0.0174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 average loss: 0.2408\n",
      "Current epoch: 22 | AUC: 0.9950 | Accuracy: 0.9441 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 23/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.05it/s, train_loss=0.163] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 average loss: 0.2113\n",
      "Current epoch: 23 | AUC: 0.9931 | Accuracy: 0.9130 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 24/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.02it/s, train_loss=0.489] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 average loss: 0.2084\n",
      "Current epoch: 24 | AUC: 0.9912 | Accuracy: 0.8696 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 25/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.98it/s, train_loss=0.134] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 average loss: 0.2271\n",
      "Current epoch: 25 | AUC: 0.9967 | Accuracy: 0.8944 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 26/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.96it/s, train_loss=1.17]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 average loss: 0.2030\n",
      "Current epoch: 26 | AUC: 0.9987 | Accuracy: 0.8758 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 27/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.04it/s, train_loss=0.0181] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 average loss: 0.2310\n",
      "Current epoch: 27 | AUC: 0.9865 | Accuracy: 0.8571 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 28/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.04it/s, train_loss=0.59]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 average loss: 0.1628\n",
      "Current epoch: 28 | AUC: 0.9850 | Accuracy: 0.8571 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 29/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.07it/s, train_loss=0.195]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 average loss: 0.1635\n",
      "Current epoch: 29 | AUC: 0.9964 | Accuracy: 0.9130 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 30/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.00it/s, train_loss=0.501]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 average loss: 0.1449\n",
      "Current epoch: 30 | AUC: 0.9925 | Accuracy: 0.8509 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 31/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.02it/s, train_loss=0.968]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 average loss: 0.1660\n",
      "Current epoch: 31 | AUC: 0.9905 | Accuracy: 0.9068 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 32/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.03it/s, train_loss=0.0683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 average loss: 0.1575\n",
      "Current epoch: 32 | AUC: 0.9915 | Accuracy: 0.9255 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 33/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.00it/s, train_loss=0.0239] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 average loss: 0.1319\n",
      "Current epoch: 33 | AUC: 0.9966 | Accuracy: 0.9006 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 34/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.02it/s, train_loss=0.29]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 average loss: 0.1242\n",
      "Current epoch: 34 | AUC: 0.9959 | Accuracy: 0.9068 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 35/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.02it/s, train_loss=0.12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 average loss: 0.1244\n",
      "Current epoch: 35 | AUC: 0.9854 | Accuracy: 0.8696 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 36/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.08it/s, train_loss=0.0832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 average loss: 0.1190\n",
      "Current epoch: 36 | AUC: 0.9822 | Accuracy: 0.8447 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 37/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.00it/s, train_loss=1.34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 average loss: 0.1537\n",
      "Current epoch: 37 | AUC: 0.9930 | Accuracy: 0.9006 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 38/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.01it/s, train_loss=0.0861] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 average loss: 0.1109\n",
      "Current epoch: 38 | AUC: 0.9902 | Accuracy: 0.8758 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 39/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.00it/s, train_loss=0.00485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 average loss: 0.1045\n",
      "Current epoch: 39 | AUC: 0.9852 | Accuracy: 0.8261 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 40/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.98it/s, train_loss=0.0884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 average loss: 0.1120\n",
      "Current epoch: 40 | AUC: 0.9809 | Accuracy: 0.8571 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 41/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.07it/s, train_loss=0.0845] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 average loss: 0.1100\n",
      "Current epoch: 41 | AUC: 0.9951 | Accuracy: 0.9130 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 42/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.05it/s, train_loss=0.029]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 average loss: 0.0981\n",
      "Current epoch: 42 | AUC: 0.9970 | Accuracy: 0.9130 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 43/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.06it/s, train_loss=0.145]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 average loss: 0.0680\n",
      "Current epoch: 43 | AUC: 0.9900 | Accuracy: 0.8696 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 44/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.01it/s, train_loss=1.2]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 average loss: 0.0977\n",
      "Current epoch: 44 | AUC: 0.9927 | Accuracy: 0.9130 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 45/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.01it/s, train_loss=1.62]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 average loss: 0.1480\n",
      "Current epoch: 45 | AUC: 0.9896 | Accuracy: 0.8758 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 46/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.99it/s, train_loss=0.176]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 average loss: 0.1215\n",
      "Current epoch: 46 | AUC: 0.9932 | Accuracy: 0.8447 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 47/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.01it/s, train_loss=0.029]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 average loss: 0.0994\n",
      "Current epoch: 47 | AUC: 0.9912 | Accuracy: 0.8758 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 48/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.01it/s, train_loss=2.69]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 average loss: 0.1149\n",
      "Current epoch: 48 | AUC: 0.9937 | Accuracy: 0.9006 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 49/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.04it/s, train_loss=0.0291] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 average loss: 0.0887\n",
      "Current epoch: 49 | AUC: 0.9894 | Accuracy: 0.8882 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 50/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.03it/s, train_loss=1.24]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 average loss: 0.0986\n",
      "Current epoch: 50 | AUC: 0.9919 | Accuracy: 0.9193 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 51/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.97it/s, train_loss=0.0142] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 average loss: 0.0505\n",
      "Current epoch: 51 | AUC: 0.9972 | Accuracy: 0.9565 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 52/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.02it/s, train_loss=0.00494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 average loss: 0.0494\n",
      "Current epoch: 52 | AUC: 0.9942 | Accuracy: 0.9193 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 53/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.04it/s, train_loss=0.315]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 average loss: 0.0725\n",
      "Current epoch: 53 | AUC: 0.9937 | Accuracy: 0.9130 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 54/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.01it/s, train_loss=0.0289] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 average loss: 0.0526\n",
      "Current epoch: 54 | AUC: 0.9938 | Accuracy: 0.9006 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 55/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.01it/s, train_loss=0.0531] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 average loss: 0.0429\n",
      "Current epoch: 55 | AUC: 0.9985 | Accuracy: 0.9627 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 56/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.01it/s, train_loss=0.00391] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 average loss: 0.0407\n",
      "Current epoch: 56 | AUC: 0.9976 | Accuracy: 0.9255 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 57/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.96it/s, train_loss=0.0292] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 average loss: 0.0482\n",
      "Current epoch: 57 | AUC: 0.9990 | Accuracy: 0.9565 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 58/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.09it/s, train_loss=0.263]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 average loss: 0.0522\n",
      "Current epoch: 58 | AUC: 0.9783 | Accuracy: 0.8634 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 59/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.01it/s, train_loss=0.019]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 average loss: 0.0777\n",
      "Current epoch: 59 | AUC: 0.9918 | Accuracy: 0.8944 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 60/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.00it/s, train_loss=0.191]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 average loss: 0.0625\n",
      "Current epoch: 60 | AUC: 0.9986 | Accuracy: 0.9627 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 61/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.04it/s, train_loss=0.0671] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 average loss: 0.0721\n",
      "Current epoch: 61 | AUC: 0.9989 | Accuracy: 0.9565 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 62/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.03it/s, train_loss=0.00425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 average loss: 0.0563\n",
      "Current epoch: 62 | AUC: 0.9934 | Accuracy: 0.8944 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 63/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.99it/s, train_loss=0.0679] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 average loss: 0.0810\n",
      "Current epoch: 63 | AUC: 0.9983 | Accuracy: 0.9317 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 64/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.03it/s, train_loss=0.0391] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 average loss: 0.0728\n",
      "Current epoch: 64 | AUC: 0.9939 | Accuracy: 0.9006 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 65/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.05it/s, train_loss=0.168]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 average loss: 0.0548\n",
      "Current epoch: 65 | AUC: 0.9942 | Accuracy: 0.9130 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 66/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.96it/s, train_loss=0.00784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 average loss: 0.0397\n",
      "Current epoch: 66 | AUC: 0.9966 | Accuracy: 0.9317 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 67/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.05it/s, train_loss=0.688]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 average loss: 0.0385\n",
      "Current epoch: 67 | AUC: 0.9945 | Accuracy: 0.9193 | Best AUC: 0.9991 at epoch: 9\n",
      "----------\n",
      "epoch 68/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.06it/s, train_loss=0.00338] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 average loss: 0.0803\n",
      "Saved new best metric model\n",
      "Current epoch: 68 | AUC: 0.9994 | Accuracy: 0.9379 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 69/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.05it/s, train_loss=0.244]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 average loss: 0.0443\n",
      "Current epoch: 69 | AUC: 0.9978 | Accuracy: 0.9441 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 70/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.03it/s, train_loss=0.0435]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 average loss: 0.0464\n",
      "Current epoch: 70 | AUC: 0.9988 | Accuracy: 0.9689 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 71/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.06it/s, train_loss=0.00217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 average loss: 0.0526\n",
      "Current epoch: 71 | AUC: 0.9914 | Accuracy: 0.9068 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 72/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.02it/s, train_loss=0.055]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 average loss: 0.0688\n",
      "Current epoch: 72 | AUC: 0.9966 | Accuracy: 0.9379 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 73/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.05it/s, train_loss=0.0173] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 average loss: 0.0341\n",
      "Current epoch: 73 | AUC: 0.9913 | Accuracy: 0.8944 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 74/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.98it/s, train_loss=0.364]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 average loss: 0.0529\n",
      "Current epoch: 74 | AUC: 0.9935 | Accuracy: 0.8820 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 75/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.01it/s, train_loss=0.0104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 average loss: 0.0752\n",
      "Current epoch: 75 | AUC: 0.9939 | Accuracy: 0.9068 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 76/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.94it/s, train_loss=0.012]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 average loss: 0.0579\n",
      "Current epoch: 76 | AUC: 0.9949 | Accuracy: 0.9255 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 77/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.04it/s, train_loss=1.19]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 average loss: 0.0619\n",
      "Current epoch: 77 | AUC: 0.9913 | Accuracy: 0.8944 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 78/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.02it/s, train_loss=0.00288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 average loss: 0.0503\n",
      "Current epoch: 78 | AUC: 0.9965 | Accuracy: 0.9565 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 79/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.04it/s, train_loss=0.00469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 average loss: 0.0525\n",
      "Current epoch: 79 | AUC: 0.9965 | Accuracy: 0.9130 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 80/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:23<00:00,  5.12it/s, train_loss=0.0297]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 average loss: 0.0248\n",
      "Current epoch: 80 | AUC: 0.9954 | Accuracy: 0.9317 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 81/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.98it/s, train_loss=0.00273] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 average loss: 0.0457\n",
      "Current epoch: 81 | AUC: 0.9943 | Accuracy: 0.9193 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 82/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.93it/s, train_loss=0.065]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 average loss: 0.0258\n",
      "Current epoch: 82 | AUC: 0.9989 | Accuracy: 0.9627 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 83/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.03it/s, train_loss=0.00317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 average loss: 0.0342\n",
      "Current epoch: 83 | AUC: 0.9944 | Accuracy: 0.9130 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 84/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.95it/s, train_loss=0.0211] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 average loss: 0.0415\n",
      "Current epoch: 84 | AUC: 0.9937 | Accuracy: 0.9255 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 85/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.06it/s, train_loss=0.993]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 average loss: 0.0569\n",
      "Current epoch: 85 | AUC: 0.9974 | Accuracy: 0.9441 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 86/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.06it/s, train_loss=0.0104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 average loss: 0.0434\n",
      "Current epoch: 86 | AUC: 0.9969 | Accuracy: 0.9565 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 87/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.03it/s, train_loss=0.0132]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 average loss: 0.0301\n",
      "Current epoch: 87 | AUC: 0.9947 | Accuracy: 0.8944 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 88/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.02it/s, train_loss=0.0172]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 average loss: 0.0149\n",
      "Current epoch: 88 | AUC: 0.9945 | Accuracy: 0.9317 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 89/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.07it/s, train_loss=0.0758] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 average loss: 0.0339\n",
      "Current epoch: 89 | AUC: 0.9946 | Accuracy: 0.9193 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 90/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.07it/s, train_loss=0.00354] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 average loss: 0.0522\n",
      "Current epoch: 90 | AUC: 0.9976 | Accuracy: 0.9379 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 91/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.98it/s, train_loss=0.00403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 average loss: 0.0396\n",
      "Current epoch: 91 | AUC: 0.9958 | Accuracy: 0.9379 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 92/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.07it/s, train_loss=0.0163]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 average loss: 0.0139\n",
      "Current epoch: 92 | AUC: 0.9952 | Accuracy: 0.9441 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 93/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.04it/s, train_loss=0.174]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 average loss: 0.0243\n",
      "Current epoch: 93 | AUC: 0.9969 | Accuracy: 0.9565 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 94/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.99it/s, train_loss=0.0146]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 average loss: 0.0500\n",
      "Current epoch: 94 | AUC: 0.9973 | Accuracy: 0.9317 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 95/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.03it/s, train_loss=0.515]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 average loss: 0.0546\n",
      "Current epoch: 95 | AUC: 0.9976 | Accuracy: 0.9503 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 96/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.08it/s, train_loss=0.0036] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 average loss: 0.0902\n",
      "Current epoch: 96 | AUC: 0.9949 | Accuracy: 0.9130 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 97/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.98it/s, train_loss=0.0052]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 average loss: 0.0319\n",
      "Current epoch: 97 | AUC: 0.9951 | Accuracy: 0.9193 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 98/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.00it/s, train_loss=0.495]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 average loss: 0.0378\n",
      "Current epoch: 98 | AUC: 0.9943 | Accuracy: 0.9193 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 99/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.01it/s, train_loss=0.254]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 average loss: 0.0428\n",
      "Current epoch: 99 | AUC: 0.9973 | Accuracy: 0.9379 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 100/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.98it/s, train_loss=0.258]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 average loss: 0.0269\n",
      "Current epoch: 100 | AUC: 0.9970 | Accuracy: 0.9503 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 101/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.05it/s, train_loss=0.0301] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 average loss: 0.0276\n",
      "Current epoch: 101 | AUC: 0.9924 | Accuracy: 0.9193 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 102/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.96it/s, train_loss=0.00413] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 average loss: 0.0278\n",
      "Current epoch: 102 | AUC: 0.9979 | Accuracy: 0.9689 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 103/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.93it/s, train_loss=0.000816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 average loss: 0.0297\n",
      "Current epoch: 103 | AUC: 0.9973 | Accuracy: 0.9503 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 104/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.02it/s, train_loss=0.00238] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 average loss: 0.0340\n",
      "Current epoch: 104 | AUC: 0.9944 | Accuracy: 0.9317 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 105/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  4.96it/s, train_loss=0.0352] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 average loss: 0.0453\n",
      "Current epoch: 105 | AUC: 0.9930 | Accuracy: 0.9193 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 106/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.02it/s, train_loss=0.0862]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 average loss: 0.0200\n",
      "Current epoch: 106 | AUC: 0.9969 | Accuracy: 0.9565 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 107/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.04it/s, train_loss=0.000891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 average loss: 0.0303\n",
      "Current epoch: 107 | AUC: 0.9954 | Accuracy: 0.9255 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 108/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.04it/s, train_loss=1.22]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 average loss: 0.0449\n",
      "Current epoch: 108 | AUC: 0.9920 | Accuracy: 0.9193 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 109/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.08it/s, train_loss=0.179]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 average loss: 0.0665\n",
      "Current epoch: 109 | AUC: 0.9956 | Accuracy: 0.9317 | Best AUC: 0.9994 at epoch: 68\n",
      "----------\n",
      "epoch 110/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|##########| 122/122 [00:24<00:00,  5.05it/s, train_loss=0.00302] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 average loss: 0.0257\n",
      "Current epoch: 110 | AUC: 0.9930 | Accuracy: 0.9006 | Best AUC: 0.9994 at epoch: 68\n",
      "Train completed, best_metric: 0.9994 at epoch: 68\n"
     ]
    }
   ],
   "source": [
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "writer = SummaryWriter()\n",
    "\n",
    "start_time = time.time()\n",
    "process = psutil.Process()\n",
    "start_cpu = process.cpu_times()\n",
    "start_mem = process.memory_info().rss / 1024**2  # В MB\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    batch_iter = tqdm(train_loader, desc=\"Training Batches\", leave=True, dynamic_ncols=True, ascii=True)\n",
    "    \n",
    "    for batch_data in batch_iter:\n",
    "        step += 1\n",
    "        images, labels = batch_data['images'].to(device), batch_data['label'][:, 0].type(torch.LongTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_dataset) // train_loader.batch_size\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "        batch_iter.set_postfix(train_loss=loss.item())\n",
    "        \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    tqdm.write(f\"Epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "            y = torch.tensor([], dtype=torch.long, device=device)\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = (\n",
    "                    val_data['images'].to(device),\n",
    "                    val_data['label'][:, 0].type(torch.LongTensor).to(device),\n",
    "                )\n",
    "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
    "                y = torch.cat([y, val_labels], dim=0)\n",
    "            y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
    "            y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
    "            auc_metric(y_pred_act, y_onehot)\n",
    "            result = auc_metric.aggregate()\n",
    "            auc_metric.reset()\n",
    "            del y_pred_act, y_onehot\n",
    "            metric_values.append(result)\n",
    "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
    "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
    "            if result > best_metric:\n",
    "                best_metric = result\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model_3d.pth\"))\n",
    "                tqdm.write(\"Saved new best metric model\")\n",
    "            tqdm.write(\n",
    "                f\"Current epoch: {epoch + 1} | AUC: {result:.4f} | \"\n",
    "                f\"Accuracy: {acc_metric:.4f} | Best AUC: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "            writer.add_scalar(\"val_accuracy\", acc_metric, epoch + 1)\n",
    "\n",
    "tqdm.write(f\"Train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 2742.62 seconds\n",
      "CPU time used: 32788.54 seconds\n",
      "Memory used: 543.55 MB\n",
      "GPU Memory Used: 787.14 MB\n",
      "Max GPU Memory Used: 4506.43 MB\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "end_cpu = process.cpu_times()\n",
    "end_mem = process.memory_info().rss / 1024**2\n",
    "\n",
    "cpu_time = (end_cpu.user + end_cpu.system) - (start_cpu.user + start_cpu.system)\n",
    "memory_used = end_mem - start_mem\n",
    "\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"CPU time used: {cpu_time:.2f} seconds\")\n",
    "print(f\"Memory used: {memory_used:.2f} MB\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    print(f\"GPU Memory Used: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"Max GPU Memory Used: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val AUC\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRAM currently used: 787.14 MB\n",
      "Max VRAM used during training: 4506.43 MB\n"
     ]
    }
   ],
   "source": [
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    vram_used = torch.cuda.memory_allocated() / 1024**2\n",
    "    vram_max_used = torch.cuda.max_memory_allocated() / 1024**2\n",
    "\n",
    "    print(f\"VRAM currently used: {vram_used:.2f} MB\")\n",
    "    print(f\"Max VRAM used during training: {vram_max_used:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.9792\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model_3d.pth\"), weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_predicted = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "    y = torch.tensor([], dtype=torch.long, device=device)\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data['images'],\n",
    "            test_data['label'][:, 0].type(torch.LongTensor),\n",
    "        )\n",
    "\n",
    "        output = model(test_images.to(device))\n",
    "        pred = output.argmax(dim=1)\n",
    "        \n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_predicted.append(pred[i].item())\n",
    "\n",
    "        y_pred = torch.cat([y_pred, output], dim=0)\n",
    "        y = torch.cat([y, test_labels.to(device)], dim=0)\n",
    "\n",
    "    # Evaluate AUC and accuracy\n",
    "    y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
    "    y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
    "    auc_metric(y_pred_act, y_onehot)\n",
    "    result = auc_metric.aggregate()\n",
    "    auc_metric.reset()\n",
    "\n",
    "    print(f\"Validation AUC: {result:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9718    1.0000    0.9857        69\n",
      "           1     0.7231    0.6912    0.7068        68\n",
      "           2     0.6341    0.7536    0.6887        69\n",
      "           3     0.5521    0.8154    0.6584        65\n",
      "           4     0.7027    0.4000    0.5098        65\n",
      "           5     0.9844    0.9545    0.9692        66\n",
      "           6     1.0000    0.8929    0.9434        28\n",
      "           7     1.0000    1.0000    1.0000        21\n",
      "           8     1.0000    1.0000    1.0000        21\n",
      "           9     1.0000    0.8841    0.9385        69\n",
      "          10     0.9851    0.9565    0.9706        69\n",
      "\n",
      "    accuracy                         0.8262       610\n",
      "   macro avg     0.8685    0.8498    0.8519       610\n",
      "weighted avg     0.8418    0.8262    0.8256       610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_predicted, target_names=info['label'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRAM currently used: 563.02 MB\n",
      "Max VRAM used during training: 12850.32 MB\n"
     ]
    }
   ],
   "source": [
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    vram_used = torch.cuda.memory_allocated() / 1024**2\n",
    "    vram_max_used = torch.cuda.max_memory_allocated() / 1024**2\n",
    "\n",
    "    print(f\"VRAM currently used: {vram_used:.2f} MB\")\n",
    "    print(f\"Max VRAM used during training: {vram_max_used:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(pretrained=True, spatial_dims=3, n_input_channels=1, \n",
    "                 feed_forward=False, shortcut_type='A', bias_downsample=True).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.00005)\n",
    "max_epochs = 110\n",
    "val_interval = 1\n",
    "auc_metric = ROCAUCMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
      "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ResNetBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResNetBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResNetBlock(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResNetBlock(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResNetBlock(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResNetBlock(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResNetBlock(\n",
      "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResNetBlock(\n",
      "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.avgpool = nn.Sequential(\n",
    "    model.avgpool,\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512, n_classes)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/110 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:01<?, ?it/s, train_loss=2.5]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:01<03:24,  1.69s/it, train_loss=2.5]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:01<03:24,  1.69s/it, train_loss=3.06]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:01<01:38,  1.21it/s, train_loss=3.06]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:02<01:38,  1.21it/s, train_loss=2.3] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:02<01:04,  1.84it/s, train_loss=2.3]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:02<01:04,  1.84it/s, train_loss=2.72]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:02<00:47,  2.49it/s, train_loss=2.72]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:02<00:47,  2.49it/s, train_loss=2.53]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:02<00:37,  3.12it/s, train_loss=2.53]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:02<00:37,  3.12it/s, train_loss=2.39]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:02<00:32,  3.54it/s, train_loss=2.39]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:02<00:32,  3.54it/s, train_loss=2.27]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:02<00:30,  3.83it/s, train_loss=2.27]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:03<00:30,  3.83it/s, train_loss=2.21]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:03<00:28,  4.07it/s, train_loss=2.21]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:03<00:28,  4.07it/s, train_loss=2.06]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:03<00:25,  4.37it/s, train_loss=2.06]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:03<00:25,  4.37it/s, train_loss=2.1] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:03<00:23,  4.68it/s, train_loss=2.1]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:03<00:23,  4.68it/s, train_loss=2.43]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:03<00:23,  4.73it/s, train_loss=2.43]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:03<00:23,  4.73it/s, train_loss=2.53]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:03<00:22,  4.85it/s, train_loss=2.53]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:04<00:22,  4.85it/s, train_loss=2.2] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:04<00:21,  5.08it/s, train_loss=2.2]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:04<00:21,  5.08it/s, train_loss=2.41]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:04<00:20,  5.23it/s, train_loss=2.41]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:04<00:20,  5.23it/s, train_loss=2.65]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:04<00:20,  5.31it/s, train_loss=2.65]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:04<00:20,  5.31it/s, train_loss=2.13]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:04<00:20,  5.28it/s, train_loss=2.13]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:04<00:20,  5.28it/s, train_loss=2.05]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:04<00:19,  5.38it/s, train_loss=2.05]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:04<00:19,  5.38it/s, train_loss=1.83]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:04<00:18,  5.48it/s, train_loss=1.83]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:05<00:18,  5.48it/s, train_loss=2.62]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:05<00:19,  5.35it/s, train_loss=2.62]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:05<00:19,  5.35it/s, train_loss=2.38]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:05<00:18,  5.45it/s, train_loss=2.38]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:05<00:18,  5.45it/s, train_loss=2.36]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:05<00:18,  5.35it/s, train_loss=2.36]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:05<00:18,  5.35it/s, train_loss=2.37]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:05<00:18,  5.40it/s, train_loss=2.37]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:05<00:18,  5.40it/s, train_loss=2.22]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:05<00:18,  5.21it/s, train_loss=2.22]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:06<00:18,  5.21it/s, train_loss=2.43]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:06<00:18,  5.34it/s, train_loss=2.43]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:06<00:18,  5.34it/s, train_loss=2.39]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:06<00:17,  5.40it/s, train_loss=2.39]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:06<00:17,  5.40it/s, train_loss=2.36]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:06<00:18,  5.30it/s, train_loss=2.36]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:06<00:18,  5.30it/s, train_loss=1.95]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:06<00:16,  5.84it/s, train_loss=1.95]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:06<00:16,  5.84it/s, train_loss=2.86]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:06<00:16,  5.70it/s, train_loss=2.86]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:06<00:16,  5.70it/s, train_loss=2.14]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:17,  5.46it/s, train_loss=2.14]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:07<00:17,  5.46it/s, train_loss=1.88]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:07<00:17,  5.39it/s, train_loss=1.88]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:07<00:17,  5.39it/s, train_loss=2.12]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:07<00:17,  5.08it/s, train_loss=2.12]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:07<00:17,  5.08it/s, train_loss=2.34]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:07<00:17,  5.11it/s, train_loss=2.34]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:07<00:17,  5.11it/s, train_loss=2.36]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:07<00:17,  5.08it/s, train_loss=2.36]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:07<00:17,  5.08it/s, train_loss=2.19]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  5.13it/s, train_loss=2.19]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:08<00:17,  5.13it/s, train_loss=1.88]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:08<00:17,  4.90it/s, train_loss=1.88]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:08<00:17,  4.90it/s, train_loss=2.07]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:08<00:17,  5.02it/s, train_loss=2.07]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:08<00:17,  5.02it/s, train_loss=1.96]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:08<00:16,  5.03it/s, train_loss=1.96]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:08<00:16,  5.03it/s, train_loss=2.17]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:08<00:17,  4.92it/s, train_loss=2.17]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:09<00:17,  4.92it/s, train_loss=1.94]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:09<00:16,  5.04it/s, train_loss=1.94]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:09<00:16,  5.04it/s, train_loss=2.39]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:09<00:15,  5.27it/s, train_loss=2.39]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:09<00:15,  5.27it/s, train_loss=1.97]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:09<00:15,  5.22it/s, train_loss=1.97]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:09<00:15,  5.22it/s, train_loss=1.99]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:09<00:15,  5.20it/s, train_loss=1.99]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:09<00:15,  5.20it/s, train_loss=2.02]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:09<00:14,  5.30it/s, train_loss=2.02]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:09<00:14,  5.30it/s, train_loss=1.8] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:14,  5.25it/s, train_loss=1.8]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:10<00:14,  5.25it/s, train_loss=2.04]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:10<00:14,  5.21it/s, train_loss=2.04]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:10<00:14,  5.21it/s, train_loss=1.59]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:10<00:14,  5.20it/s, train_loss=1.59]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:10<00:14,  5.20it/s, train_loss=1.84]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:10<00:14,  5.10it/s, train_loss=1.84]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:10<00:14,  5.10it/s, train_loss=1.72]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:10<00:14,  4.99it/s, train_loss=1.72]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:10<00:14,  4.99it/s, train_loss=2.88]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  4.98it/s, train_loss=2.88]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:11<00:14,  4.98it/s, train_loss=1.87]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:11<00:14,  5.00it/s, train_loss=1.87]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:11<00:14,  5.00it/s, train_loss=2.08]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:11<00:14,  5.02it/s, train_loss=2.08]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:11<00:14,  5.02it/s, train_loss=2.13]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:11<00:14,  4.95it/s, train_loss=2.13]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:11<00:14,  4.95it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:11<00:14,  4.77it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:11<00:14,  4.77it/s, train_loss=2.11]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  4.93it/s, train_loss=2.11]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:12<00:13,  4.93it/s, train_loss=2.73]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:12<00:13,  4.93it/s, train_loss=2.73]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:12<00:13,  4.93it/s, train_loss=2.63]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:12<00:13,  4.80it/s, train_loss=2.63]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:12<00:13,  4.80it/s, train_loss=1.64]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:12<00:12,  5.01it/s, train_loss=1.64]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:12<00:12,  5.01it/s, train_loss=2]   \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:12<00:12,  5.26it/s, train_loss=2]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:12<00:12,  5.26it/s, train_loss=1.92]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  5.18it/s, train_loss=1.92]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:13<00:12,  5.18it/s, train_loss=1.68]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:13<00:12,  5.08it/s, train_loss=1.68]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:13<00:12,  5.08it/s, train_loss=2.15]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:13<00:11,  5.34it/s, train_loss=2.15]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:13<00:11,  5.34it/s, train_loss=1.54]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:13<00:11,  5.15it/s, train_loss=1.54]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:13<00:11,  5.15it/s, train_loss=1.7] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:13<00:11,  5.17it/s, train_loss=1.7]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:13<00:11,  5.17it/s, train_loss=1.68]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  5.19it/s, train_loss=1.68]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:14<00:11,  5.19it/s, train_loss=2.2] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:14<00:11,  5.13it/s, train_loss=2.2]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:14<00:11,  5.13it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:14<00:10,  5.27it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:14<00:10,  5.27it/s, train_loss=1.7] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:14<00:10,  5.04it/s, train_loss=1.7]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:14<00:10,  5.04it/s, train_loss=1.98]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:14<00:10,  5.12it/s, train_loss=1.98]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:14<00:10,  5.12it/s, train_loss=2.24]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  5.26it/s, train_loss=2.24]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:15<00:10,  5.26it/s, train_loss=2.03]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:15<00:10,  5.13it/s, train_loss=2.03]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:15<00:10,  5.13it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:15<00:10,  5.04it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:15<00:10,  5.04it/s, train_loss=1.55]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:15<00:09,  5.32it/s, train_loss=1.55]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:15<00:09,  5.32it/s, train_loss=2.6] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:15<00:09,  5.21it/s, train_loss=2.6]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:15<00:09,  5.21it/s, train_loss=1.96]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  5.05it/s, train_loss=1.96]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:16<00:09,  5.05it/s, train_loss=1.59]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:16<00:09,  5.06it/s, train_loss=1.59]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:16<00:09,  5.06it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:16<00:09,  4.99it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:16<00:09,  4.99it/s, train_loss=2.11]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:16<00:08,  5.26it/s, train_loss=2.11]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:16<00:08,  5.26it/s, train_loss=1.53]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:16<00:08,  5.15it/s, train_loss=1.53]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:16<00:08,  5.15it/s, train_loss=1.88]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:08,  5.10it/s, train_loss=1.88]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:17<00:08,  5.10it/s, train_loss=1.56]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:17<00:08,  5.16it/s, train_loss=1.56]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:17<00:08,  5.16it/s, train_loss=1.98]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:17<00:07,  5.15it/s, train_loss=1.98]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:17<00:07,  5.15it/s, train_loss=1.75]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:17<00:07,  5.21it/s, train_loss=1.75]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:17<00:07,  5.21it/s, train_loss=1.72]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:17<00:07,  5.13it/s, train_loss=1.72]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:17<00:07,  5.13it/s, train_loss=2.03]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  5.21it/s, train_loss=2.03]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  5.21it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.01it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:18<00:07,  5.01it/s, train_loss=2.2] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:18<00:07,  4.97it/s, train_loss=2.2]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:18<00:07,  4.97it/s, train_loss=2.06]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:18<00:07,  4.96it/s, train_loss=2.06]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:18<00:07,  4.96it/s, train_loss=1.76]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:18<00:06,  5.01it/s, train_loss=1.76]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:18<00:06,  5.01it/s, train_loss=2.56]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  5.03it/s, train_loss=2.56]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  5.03it/s, train_loss=1.68]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.10it/s, train_loss=1.68]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:19<00:06,  5.10it/s, train_loss=1.88]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:19<00:06,  5.05it/s, train_loss=1.88]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:19<00:06,  5.05it/s, train_loss=2.2] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:19<00:05,  5.11it/s, train_loss=2.2]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:19<00:05,  5.11it/s, train_loss=1.3]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:19<00:05,  5.11it/s, train_loss=1.3]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:19<00:05,  5.11it/s, train_loss=1.55]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  5.26it/s, train_loss=1.55]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  5.26it/s, train_loss=2.21]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:04,  5.51it/s, train_loss=2.21]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:20<00:04,  5.51it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:20<00:04,  5.46it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:20<00:04,  5.46it/s, train_loss=1.64]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:20<00:04,  5.49it/s, train_loss=1.64]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:20<00:04,  5.49it/s, train_loss=2.24]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:20<00:04,  5.39it/s, train_loss=2.24]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:20<00:04,  5.39it/s, train_loss=1.89]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:20<00:04,  5.41it/s, train_loss=1.89]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:20<00:04,  5.41it/s, train_loss=1.54]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.50it/s, train_loss=1.54]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:21<00:04,  5.50it/s, train_loss=2.25]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:21<00:03,  5.33it/s, train_loss=2.25]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:21<00:03,  5.33it/s, train_loss=1.81]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:21<00:03,  5.07it/s, train_loss=1.81]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:21<00:03,  5.07it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:21<00:03,  5.11it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:21<00:03,  5.11it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  5.30it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  5.30it/s, train_loss=1.98]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.31it/s, train_loss=1.98]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:22<00:03,  5.31it/s, train_loss=2.08]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:22<00:03,  5.21it/s, train_loss=2.08]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:22<00:03,  5.21it/s, train_loss=0.994]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:22<00:02,  5.15it/s, train_loss=0.994]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:22<00:02,  5.15it/s, train_loss=1.34] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:22<00:02,  5.08it/s, train_loss=1.34]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:22<00:02,  5.08it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  4.95it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  4.95it/s, train_loss=1.71]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.04it/s, train_loss=1.71]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:23<00:02,  5.04it/s, train_loss=1.48]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:23<00:02,  5.01it/s, train_loss=1.48]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:23<00:02,  5.01it/s, train_loss=1.4] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:23<00:02,  4.85it/s, train_loss=1.4]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:23<00:02,  4.85it/s, train_loss=1.58]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:23<00:01,  4.87it/s, train_loss=1.58]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:23<00:01,  4.87it/s, train_loss=1.75]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.96it/s, train_loss=1.75]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.96it/s, train_loss=1.5] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.02it/s, train_loss=1.5]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:24<00:01,  5.02it/s, train_loss=1.51]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:24<00:01,  5.04it/s, train_loss=1.51]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:24<00:01,  5.04it/s, train_loss=1.6] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:24<00:01,  4.94it/s, train_loss=1.6]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:24<00:01,  4.94it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:24<00:00,  5.17it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:24<00:00,  5.17it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  5.31it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  5.31it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.02it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.02it/s, train_loss=1.72]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:25<00:00,  5.07it/s, train_loss=1.72]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:25<00:00,  5.07it/s, train_loss=2.29]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:25<00:00,  5.87it/s, train_loss=2.29]\n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 average loss: 1.9724\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   1%|          | 1/110 [00:26<49:01, 26.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 1 current AUC: 0.9378 current accuracy: 0.5466 best AUC: 0.9378 at epoch: 1\n",
      "----------\n",
      "epoch 2/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=1.76]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.28it/s, train_loss=1.76]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.28it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.07it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.07it/s, train_loss=1.86]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.18it/s, train_loss=1.86]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.18it/s, train_loss=1.34]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.99it/s, train_loss=1.34]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.99it/s, train_loss=1.93]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.05it/s, train_loss=1.93]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.05it/s, train_loss=1.4] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.02it/s, train_loss=1.4]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.02it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.10it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.10it/s, train_loss=1.6] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.16it/s, train_loss=1.6]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.16it/s, train_loss=1.8]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.15it/s, train_loss=1.8]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.15it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.03it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.03it/s, train_loss=1.59]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.02it/s, train_loss=1.59]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.02it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.05it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.05it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.06it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.06it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.13it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.13it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.04it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.04it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.19it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.19it/s, train_loss=1.68]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.06it/s, train_loss=1.68]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.06it/s, train_loss=1.82]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.13it/s, train_loss=1.82]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.13it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.09it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.09it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.89it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.89it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.87it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.87it/s, train_loss=1.56]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.99it/s, train_loss=1.56]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.99it/s, train_loss=1.63]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=1.63]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=1.46]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.27it/s, train_loss=1.46]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.27it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.18it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.18it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.16it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.16it/s, train_loss=1.56]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.44it/s, train_loss=1.56]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.44it/s, train_loss=1.5] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.37it/s, train_loss=1.5]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.37it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.21it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.21it/s, train_loss=1.71]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.10it/s, train_loss=1.71]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.10it/s, train_loss=2.03]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.93it/s, train_loss=2.03]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.93it/s, train_loss=1.76]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.82it/s, train_loss=1.76]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.82it/s, train_loss=2.02]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.84it/s, train_loss=2.02]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.84it/s, train_loss=1.38]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:18,  4.77it/s, train_loss=1.38]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.77it/s, train_loss=1.46]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.68it/s, train_loss=1.46]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.68it/s, train_loss=1.38]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:18,  4.69it/s, train_loss=1.38]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:18,  4.69it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.76it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.76it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.89it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.89it/s, train_loss=1.2] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.07it/s, train_loss=1.2]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.07it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.16it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.16it/s, train_loss=1.52]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.16it/s, train_loss=1.52]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.16it/s, train_loss=1]   \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.19it/s, train_loss=1]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.19it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.26it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.26it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.06it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.06it/s, train_loss=0.971]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.35it/s, train_loss=0.971]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.35it/s, train_loss=1.09] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.29it/s, train_loss=1.09]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.29it/s, train_loss=1.1] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.41it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.41it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.59it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.59it/s, train_loss=1.5] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.25it/s, train_loss=1.5]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.25it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.18it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.18it/s, train_loss=1.74] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.22it/s, train_loss=1.74]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.22it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.17it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.17it/s, train_loss=1.63]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.95it/s, train_loss=1.63]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.95it/s, train_loss=0.944]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.16it/s, train_loss=0.944]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.16it/s, train_loss=0.983]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.14it/s, train_loss=0.983]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.14it/s, train_loss=1.67] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=1.67]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=1.51]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.18it/s, train_loss=1.51]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.18it/s, train_loss=1.58]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.32it/s, train_loss=1.58]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.32it/s, train_loss=0.873]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.21it/s, train_loss=0.873]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.21it/s, train_loss=1.21] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:11,  5.18it/s, train_loss=1.21]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.18it/s, train_loss=1.59]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.15it/s, train_loss=1.59]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.15it/s, train_loss=1.45]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.08it/s, train_loss=1.45]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.08it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.28it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.28it/s, train_loss=1.25]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.42it/s, train_loss=1.25]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.42it/s, train_loss=1.72]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.18it/s, train_loss=1.72]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.18it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.25it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.25it/s, train_loss=2.13]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.38it/s, train_loss=2.13]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.38it/s, train_loss=2]   \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:09,  5.56it/s, train_loss=2]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:09,  5.56it/s, train_loss=1.21]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.50it/s, train_loss=1.21]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.50it/s, train_loss=1.04]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.55it/s, train_loss=1.04]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.55it/s, train_loss=1.77]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.41it/s, train_loss=1.77]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.41it/s, train_loss=1.38]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.25it/s, train_loss=1.38]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.25it/s, train_loss=1.61]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.27it/s, train_loss=1.61]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.27it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.25it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.25it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.15it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.15it/s, train_loss=1.61]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:14<00:08,  5.15it/s, train_loss=1.61]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.15it/s, train_loss=1.25]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.15it/s, train_loss=1.25]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.15it/s, train_loss=1.34]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.11it/s, train_loss=1.34]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.11it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.27it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.27it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.28it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.28it/s, train_loss=1.93]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:15<00:07,  5.22it/s, train_loss=1.93]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.22it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.26it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.26it/s, train_loss=1.2] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.17it/s, train_loss=1.2]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.17it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.18it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.18it/s, train_loss=0.954]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.32it/s, train_loss=0.954]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.32it/s, train_loss=1.58] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:16<00:06,  5.11it/s, train_loss=1.58]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.11it/s, train_loss=1.64]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.06it/s, train_loss=1.64]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.06it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.91it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.91it/s, train_loss=1.87]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.93it/s, train_loss=1.87]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.93it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.08it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.08it/s, train_loss=1.49]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:17<00:05,  5.11it/s, train_loss=1.49]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.11it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.12it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.12it/s, train_loss=1.17] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.21it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.21it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:04,  5.51it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:04,  5.51it/s, train_loss=1.33]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.17it/s, train_loss=1.33]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.17it/s, train_loss=0.943]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:18<00:05,  4.88it/s, train_loss=0.943]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=1.03] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.94it/s, train_loss=1.03]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.94it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.01it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.01it/s, train_loss=1.29] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.975]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.12it/s, train_loss=0.975]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.12it/s, train_loss=2.19] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:19<00:03,  5.20it/s, train_loss=2.19]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.20it/s, train_loss=0.866]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.16it/s, train_loss=0.866]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.16it/s, train_loss=1.26] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.15it/s, train_loss=1.26]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.15it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.00it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.00it/s, train_loss=0.928]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.12it/s, train_loss=0.928]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.12it/s, train_loss=1.22] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:20<00:02,  5.26it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.26it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.29it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.29it/s, train_loss=1.66]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.35it/s, train_loss=1.66]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.35it/s, train_loss=1.68]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.39it/s, train_loss=1.68]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.39it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.36it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.36it/s, train_loss=1.51]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:01,  5.29it/s, train_loss=1.51]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:01,  5.29it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:21<00:01,  5.38it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.38it/s, train_loss=1.49]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.49it/s, train_loss=1.49]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.49it/s, train_loss=1.38]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.47it/s, train_loss=1.38]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.47it/s, train_loss=1.6] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.26it/s, train_loss=1.6]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.26it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:22<00:00,  5.52it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:22<00:00,  5.52it/s, train_loss=1.67]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:22<00:00,  5.35it/s, train_loss=1.67]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.35it/s, train_loss=1.24]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.30it/s, train_loss=1.24]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.30it/s, train_loss=1.61]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.11it/s, train_loss=1.61]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.11it/s, train_loss=1.1] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.07it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.07it/s, train_loss=1.68]\n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 average loss: 1.4056\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   2%|▏         | 2/110 [00:52<46:53, 26.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 2 current AUC: 0.9685 current accuracy: 0.6708 best AUC: 0.9685 at epoch: 2\n",
      "----------\n",
      "epoch 3/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.37it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.37it/s, train_loss=0.741]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.29it/s, train_loss=0.741]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.29it/s, train_loss=1.18] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.99it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.99it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.30it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.30it/s, train_loss=1.54]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.17it/s, train_loss=1.54]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.17it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.92it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.92it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.99it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.99it/s, train_loss=1.08] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.92it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.92it/s, train_loss=1.47]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.80it/s, train_loss=1.47]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.80it/s, train_loss=1.27]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.02it/s, train_loss=1.27]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.02it/s, train_loss=1.79]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.91it/s, train_loss=1.79]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.91it/s, train_loss=0.78]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.85it/s, train_loss=0.78]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.85it/s, train_loss=0.759]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.10it/s, train_loss=0.759]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.10it/s, train_loss=1.25] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.12it/s, train_loss=1.25]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.12it/s, train_loss=1.73]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.22it/s, train_loss=1.73]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.22it/s, train_loss=1.33]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.99it/s, train_loss=1.33]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.99it/s, train_loss=1.45]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.01it/s, train_loss=1.45]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.01it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.94it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.94it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.10it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.10it/s, train_loss=2.13]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.21it/s, train_loss=2.13]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.21it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.39it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.39it/s, train_loss=0.858]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.09it/s, train_loss=0.858]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.09it/s, train_loss=1.05] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.38it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.38it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.43it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.43it/s, train_loss=0.997]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:17,  5.43it/s, train_loss=0.997]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:17,  5.43it/s, train_loss=0.96] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:16,  5.75it/s, train_loss=0.96]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:16,  5.75it/s, train_loss=0.93]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:16,  5.60it/s, train_loss=0.93]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:16,  5.60it/s, train_loss=0.748]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.51it/s, train_loss=0.748]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.51it/s, train_loss=1.22] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.32it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.32it/s, train_loss=0.867]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.10it/s, train_loss=0.867]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.10it/s, train_loss=0.958]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.15it/s, train_loss=0.958]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.15it/s, train_loss=1.29] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.16it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.16it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.18it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.18it/s, train_loss=0.964]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.14it/s, train_loss=0.964]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.14it/s, train_loss=1.28] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.25it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.25it/s, train_loss=0.959]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:06<00:16,  5.28it/s, train_loss=0.959]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.28it/s, train_loss=0.632]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.19it/s, train_loss=0.632]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.19it/s, train_loss=1.2]  \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.26it/s, train_loss=1.2]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.26it/s, train_loss=0.8]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.8]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.14it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.14it/s, train_loss=1.61] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:07<00:15,  5.19it/s, train_loss=1.61]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.19it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.05it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.05it/s, train_loss=0.736]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.97it/s, train_loss=0.736]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.97it/s, train_loss=1.04] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.10it/s, train_loss=1.04]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.10it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.19it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.19it/s, train_loss=0.899]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:15,  5.06it/s, train_loss=0.899]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.06it/s, train_loss=1.27] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.18it/s, train_loss=1.27]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.18it/s, train_loss=1.47]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.11it/s, train_loss=1.47]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.11it/s, train_loss=1.27]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.11it/s, train_loss=1.27]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.11it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.20it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.20it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:14,  5.05it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.05it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.12it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.12it/s, train_loss=0.888]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.23it/s, train_loss=0.888]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.23it/s, train_loss=1.35] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.27it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.27it/s, train_loss=0.944]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.11it/s, train_loss=0.944]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.11it/s, train_loss=1.2]  \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.24it/s, train_loss=1.2]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.24it/s, train_loss=0.86]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.41it/s, train_loss=0.86]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.41it/s, train_loss=0.647]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.29it/s, train_loss=0.647]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.29it/s, train_loss=1.16] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.16it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.16it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.97it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.97it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  4.88it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.88it/s, train_loss=1.21]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.93it/s, train_loss=1.21]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.93it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.98it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.98it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.81it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.81it/s, train_loss=1]   \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.90it/s, train_loss=1]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.90it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  4.94it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.94it/s, train_loss=1.3] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.89it/s, train_loss=1.3]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.89it/s, train_loss=0.763]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.02it/s, train_loss=0.763]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.02it/s, train_loss=1.62] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.18it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.18it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.40it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.40it/s, train_loss=0.992]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.25it/s, train_loss=0.992]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.25it/s, train_loss=1.06] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.16it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.16it/s, train_loss=0.73]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.21it/s, train_loss=0.73]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.21it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.29it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.29it/s, train_loss=0.991]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.23it/s, train_loss=0.991]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.23it/s, train_loss=0.801]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.15it/s, train_loss=0.801]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.15it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:14<00:08,  5.23it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.23it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.11it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.11it/s, train_loss=0.872]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.21it/s, train_loss=0.872]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.21it/s, train_loss=0.968]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.21it/s, train_loss=0.968]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.21it/s, train_loss=0.855]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.24it/s, train_loss=0.855]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.24it/s, train_loss=1.28] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:15<00:07,  5.08it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.08it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.88it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.88it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.80it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.80it/s, train_loss=1.13] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.01it/s, train_loss=1.13]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.01it/s, train_loss=0.9] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  4.99it/s, train_loss=0.9]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  4.99it/s, train_loss=1.66]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:16<00:06,  5.11it/s, train_loss=1.66]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.11it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.24it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.24it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.15it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.15it/s, train_loss=1.09] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.03it/s, train_loss=1.09]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.03it/s, train_loss=0.67]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.12it/s, train_loss=0.67]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.12it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:17<00:06,  4.90it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.90it/s, train_loss=0.993]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.00it/s, train_loss=0.993]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.00it/s, train_loss=1.19] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.87it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.87it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.03it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.03it/s, train_loss=1.03]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.34it/s, train_loss=1.03]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.34it/s, train_loss=1.76]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:18<00:04,  5.22it/s, train_loss=1.76]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.22it/s, train_loss=1.2] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.28it/s, train_loss=1.2]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.28it/s, train_loss=1.98]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.28it/s, train_loss=1.98]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.28it/s, train_loss=0.975]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.975]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.682]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.29it/s, train_loss=0.682]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.29it/s, train_loss=0.689]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:19<00:03,  5.29it/s, train_loss=0.689]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.29it/s, train_loss=1.03] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.18it/s, train_loss=1.03]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.18it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.08it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.08it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.24it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.24it/s, train_loss=1.09] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.31it/s, train_loss=1.09]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.31it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:20<00:02,  5.17it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.17it/s, train_loss=1.82]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.23it/s, train_loss=1.82]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.23it/s, train_loss=1.47]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.96it/s, train_loss=1.47]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.96it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.83it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.83it/s, train_loss=0.875]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.91it/s, train_loss=0.875]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.91it/s, train_loss=1.32] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:02,  4.98it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.98it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.05it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.05it/s, train_loss=0.971]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.91it/s, train_loss=0.971]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.91it/s, train_loss=1.83] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.06it/s, train_loss=1.83]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.06it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.06it/s, train_loss=1.62]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.06it/s, train_loss=1.1] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:22<00:00,  5.11it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.11it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.98it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.98it/s, train_loss=1.49]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.91it/s, train_loss=1.49]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.91it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.04it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.04it/s, train_loss=0.821]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.93it/s, train_loss=0.821]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.93it/s, train_loss=2.66] \n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:23<00:00,  5.71it/s, train_loss=2.66]\n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 average loss: 1.1324\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   3%|▎         | 3/110 [01:18<46:06, 25.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 3 current AUC: 0.9795 current accuracy: 0.6832 best AUC: 0.9795 at epoch: 3\n",
      "----------\n",
      "epoch 4/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.07it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.07it/s, train_loss=0.588]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.22it/s, train_loss=0.588]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.22it/s, train_loss=1.8]  \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.05it/s, train_loss=1.8]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.05it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.93it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  4.93it/s, train_loss=1.25] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.89it/s, train_loss=1.25]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.89it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.64it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.64it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.80it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.80it/s, train_loss=1.43]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=1.43]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=1]   \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.04it/s, train_loss=1]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  5.04it/s, train_loss=1.7]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.90it/s, train_loss=1.7]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.90it/s, train_loss=1.09]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.98it/s, train_loss=1.09]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.98it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=0.893]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.87it/s, train_loss=0.893]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.87it/s, train_loss=1.35] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.95it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  4.95it/s, train_loss=0.719]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.04it/s, train_loss=0.719]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.04it/s, train_loss=1.22] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.24it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.24it/s, train_loss=0.544]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.10it/s, train_loss=0.544]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.10it/s, train_loss=1.33] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.08it/s, train_loss=1.33]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.08it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.22it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.22it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.21it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.21it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.40it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.40it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.30it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.30it/s, train_loss=1.8] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.23it/s, train_loss=1.8]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.23it/s, train_loss=0.816]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.27it/s, train_loss=0.816]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.27it/s, train_loss=0.789]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.25it/s, train_loss=0.789]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.25it/s, train_loss=0.873]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.23it/s, train_loss=0.873]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.23it/s, train_loss=1.6]  \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.21it/s, train_loss=1.6]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.21it/s, train_loss=1.47]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.25it/s, train_loss=1.47]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.25it/s, train_loss=0.669]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.13it/s, train_loss=0.669]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.13it/s, train_loss=1.14] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.08it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.08it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.15it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.15it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.09it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.09it/s, train_loss=0.771]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.16it/s, train_loss=0.771]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.16it/s, train_loss=1.78] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.41it/s, train_loss=1.78]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.41it/s, train_loss=0.47]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.32it/s, train_loss=0.47]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.32it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:15,  5.50it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:15,  5.50it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.39it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.39it/s, train_loss=0.742]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.44it/s, train_loss=0.742]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.44it/s, train_loss=1.3]  \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.31it/s, train_loss=1.3]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.31it/s, train_loss=1.96]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.25it/s, train_loss=1.96]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.25it/s, train_loss=0.896]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:07<00:15,  5.20it/s, train_loss=0.896]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.20it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.22it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.22it/s, train_loss=0.902]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.94it/s, train_loss=0.902]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.94it/s, train_loss=1.27] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.95it/s, train_loss=1.27]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.95it/s, train_loss=0.825]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.90it/s, train_loss=0.825]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.90it/s, train_loss=0.66] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:15,  5.00it/s, train_loss=0.66]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.00it/s, train_loss=0.728]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.90it/s, train_loss=0.728]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.90it/s, train_loss=1.52] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.05it/s, train_loss=1.52]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.05it/s, train_loss=0.93]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.98it/s, train_loss=0.93]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.98it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.21it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.21it/s, train_loss=0.967]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.31it/s, train_loss=0.967]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.31it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.20it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.20it/s, train_loss=0.775]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=0.775]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=1.45] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.87it/s, train_loss=1.45]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.87it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.99it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.99it/s, train_loss=0.838]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.08it/s, train_loss=0.838]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.08it/s, train_loss=1.21] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.13it/s, train_loss=1.21]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.13it/s, train_loss=0.92]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.27it/s, train_loss=0.92]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.27it/s, train_loss=0.762]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.23it/s, train_loss=0.762]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.23it/s, train_loss=0.811]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.23it/s, train_loss=0.811]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.23it/s, train_loss=1.13] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:11,  5.29it/s, train_loss=1.13]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.29it/s, train_loss=0.783]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.29it/s, train_loss=0.783]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.29it/s, train_loss=0.854]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.06it/s, train_loss=0.854]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.06it/s, train_loss=1.43] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.97it/s, train_loss=1.43]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.97it/s, train_loss=0.665]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.93it/s, train_loss=0.665]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.93it/s, train_loss=2.02] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  5.03it/s, train_loss=2.02]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.03it/s, train_loss=0.738]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.24it/s, train_loss=0.738]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.24it/s, train_loss=1.66] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.22it/s, train_loss=1.66]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.22it/s, train_loss=1.03]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.30it/s, train_loss=1.03]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.30it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.36it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.36it/s, train_loss=1.03]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.19it/s, train_loss=1.03]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.19it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.10it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.10it/s, train_loss=0.963]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.96it/s, train_loss=0.963]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.96it/s, train_loss=1.6]  \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.10it/s, train_loss=1.6]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.10it/s, train_loss=0.595]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.00it/s, train_loss=0.595]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.00it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.11it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.11it/s, train_loss=0.89] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.11it/s, train_loss=0.89]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.11it/s, train_loss=0.721]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.10it/s, train_loss=0.721]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.10it/s, train_loss=0.955]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=0.955]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=0.54] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.83it/s, train_loss=0.54]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.83it/s, train_loss=1.23]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.00it/s, train_loss=1.23]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.00it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.14it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.14it/s, train_loss=0.781]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.15it/s, train_loss=0.781]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.15it/s, train_loss=0.889]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.37it/s, train_loss=0.889]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.37it/s, train_loss=0.613]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.39it/s, train_loss=0.613]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.39it/s, train_loss=2.31] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.33it/s, train_loss=2.31]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.33it/s, train_loss=1.24]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:16<00:06,  5.26it/s, train_loss=1.24]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.26it/s, train_loss=0.758]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.19it/s, train_loss=0.758]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.19it/s, train_loss=1.37] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.01it/s, train_loss=1.37]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.01it/s, train_loss=1.57]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.14it/s, train_loss=1.57]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.14it/s, train_loss=0.632]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.99it/s, train_loss=0.632]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.99it/s, train_loss=0.96] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:17<00:06,  4.85it/s, train_loss=0.96]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.85it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.02it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.02it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=1.48] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.93it/s, train_loss=1.48]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.93it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.08it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.08it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:18<00:04,  5.06it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.06it/s, train_loss=1.09] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.90it/s, train_loss=1.09]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.90it/s, train_loss=0.772]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.83it/s, train_loss=0.772]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.83it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.34it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.34it/s, train_loss=1.43] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.39it/s, train_loss=1.43]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.39it/s, train_loss=1.57]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:19<00:03,  5.37it/s, train_loss=1.57]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.37it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.25it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.25it/s, train_loss=0.539]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.20it/s, train_loss=0.539]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.20it/s, train_loss=1.22] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.13it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.13it/s, train_loss=0.738]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.01it/s, train_loss=0.738]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.01it/s, train_loss=0.811]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:20<00:02,  5.04it/s, train_loss=0.811]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.04it/s, train_loss=1.02] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.10it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.10it/s, train_loss=1]   \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.93it/s, train_loss=1]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.93it/s, train_loss=0.991]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.08it/s, train_loss=0.991]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.08it/s, train_loss=0.975]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.32it/s, train_loss=0.975]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.32it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:01,  5.04it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.12it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.12it/s, train_loss=0.606]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.17it/s, train_loss=0.606]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.17it/s, train_loss=0.796]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.10it/s, train_loss=0.796]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.10it/s, train_loss=0.726]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.26it/s, train_loss=0.726]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.26it/s, train_loss=0.792]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:22<00:00,  5.39it/s, train_loss=0.792]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.39it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.26it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.26it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.34it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.34it/s, train_loss=0.948]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.32it/s, train_loss=0.948]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.32it/s, train_loss=1.49] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.34it/s, train_loss=1.49]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.34it/s, train_loss=2.52]\n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 average loss: 1.0292\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   4%|▎         | 4/110 [01:43<45:27, 25.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 4 current AUC: 0.9845 current accuracy: 0.7764 best AUC: 0.9845 at epoch: 4\n",
      "----------\n",
      "epoch 5/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.709]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.88it/s, train_loss=0.709]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.88it/s, train_loss=1.01] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  5.00it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  5.00it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.79it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.79it/s, train_loss=0.814]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.92it/s, train_loss=0.814]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  4.92it/s, train_loss=0.59] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.86it/s, train_loss=0.59]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.86it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.94it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.94it/s, train_loss=0.89]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.82it/s, train_loss=0.89]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.82it/s, train_loss=1.66]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.76it/s, train_loss=1.66]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.76it/s, train_loss=0.69]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.01it/s, train_loss=0.69]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  5.01it/s, train_loss=0.807]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.24it/s, train_loss=0.807]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.24it/s, train_loss=0.709]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.42it/s, train_loss=0.709]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.42it/s, train_loss=0.686]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.40it/s, train_loss=0.686]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.40it/s, train_loss=1.16] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.40it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.40it/s, train_loss=1.26]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.30it/s, train_loss=1.26]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.30it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.27it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.27it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.31it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.31it/s, train_loss=0.734]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.37it/s, train_loss=0.734]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.37it/s, train_loss=0.628]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.44it/s, train_loss=0.628]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.44it/s, train_loss=0.516]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:18,  5.60it/s, train_loss=0.516]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:18,  5.60it/s, train_loss=0.801]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.11it/s, train_loss=0.801]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.11it/s, train_loss=0.53] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.00it/s, train_loss=0.53]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.00it/s, train_loss=0.688]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=0.688]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=1.19] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.04it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.04it/s, train_loss=1.43]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.17it/s, train_loss=1.43]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.17it/s, train_loss=1.26]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.13it/s, train_loss=1.26]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.13it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.00it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.00it/s, train_loss=0.837]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.97it/s, train_loss=0.837]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.97it/s, train_loss=0.977]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.85it/s, train_loss=0.977]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.85it/s, train_loss=0.781]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.95it/s, train_loss=0.781]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.95it/s, train_loss=0.875]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.03it/s, train_loss=0.875]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.03it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.98it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.98it/s, train_loss=0.755]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.26it/s, train_loss=0.755]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.26it/s, train_loss=0.826]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.02it/s, train_loss=0.826]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.02it/s, train_loss=0.849]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.00it/s, train_loss=0.849]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.00it/s, train_loss=0.784]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:18,  4.76it/s, train_loss=0.784]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.76it/s, train_loss=0.731]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.73it/s, train_loss=0.731]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.73it/s, train_loss=0.738]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:18,  4.64it/s, train_loss=0.738]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:18,  4.64it/s, train_loss=0.548]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.77it/s, train_loss=0.548]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.77it/s, train_loss=0.931]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.00it/s, train_loss=0.931]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.00it/s, train_loss=1.19] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.11it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.11it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.10it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.10it/s, train_loss=0.696]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.02it/s, train_loss=0.696]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.02it/s, train_loss=0.821]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.99it/s, train_loss=0.821]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.99it/s, train_loss=0.596]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.16it/s, train_loss=0.596]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.16it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.28it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.28it/s, train_loss=0.734]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.24it/s, train_loss=0.734]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.24it/s, train_loss=1.17] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.41it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.41it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.12it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.12it/s, train_loss=0.76] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.26it/s, train_loss=0.76]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.26it/s, train_loss=0.47]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.08it/s, train_loss=0.47]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.08it/s, train_loss=1.11]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.26it/s, train_loss=1.11]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.26it/s, train_loss=0.729]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.16it/s, train_loss=0.729]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.16it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.15it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.15it/s, train_loss=0.849]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.09it/s, train_loss=0.849]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.09it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.93it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.93it/s, train_loss=0.878]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.86it/s, train_loss=0.878]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.86it/s, train_loss=1.07] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.05it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.05it/s, train_loss=0.919]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.96it/s, train_loss=0.919]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.96it/s, train_loss=0.924]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.03it/s, train_loss=0.924]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.03it/s, train_loss=0.847]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.97it/s, train_loss=0.847]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.97it/s, train_loss=1.47] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.21it/s, train_loss=1.47]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.21it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.32it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.32it/s, train_loss=0.668]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.25it/s, train_loss=0.668]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.25it/s, train_loss=0.979]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.12it/s, train_loss=0.979]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.12it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.21it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.21it/s, train_loss=1.4]  \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.11it/s, train_loss=1.4]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.11it/s, train_loss=1.33]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.11it/s, train_loss=1.33]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.11it/s, train_loss=0.844]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.01it/s, train_loss=0.844]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.01it/s, train_loss=0.625]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.96it/s, train_loss=0.625]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.96it/s, train_loss=0.986]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.14it/s, train_loss=0.986]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.14it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  4.99it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.99it/s, train_loss=0.687]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.09it/s, train_loss=0.687]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.09it/s, train_loss=0.763]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.80it/s, train_loss=0.763]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.80it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.89it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.89it/s, train_loss=0.652]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.78it/s, train_loss=0.652]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.78it/s, train_loss=2.04] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.88it/s, train_loss=2.04]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.88it/s, train_loss=1.13]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.78it/s, train_loss=1.13]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.78it/s, train_loss=0.56]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.87it/s, train_loss=0.56]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.87it/s, train_loss=1.25]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=1.25]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.98it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.98it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.03it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.03it/s, train_loss=1.05] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.87it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.87it/s, train_loss=1.83]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.00it/s, train_loss=1.83]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.00it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.83it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.83it/s, train_loss=1.11] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.89it/s, train_loss=1.11]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.89it/s, train_loss=1]   \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.95it/s, train_loss=1]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.95it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.88it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.88it/s, train_loss=1.24]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.74it/s, train_loss=1.24]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.74it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.79it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.79it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.91it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.91it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.04it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.04it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.99it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.99it/s, train_loss=0.824]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.06it/s, train_loss=0.824]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.06it/s, train_loss=0.655]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.29it/s, train_loss=0.655]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.29it/s, train_loss=1.18] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.16it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.16it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.96it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.96it/s, train_loss=0.744]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.92it/s, train_loss=0.744]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.92it/s, train_loss=0.812]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.03it/s, train_loss=0.812]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.03it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.12it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.12it/s, train_loss=1.13] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.04it/s, train_loss=1.13]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.04it/s, train_loss=0.703]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.07it/s, train_loss=0.703]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.07it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.99it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.99it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.22it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.22it/s, train_loss=0.781]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.14it/s, train_loss=0.781]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.14it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.07it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.07it/s, train_loss=1.31] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.06it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.06it/s, train_loss=0.846]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.13it/s, train_loss=0.846]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.13it/s, train_loss=0.655]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.03it/s, train_loss=0.655]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.03it/s, train_loss=1.12] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.11it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.11it/s, train_loss=0.97]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.20it/s, train_loss=0.97]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.20it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.16it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.16it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.24it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.24it/s, train_loss=0.884]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.24it/s, train_loss=0.884]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.24it/s, train_loss=0.51] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.45it/s, train_loss=0.51]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.45it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.07it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.07it/s, train_loss=0.686]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.97it/s, train_loss=0.686]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.97it/s, train_loss=0.754]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.86it/s, train_loss=0.754]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.86it/s, train_loss=1.27] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.98it/s, train_loss=1.27]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.98it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.90it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.90it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.11it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.11it/s, train_loss=1.42] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.08it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=0.387]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 average loss: 0.9063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   5%|▍         | 5/110 [02:08<44:20, 25.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 5 current AUC: 0.9812 current accuracy: 0.6708 best AUC: 0.9845 at epoch: 4\n",
      "----------\n",
      "epoch 6/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.771]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.21it/s, train_loss=0.771]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.21it/s, train_loss=1.23] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.13it/s, train_loss=1.23]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.13it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.97it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.97it/s, train_loss=0.58]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.83it/s, train_loss=0.58]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.83it/s, train_loss=0.829]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.92it/s, train_loss=0.829]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.92it/s, train_loss=0.593]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.89it/s, train_loss=0.593]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.89it/s, train_loss=0.677]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.11it/s, train_loss=0.677]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.11it/s, train_loss=0.592]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.93it/s, train_loss=0.592]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.93it/s, train_loss=1.31] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.91it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  4.91it/s, train_loss=0.517]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.99it/s, train_loss=0.517]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.99it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.93it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.93it/s, train_loss=0.881]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.12it/s, train_loss=0.881]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.12it/s, train_loss=0.806]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.14it/s, train_loss=0.806]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.14it/s, train_loss=0.73] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.09it/s, train_loss=0.73]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.09it/s, train_loss=1.09]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.13it/s, train_loss=1.09]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.13it/s, train_loss=0.947]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.11it/s, train_loss=0.947]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.11it/s, train_loss=1.38] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.17it/s, train_loss=1.38]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.17it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.14it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.14it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.13it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.13it/s, train_loss=0.975]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.16it/s, train_loss=0.975]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.16it/s, train_loss=1.44] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.13it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.13it/s, train_loss=0.697]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.04it/s, train_loss=0.697]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.04it/s, train_loss=0.613]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.87it/s, train_loss=0.613]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.87it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.10it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.10it/s, train_loss=0.836]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:20,  4.81it/s, train_loss=0.836]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.81it/s, train_loss=0.831]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.98it/s, train_loss=0.831]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.98it/s, train_loss=1.02] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.14it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.14it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.19it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.19it/s, train_loss=0.701]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.11it/s, train_loss=0.701]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.11it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.02it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.02it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.26it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.26it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.09it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.09it/s, train_loss=0.827]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.97it/s, train_loss=0.827]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.97it/s, train_loss=0.52] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.83it/s, train_loss=0.52]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.83it/s, train_loss=0.955]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.13it/s, train_loss=0.955]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.13it/s, train_loss=0.685]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.06it/s, train_loss=0.685]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.06it/s, train_loss=1.17] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.03it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.03it/s, train_loss=1.46] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.06it/s, train_loss=1.46]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.06it/s, train_loss=0.871]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.07it/s, train_loss=0.871]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.07it/s, train_loss=2.41] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.03it/s, train_loss=2.41]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.03it/s, train_loss=0.728]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.30it/s, train_loss=0.728]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.30it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.21it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.21it/s, train_loss=1.05] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.15it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.15it/s, train_loss=0.956]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.91it/s, train_loss=0.956]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.91it/s, train_loss=0.541]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:16,  4.71it/s, train_loss=0.541]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:16,  4.71it/s, train_loss=1.35] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.76it/s, train_loss=1.35]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.76it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.93it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.93it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.96it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.96it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.91it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.91it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.98it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.98it/s, train_loss=1.42] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.06it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.06it/s, train_loss=0.865]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.01it/s, train_loss=0.865]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.01it/s, train_loss=0.981]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.83it/s, train_loss=0.981]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.83it/s, train_loss=1.07] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.89it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.89it/s, train_loss=1.93]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.91it/s, train_loss=1.93]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.91it/s, train_loss=0.71]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.93it/s, train_loss=0.71]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.93it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.11it/s, train_loss=1.41]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.11it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=1.1] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.89it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.89it/s, train_loss=0.939]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.70it/s, train_loss=0.939]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.70it/s, train_loss=0.74] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.65it/s, train_loss=0.74]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.65it/s, train_loss=0.758]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.78it/s, train_loss=0.758]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.78it/s, train_loss=0.677]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.00it/s, train_loss=0.677]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  5.00it/s, train_loss=0.636]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.92it/s, train_loss=0.636]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.92it/s, train_loss=0.69] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.09it/s, train_loss=0.69]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.09it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.16it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.16it/s, train_loss=0.723]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.28it/s, train_loss=0.723]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.28it/s, train_loss=1.19] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.19it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.19it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.31it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.31it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.18it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.18it/s, train_loss=0.608]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.03it/s, train_loss=0.608]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.03it/s, train_loss=1.02] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.03it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.03it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.95it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.95it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.09it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.09it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.04it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.04it/s, train_loss=0.531]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.87it/s, train_loss=0.531]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.87it/s, train_loss=0.757]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.94it/s, train_loss=0.757]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.94it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.05it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.05it/s, train_loss=0.855]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.02it/s, train_loss=0.855]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.02it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.99it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.99it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=2.05] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.25it/s, train_loss=2.05]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.25it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.15it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.15it/s, train_loss=0.859]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.27it/s, train_loss=0.859]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.27it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.40it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.40it/s, train_loss=0.582]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  5.00it/s, train_loss=0.582]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  5.00it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.01it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.01it/s, train_loss=0.855]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.84it/s, train_loss=0.855]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.84it/s, train_loss=0.784]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.87it/s, train_loss=0.784]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.87it/s, train_loss=1.08] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.00it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.00it/s, train_loss=0.848]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.91it/s, train_loss=0.848]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.91it/s, train_loss=0.654]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.90it/s, train_loss=0.654]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.90it/s, train_loss=0.925]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.01it/s, train_loss=0.925]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.01it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.92it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.92it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.08it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.08it/s, train_loss=1.56] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=1.56]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.94]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.13it/s, train_loss=0.94]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.13it/s, train_loss=0.921]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.11it/s, train_loss=0.921]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.11it/s, train_loss=0.796]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.96it/s, train_loss=0.796]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.96it/s, train_loss=1.28] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.18it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.18it/s, train_loss=0.943]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.15it/s, train_loss=0.943]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.15it/s, train_loss=0.663]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.19it/s, train_loss=0.663]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.19it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.24it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.24it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.40it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.40it/s, train_loss=0.67]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:02,  5.37it/s, train_loss=0.67]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:02,  5.37it/s, train_loss=0.72]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.20it/s, train_loss=0.72]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.20it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.11it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.11it/s, train_loss=0.644]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.16it/s, train_loss=0.644]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.16it/s, train_loss=1.08] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.24it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.24it/s, train_loss=0.803]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.14it/s, train_loss=0.803]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.14it/s, train_loss=0.89] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.38it/s, train_loss=0.89]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.38it/s, train_loss=0.776]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.24it/s, train_loss=0.776]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.24it/s, train_loss=0.789]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.05it/s, train_loss=0.789]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.05it/s, train_loss=0.905]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.02it/s, train_loss=0.905]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.02it/s, train_loss=0.907]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.14it/s, train_loss=0.907]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.14it/s, train_loss=0.566]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.24it/s, train_loss=0.566]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.24it/s, train_loss=0.807]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.35it/s, train_loss=0.807]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.35it/s, train_loss=0.863]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.40it/s, train_loss=0.863]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.40it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.26it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.26it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.08it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=1.09] \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 average loss: 0.8730\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   5%|▌         | 6/110 [02:34<44:14, 25.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 6 current AUC: 0.9868 current accuracy: 0.7143 best AUC: 0.9868 at epoch: 6\n",
      "----------\n",
      "epoch 7/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.05it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.05it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.36it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.36it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.21it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.21it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.11it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.11it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.12it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.12it/s, train_loss=0.891]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.22it/s, train_loss=0.891]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.22it/s, train_loss=0.787]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.11it/s, train_loss=0.787]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.11it/s, train_loss=1.15] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.41it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.41it/s, train_loss=0.759]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.37it/s, train_loss=0.759]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.37it/s, train_loss=0.544]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:20,  5.38it/s, train_loss=0.544]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:20,  5.38it/s, train_loss=1.05] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.47it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.47it/s, train_loss=0.691]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.42it/s, train_loss=0.691]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.42it/s, train_loss=1.53] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.34it/s, train_loss=1.53]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.34it/s, train_loss=1.1] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.26it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.26it/s, train_loss=0.816]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.31it/s, train_loss=0.816]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.31it/s, train_loss=1.12] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.33it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.33it/s, train_loss=0.825]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.20it/s, train_loss=0.825]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.20it/s, train_loss=1]    \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.14it/s, train_loss=1]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.14it/s, train_loss=0.488]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.87it/s, train_loss=0.488]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.87it/s, train_loss=0.932]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.97it/s, train_loss=0.932]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.97it/s, train_loss=1.34] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.17it/s, train_loss=1.34]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.17it/s, train_loss=0.563]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.91it/s, train_loss=0.563]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.91it/s, train_loss=0.577]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.96it/s, train_loss=0.577]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.96it/s, train_loss=0.905]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=0.905]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.96it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.96it/s, train_loss=0.644]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.96it/s, train_loss=0.644]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.96it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.88it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.88it/s, train_loss=0.796]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.11it/s, train_loss=0.796]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.11it/s, train_loss=0.861]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.92it/s, train_loss=0.861]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.92it/s, train_loss=0.86] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.10it/s, train_loss=0.86]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.10it/s, train_loss=0.746]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.746]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.93] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.95it/s, train_loss=0.93]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.95it/s, train_loss=0.559]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.82it/s, train_loss=0.559]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.82it/s, train_loss=0.735]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.96it/s, train_loss=0.735]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.96it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.16it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.16it/s, train_loss=0.845]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.10it/s, train_loss=0.845]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.10it/s, train_loss=0.779]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.91it/s, train_loss=0.779]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.91it/s, train_loss=0.722]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.92it/s, train_loss=0.722]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.92it/s, train_loss=1.31] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.97it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.97it/s, train_loss=1.7] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.02it/s, train_loss=1.7]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.02it/s, train_loss=0.946]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.23it/s, train_loss=0.946]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.23it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.97it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.97it/s, train_loss=0.4]  \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.99it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.99it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.99it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.99it/s, train_loss=0.96] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.11it/s, train_loss=0.96]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.11it/s, train_loss=0.788]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.31it/s, train_loss=0.788]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.31it/s, train_loss=0.69] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.42it/s, train_loss=0.69]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.42it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.48it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.48it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.28it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.28it/s, train_loss=0.815]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.13it/s, train_loss=0.815]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.13it/s, train_loss=0.782]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.00it/s, train_loss=0.782]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.00it/s, train_loss=0.698]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.99it/s, train_loss=0.698]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.99it/s, train_loss=0.884]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.97it/s, train_loss=0.884]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.97it/s, train_loss=0.769]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.89it/s, train_loss=0.769]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.89it/s, train_loss=0.944]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:13,  5.00it/s, train_loss=0.944]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.00it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.95it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.95it/s, train_loss=0.547]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.83it/s, train_loss=0.547]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.83it/s, train_loss=0.646]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.86it/s, train_loss=0.646]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.86it/s, train_loss=0.994]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.83it/s, train_loss=0.994]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.83it/s, train_loss=0.561]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.87it/s, train_loss=0.561]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.87it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.89it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.89it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.94it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.94it/s, train_loss=0.907]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.79it/s, train_loss=0.907]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.79it/s, train_loss=0.715]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.92it/s, train_loss=0.715]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.92it/s, train_loss=1.05] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.82it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.82it/s, train_loss=0.545]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.545]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.784]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.88it/s, train_loss=0.784]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.88it/s, train_loss=1.14] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.94it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.94it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.02it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.02it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.95it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.95it/s, train_loss=0.72]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.99it/s, train_loss=0.72]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.99it/s, train_loss=0.906]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.96it/s, train_loss=0.906]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.96it/s, train_loss=1.38] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.72it/s, train_loss=1.38]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.72it/s, train_loss=0.568]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:10,  4.69it/s, train_loss=0.568]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:10,  4.69it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.91it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.91it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.90it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.90it/s, train_loss=0.652]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.01it/s, train_loss=0.652]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.01it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.13it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.13it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.15it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.15it/s, train_loss=0.616]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.32it/s, train_loss=0.616]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.32it/s, train_loss=0.787]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.11it/s, train_loss=0.787]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.11it/s, train_loss=0.638]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.07it/s, train_loss=0.638]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.07it/s, train_loss=0.516]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.20it/s, train_loss=0.516]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.20it/s, train_loss=0.51] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.29it/s, train_loss=0.51]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:06,  5.29it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.09it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.09it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.08it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.08it/s, train_loss=0.771]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.07it/s, train_loss=0.771]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.07it/s, train_loss=0.885]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.97it/s, train_loss=0.885]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.97it/s, train_loss=2.02] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.13it/s, train_loss=2.02]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.13it/s, train_loss=0.725]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.94it/s, train_loss=0.725]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.94it/s, train_loss=0.463]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.11it/s, train_loss=0.463]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.11it/s, train_loss=1.01] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.04it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.04it/s, train_loss=0.924]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.18it/s, train_loss=0.924]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.18it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.94it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.94it/s, train_loss=0.685]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.97it/s, train_loss=0.685]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.97it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.16it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.16it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.12it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.12it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.94it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.94it/s, train_loss=1.01] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.78it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.78it/s, train_loss=0.786]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.88it/s, train_loss=0.786]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.88it/s, train_loss=0.758]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.88it/s, train_loss=0.758]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.88it/s, train_loss=0.814]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:04,  4.75it/s, train_loss=0.814]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:04,  4.75it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.92it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.92it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.07it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.07it/s, train_loss=0.62] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.19it/s, train_loss=0.62]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.19it/s, train_loss=0.616]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.22it/s, train_loss=0.616]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.22it/s, train_loss=0.923]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.31it/s, train_loss=0.923]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.31it/s, train_loss=1.6]  \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.10it/s, train_loss=1.6]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.10it/s, train_loss=0.837]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.13it/s, train_loss=0.837]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.13it/s, train_loss=0.942]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.20it/s, train_loss=0.942]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.20it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.14it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.14it/s, train_loss=0.511]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.16it/s, train_loss=0.511]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.16it/s, train_loss=0.647]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.19it/s, train_loss=0.647]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.19it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.11it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.11it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.31it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.31it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.21it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.21it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.23it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.23it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.15it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.15it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.99it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.99it/s, train_loss=0.559]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.06it/s, train_loss=0.559]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.06it/s, train_loss=0.428]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 average loss: 0.7390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   6%|▋         | 7/110 [02:58<43:18, 25.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 7 current AUC: 0.9826 current accuracy: 0.7950 best AUC: 0.9868 at epoch: 6\n",
      "----------\n",
      "epoch 8/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.54it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.54it/s, train_loss=1.06] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  5.00it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  5.00it/s, train_loss=2.26]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.24it/s, train_loss=2.26]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.24it/s, train_loss=0.951]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.32it/s, train_loss=0.951]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.32it/s, train_loss=0.985]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.10it/s, train_loss=0.985]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.10it/s, train_loss=1.11] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.97it/s, train_loss=1.11]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.97it/s, train_loss=0.956]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.06it/s, train_loss=0.956]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.06it/s, train_loss=0.824]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  4.98it/s, train_loss=0.824]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  4.98it/s, train_loss=0.766]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.12it/s, train_loss=0.766]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.12it/s, train_loss=0.798]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.10it/s, train_loss=0.798]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.10it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.17it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.17it/s, train_loss=0.761]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.07it/s, train_loss=0.761]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.07it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.05it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.05it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.02it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.02it/s, train_loss=0.722]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.08it/s, train_loss=0.722]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.08it/s, train_loss=0.807]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.21it/s, train_loss=0.807]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.21it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.21it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.21it/s, train_loss=0.726]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.01it/s, train_loss=0.726]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.01it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.00it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.00it/s, train_loss=0.892]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.92it/s, train_loss=0.892]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.92it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.23it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.23it/s, train_loss=0.653]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.31it/s, train_loss=0.653]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.31it/s, train_loss=0.841]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.31it/s, train_loss=0.841]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.31it/s, train_loss=0.722]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.22it/s, train_loss=0.722]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.22it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.20it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.20it/s, train_loss=1.01] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.14it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.14it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.38it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.38it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.40it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.40it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.39it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.39it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.17it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.17it/s, train_loss=0.674]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.18it/s, train_loss=0.674]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.18it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.92it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.92it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.84it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.84it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.90it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.90it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.11it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.11it/s, train_loss=0.74] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.04it/s, train_loss=0.74]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.04it/s, train_loss=0.689]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.27it/s, train_loss=0.689]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.27it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.19it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.19it/s, train_loss=0.58] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.30it/s, train_loss=0.58]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.30it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.21it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.21it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.07it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.07it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.06it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.06it/s, train_loss=0.927]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.13it/s, train_loss=0.927]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.13it/s, train_loss=1.21] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.13it/s, train_loss=1.21]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.13it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.10it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.10it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:15,  5.05it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.05it/s, train_loss=0.817]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.06it/s, train_loss=0.817]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.06it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.14it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.14it/s, train_loss=1.48] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.98it/s, train_loss=1.48]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.98it/s, train_loss=0.426]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.91it/s, train_loss=0.426]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.91it/s, train_loss=0.767]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.79it/s, train_loss=0.767]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.79it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.03it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.03it/s, train_loss=0.51] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.07it/s, train_loss=0.51]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.07it/s, train_loss=0.689]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.94it/s, train_loss=0.689]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.94it/s, train_loss=0.644]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.95it/s, train_loss=0.644]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.95it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.89it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.89it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.93it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.93it/s, train_loss=0.867]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.90it/s, train_loss=0.867]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.90it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.84it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.84it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.95it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.95it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.12it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.12it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.99it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.99it/s, train_loss=0.76] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.85it/s, train_loss=0.76]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.85it/s, train_loss=0.735]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.80it/s, train_loss=0.735]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.80it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:12,  4.75it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:12,  4.75it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.97it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.97it/s, train_loss=0.622]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.75it/s, train_loss=0.622]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.75it/s, train_loss=1.01] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.86it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.86it/s, train_loss=1.99]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.85it/s, train_loss=1.99]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.85it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.11it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.11it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.81it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.81it/s, train_loss=0.673]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.93it/s, train_loss=0.673]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.93it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.76it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.76it/s, train_loss=0.686]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.81it/s, train_loss=0.686]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.81it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.02it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.02it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.99it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.99it/s, train_loss=0.47] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.83it/s, train_loss=0.47]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.83it/s, train_loss=1.54]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.69it/s, train_loss=1.54]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.69it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.48it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.48it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.90it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.90it/s, train_loss=0.74]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.98it/s, train_loss=0.74]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.98it/s, train_loss=0.467]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.19it/s, train_loss=0.467]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.19it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.92it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.92it/s, train_loss=0.5]  \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.97it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.97it/s, train_loss=1.26]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.03it/s, train_loss=1.26]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.03it/s, train_loss=0.91]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.08it/s, train_loss=0.91]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.08it/s, train_loss=0.744]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.05it/s, train_loss=0.744]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.05it/s, train_loss=1.15] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.09it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.09it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.28it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.28it/s, train_loss=0.531]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.51it/s, train_loss=0.531]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:05,  5.51it/s, train_loss=1.76] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.25it/s, train_loss=1.76]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.25it/s, train_loss=0.732]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.37it/s, train_loss=0.732]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.37it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.08it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.08it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=0.807]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.01it/s, train_loss=0.807]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.01it/s, train_loss=0.823]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.86it/s, train_loss=0.823]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.86it/s, train_loss=1]    \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.95it/s, train_loss=1]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.95it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.00it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.00it/s, train_loss=0.643]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.09it/s, train_loss=0.643]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.09it/s, train_loss=0.904]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.07it/s, train_loss=0.904]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.07it/s, train_loss=0.614]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.95it/s, train_loss=0.614]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.95it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.90it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.90it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.96it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.96it/s, train_loss=0.755]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.98it/s, train_loss=0.755]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.98it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.11it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.11it/s, train_loss=0.942]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.24it/s, train_loss=0.942]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.24it/s, train_loss=1.11] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.20it/s, train_loss=1.11]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.20it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.22it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.22it/s, train_loss=0.602]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.19it/s, train_loss=0.602]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.19it/s, train_loss=0.832]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.12it/s, train_loss=0.832]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.12it/s, train_loss=1.17] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.03it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.03it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  5.00it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  5.00it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.20it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.20it/s, train_loss=1.51] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.05it/s, train_loss=1.51]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.05it/s, train_loss=0.976]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.33it/s, train_loss=0.976]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.33it/s, train_loss=0.589]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.37it/s, train_loss=0.589]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.37it/s, train_loss=0.793]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.44it/s, train_loss=0.793]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.44it/s, train_loss=1.15] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.37it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.37it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.32it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.32it/s, train_loss=0.532]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.33it/s, train_loss=0.532]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.33it/s, train_loss=0.655]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.51it/s, train_loss=0.655]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.51it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:23<00:00,  6.30it/s, train_loss=0.442]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 average loss: 0.7424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   7%|▋         | 8/110 [03:23<42:32, 25.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 8 current AUC: 0.9824 current accuracy: 0.7702 best AUC: 0.9868 at epoch: 6\n",
      "----------\n",
      "epoch 9/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.21it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.21it/s, train_loss=1.61] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.64it/s, train_loss=1.61]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.64it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.02it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.02it/s, train_loss=1.12] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.29it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.29it/s, train_loss=0.54]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.07it/s, train_loss=0.54]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.07it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.18it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.18it/s, train_loss=0.7]  \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.22it/s, train_loss=0.7]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.22it/s, train_loss=0.994]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.05it/s, train_loss=0.994]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.05it/s, train_loss=0.591]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.92it/s, train_loss=0.591]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.92it/s, train_loss=1.17] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  4.88it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.88it/s, train_loss=0.998]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.93it/s, train_loss=0.998]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.93it/s, train_loss=0.775]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.10it/s, train_loss=0.775]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.10it/s, train_loss=0.959]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.29it/s, train_loss=0.959]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.29it/s, train_loss=0.36] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.13it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.13it/s, train_loss=0.848]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:19,  5.36it/s, train_loss=0.848]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:19,  5.36it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.12it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.12it/s, train_loss=1.43] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.99it/s, train_loss=1.43]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.99it/s, train_loss=0.48]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.90it/s, train_loss=0.48]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.90it/s, train_loss=0.68]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.04it/s, train_loss=0.68]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.04it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.25it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.25it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.33it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.33it/s, train_loss=0.57] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.27it/s, train_loss=0.57]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.27it/s, train_loss=0.894]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.26it/s, train_loss=0.894]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.26it/s, train_loss=0.822]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.02it/s, train_loss=0.822]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.02it/s, train_loss=0.663]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.90it/s, train_loss=0.663]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.90it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.89it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.89it/s, train_loss=0.661]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:20,  4.70it/s, train_loss=0.661]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:20,  4.70it/s, train_loss=1.01] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.90it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.90it/s, train_loss=0.379]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.79it/s, train_loss=0.379]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.79it/s, train_loss=1.64] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.87it/s, train_loss=1.64]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.87it/s, train_loss=0.922]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.25it/s, train_loss=0.922]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.25it/s, train_loss=1.72] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.08it/s, train_loss=1.72]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.08it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.01it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.01it/s, train_loss=0.35] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.03it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.03it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.14it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.14it/s, train_loss=0.67] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.05it/s, train_loss=0.67]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.05it/s, train_loss=0.475]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.08it/s, train_loss=0.475]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.08it/s, train_loss=0.47] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.91it/s, train_loss=0.47]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.91it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.78it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.78it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:17,  4.62it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.62it/s, train_loss=1.15] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:17,  4.59it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:17,  4.59it/s, train_loss=0.854]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:17,  4.58it/s, train_loss=0.854]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:17,  4.58it/s, train_loss=0.84] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.72it/s, train_loss=0.84]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.72it/s, train_loss=0.432]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.80it/s, train_loss=0.432]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.80it/s, train_loss=1]    \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.12it/s, train_loss=1]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.12it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.27it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.27it/s, train_loss=0.63] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.14it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.14it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.10it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.10it/s, train_loss=0.876]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.12it/s, train_loss=0.876]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.12it/s, train_loss=1.82] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.13it/s, train_loss=1.82]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.13it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.02it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.02it/s, train_loss=0.804]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.98it/s, train_loss=0.804]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.98it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.16it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.16it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.93it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.93it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.01it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.01it/s, train_loss=0.488]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.87it/s, train_loss=0.488]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.87it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.19it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.19it/s, train_loss=0.811]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.21it/s, train_loss=0.811]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.21it/s, train_loss=1.06] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.15it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.15it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.90it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.90it/s, train_loss=1.44] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.09it/s, train_loss=1.44]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.09it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.06it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.06it/s, train_loss=0.808]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.11it/s, train_loss=0.808]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.11it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.27it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.27it/s, train_loss=0.684]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.37it/s, train_loss=0.684]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.37it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.23it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.23it/s, train_loss=0.563]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.39it/s, train_loss=0.563]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.39it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.30it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.30it/s, train_loss=0.813]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.19it/s, train_loss=0.813]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.19it/s, train_loss=0.523]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.20it/s, train_loss=0.523]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.20it/s, train_loss=0.45] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.28it/s, train_loss=0.45]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.28it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.21it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.21it/s, train_loss=0.614]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.12it/s, train_loss=0.614]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.12it/s, train_loss=0.5]  \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.02it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.02it/s, train_loss=0.743]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.06it/s, train_loss=0.743]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.06it/s, train_loss=0.93] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.25it/s, train_loss=0.93]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.25it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.11it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.11it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.14it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.14it/s, train_loss=0.985]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.10it/s, train_loss=0.985]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.10it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.13it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.13it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.95it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.95it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.14it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.14it/s, train_loss=0.888]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.36it/s, train_loss=0.888]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.36it/s, train_loss=0.607]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:06,  5.58it/s, train_loss=0.607]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:06,  5.58it/s, train_loss=0.727]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.53it/s, train_loss=0.727]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.53it/s, train_loss=1.39] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.26it/s, train_loss=1.39]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.26it/s, train_loss=0.711]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.17it/s, train_loss=0.711]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.17it/s, train_loss=0.811]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.23it/s, train_loss=0.811]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.23it/s, train_loss=0.4]  \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.26it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.26it/s, train_loss=0.745]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.13it/s, train_loss=0.745]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.13it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.37it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.37it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.11it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.11it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.03it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.03it/s, train_loss=0.801]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.16it/s, train_loss=0.801]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.16it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.15it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.15it/s, train_loss=0.39] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.16it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.16it/s, train_loss=0.633]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.31it/s, train_loss=0.633]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.31it/s, train_loss=0.795]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.22it/s, train_loss=0.795]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.22it/s, train_loss=0.599]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.13it/s, train_loss=0.599]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.13it/s, train_loss=1.02] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.00it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.00it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.17it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.17it/s, train_loss=0.647]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:19<00:03,  5.30it/s, train_loss=0.647]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.30it/s, train_loss=0.72] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.52it/s, train_loss=0.72]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.52it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.34it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.34it/s, train_loss=0.882]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.45it/s, train_loss=0.882]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.45it/s, train_loss=0.56] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.20it/s, train_loss=0.56]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.20it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:20<00:02,  5.18it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.18it/s, train_loss=0.846]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.13it/s, train_loss=0.846]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.13it/s, train_loss=0.587]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.88it/s, train_loss=0.587]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.88it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.87it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.87it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.79it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.79it/s, train_loss=0.39] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:02,  4.85it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.85it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.89it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.89it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.86it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.86it/s, train_loss=0.531]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.92it/s, train_loss=0.531]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.92it/s, train_loss=1.56] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.04it/s, train_loss=1.56]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.04it/s, train_loss=0.82]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.82it/s, train_loss=0.82]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.82it/s, train_loss=0.794]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=0.794]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=1.22] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.02it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.02it/s, train_loss=0.694]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.03it/s, train_loss=0.694]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.03it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.16it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.16it/s, train_loss=0.655]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 average loss: 0.7067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   8%|▊         | 9/110 [03:47<41:50, 24.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 9 current AUC: 0.9816 current accuracy: 0.8261 best AUC: 0.9868 at epoch: 6\n",
      "----------\n",
      "epoch 10/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  5.01it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  5.01it/s, train_loss=0.41] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.22it/s, train_loss=0.41]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.22it/s, train_loss=0.718]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.05it/s, train_loss=0.718]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.05it/s, train_loss=1.02] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.85it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.85it/s, train_loss=0.809]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.809]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.649]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.88it/s, train_loss=0.649]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.88it/s, train_loss=0.68] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.86it/s, train_loss=0.68]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.86it/s, train_loss=0.508]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.508]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.935]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.13it/s, train_loss=0.935]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.13it/s, train_loss=0.782]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.09it/s, train_loss=0.782]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.09it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.05it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.05it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.19it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.19it/s, train_loss=0.592]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.22it/s, train_loss=0.592]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.22it/s, train_loss=0.49] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.85it/s, train_loss=0.49]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.85it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.92it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.92it/s, train_loss=0.7]  \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.97it/s, train_loss=0.7]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.97it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.02it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.02it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.81it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.81it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.93it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  4.93it/s, train_loss=0.649]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.05it/s, train_loss=0.649]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.05it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.99it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.99it/s, train_loss=0.58] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.19it/s, train_loss=0.58]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.19it/s, train_loss=0.791]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.34it/s, train_loss=0.791]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.34it/s, train_loss=1.36] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.37it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.37it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:17,  5.42it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:17,  5.42it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.19it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.19it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.97it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.97it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.22it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.22it/s, train_loss=1.2]  \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.04it/s, train_loss=1.2]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.04it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.89it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.89it/s, train_loss=0.547]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.08it/s, train_loss=0.547]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.08it/s, train_loss=0.511]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.08it/s, train_loss=0.511]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.08it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.16it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.16it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.15it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.15it/s, train_loss=0.713]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.36it/s, train_loss=0.713]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.36it/s, train_loss=0.972]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.37it/s, train_loss=0.972]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.37it/s, train_loss=0.858]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.23it/s, train_loss=0.858]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.23it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.26it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.26it/s, train_loss=0.897]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.26it/s, train_loss=0.897]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.26it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.34it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.34it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.30it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.30it/s, train_loss=0.856]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.08it/s, train_loss=0.856]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.08it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.00it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.00it/s, train_loss=0.721]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.93it/s, train_loss=0.721]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.93it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.98it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.98it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.93it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.93it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.98it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.98it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.31it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.31it/s, train_loss=0.696]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.35it/s, train_loss=0.696]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.35it/s, train_loss=0.34] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.35it/s, train_loss=0.34]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.35it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.31it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.31it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.16it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.16it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.12it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.12it/s, train_loss=0.766]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.03it/s, train_loss=0.766]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.03it/s, train_loss=0.701]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.02it/s, train_loss=0.701]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.02it/s, train_loss=0.668]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:13,  4.98it/s, train_loss=0.668]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.98it/s, train_loss=0.772]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.10it/s, train_loss=0.772]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.10it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.02it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.02it/s, train_loss=0.65] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.06it/s, train_loss=0.65]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.06it/s, train_loss=0.647]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.08it/s, train_loss=0.647]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.08it/s, train_loss=0.487]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  5.03it/s, train_loss=0.487]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.03it/s, train_loss=0.653]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=0.653]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=0.859]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.00it/s, train_loss=0.859]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.00it/s, train_loss=1.07] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.02it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.02it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.09it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.09it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  5.09it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.09it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.08it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.08it/s, train_loss=1.01] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.21it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.21it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.03it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.03it/s, train_loss=0.847]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.78it/s, train_loss=0.847]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.78it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.76it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.76it/s, train_loss=0.601]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.91it/s, train_loss=0.601]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.91it/s, train_loss=1.11] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.22it/s, train_loss=1.11]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.22it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.98it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.98it/s, train_loss=0.624]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.23it/s, train_loss=0.624]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.23it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.21it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.21it/s, train_loss=0.558]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.97it/s, train_loss=0.558]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.97it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.08it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.08it/s, train_loss=0.635]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.94it/s, train_loss=0.635]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.94it/s, train_loss=0.714]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.70it/s, train_loss=0.714]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.70it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.00it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.00it/s, train_loss=0.58] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.04it/s, train_loss=0.58]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.04it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.27it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.27it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.39it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.39it/s, train_loss=0.882]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.34it/s, train_loss=0.882]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.34it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.21it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.21it/s, train_loss=0.488]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.10it/s, train_loss=0.488]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.10it/s, train_loss=0.862]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.93it/s, train_loss=0.862]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.93it/s, train_loss=0.645]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.79it/s, train_loss=0.645]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.79it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.68it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.68it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.72it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.72it/s, train_loss=1.18] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.87it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.87it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.95it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.95it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.90it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.90it/s, train_loss=0.764]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.80it/s, train_loss=0.764]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.80it/s, train_loss=0.596]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.91it/s, train_loss=0.596]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.91it/s, train_loss=0.971]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.81it/s, train_loss=0.971]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.81it/s, train_loss=0.864]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.99it/s, train_loss=0.864]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.99it/s, train_loss=0.66] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.91it/s, train_loss=0.66]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.91it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.95it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.95it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.01it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.01it/s, train_loss=0.797]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.05it/s, train_loss=0.797]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.05it/s, train_loss=0.813]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.87it/s, train_loss=0.813]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.87it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.64it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.64it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.92it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.92it/s, train_loss=1.08] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.97it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.97it/s, train_loss=0.704]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.09it/s, train_loss=0.704]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.09it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.17it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.17it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.10it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.10it/s, train_loss=0.778]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.94it/s, train_loss=0.778]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.94it/s, train_loss=0.459]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.90it/s, train_loss=0.459]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.90it/s, train_loss=0.634]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.634]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.574]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.03it/s, train_loss=0.574]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.03it/s, train_loss=0.698]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.36it/s, train_loss=0.698]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.36it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.13it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.13it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.08it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.08it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.28it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.28it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.11it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.11it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.07it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.07it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.97it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.97it/s, train_loss=0.593]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.08it/s, train_loss=0.593]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=1.75] \n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.83it/s, train_loss=1.75]\n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 average loss: 0.6237\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   9%|▉         | 10/110 [04:13<41:58, 25.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 10 current AUC: 0.9869 current accuracy: 0.8385 best AUC: 0.9869 at epoch: 10\n",
      "----------\n",
      "epoch 11/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.68it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.68it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.40it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.40it/s, train_loss=0.783]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.47it/s, train_loss=0.783]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.47it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.10it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.10it/s, train_loss=0.439]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.14it/s, train_loss=0.439]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.14it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.26it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.26it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.18it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.18it/s, train_loss=1.14] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.69it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.69it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.91it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.91it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:23,  4.86it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.86it/s, train_loss=1.42] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.01it/s, train_loss=1.42]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.01it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.08it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.08it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.04it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.04it/s, train_loss=0.747]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.92it/s, train_loss=0.747]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.92it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:22,  4.86it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.86it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.96it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.96it/s, train_loss=0.627]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:22,  4.75it/s, train_loss=0.627]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:22,  4.75it/s, train_loss=0.596]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.83it/s, train_loss=0.596]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.83it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.05it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.05it/s, train_loss=0.821]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.14it/s, train_loss=0.821]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.14it/s, train_loss=0.856]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.12it/s, train_loss=0.856]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.12it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.99it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.99it/s, train_loss=1.04] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.06it/s, train_loss=1.04]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:19,  5.06it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.79it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.79it/s, train_loss=0.746]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.98it/s, train_loss=0.746]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.98it/s, train_loss=0.49] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.99it/s, train_loss=0.49]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.99it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.06it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.06it/s, train_loss=0.587]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.14it/s, train_loss=0.587]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.14it/s, train_loss=1.09] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.17it/s, train_loss=1.09]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.17it/s, train_loss=0.663]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.15it/s, train_loss=0.663]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.15it/s, train_loss=0.452]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.78it/s, train_loss=0.452]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.78it/s, train_loss=0.784]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.89it/s, train_loss=0.784]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.89it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.99it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.99it/s, train_loss=1.32] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.92it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.92it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.82it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.82it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.96it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.96it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.08it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.08it/s, train_loss=1]    \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.20it/s, train_loss=1]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.20it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.11it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.11it/s, train_loss=0.725]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.84it/s, train_loss=0.725]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.84it/s, train_loss=0.74] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.03it/s, train_loss=0.74]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.03it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.84it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.84it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.90it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  4.90it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.76it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.76it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:16,  4.64it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:16,  4.64it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.81it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.81it/s, train_loss=0.439]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.92it/s, train_loss=0.439]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.92it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.01it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  5.01it/s, train_loss=0.583]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.06it/s, train_loss=0.583]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.06it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.06it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.06it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.18it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.18it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.06it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.06it/s, train_loss=1.07] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.12it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  5.12it/s, train_loss=0.882]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.04it/s, train_loss=0.882]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.04it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.89it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.89it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.91it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.91it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.79] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.31it/s, train_loss=0.79]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:11,  5.31it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.02it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.02it/s, train_loss=0.806]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.01it/s, train_loss=0.806]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.01it/s, train_loss=1.04] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=1.04]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.05it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.05it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.14it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.14it/s, train_loss=0.609]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.41it/s, train_loss=0.609]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.41it/s, train_loss=0.523]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.20it/s, train_loss=0.523]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.20it/s, train_loss=1.61] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=1.61]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=0.661]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.25it/s, train_loss=0.661]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.25it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.02it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.02it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.84it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.84it/s, train_loss=2.1]  \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.79it/s, train_loss=2.1]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.79it/s, train_loss=0.662]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.82it/s, train_loss=0.662]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.82it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.80it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.80it/s, train_loss=0.758]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.95it/s, train_loss=0.758]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  4.95it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.83it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.83it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.79it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.79it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.87it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.87it/s, train_loss=1.08] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.05it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.05it/s, train_loss=0.894]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.20it/s, train_loss=0.894]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.20it/s, train_loss=0.854]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.22it/s, train_loss=0.854]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.22it/s, train_loss=0.771]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.91it/s, train_loss=0.771]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.91it/s, train_loss=0.646]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.97it/s, train_loss=0.646]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.97it/s, train_loss=0.713]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.94it/s, train_loss=0.713]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.94it/s, train_loss=0.475]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.09it/s, train_loss=0.475]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  5.09it/s, train_loss=0.847]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.90it/s, train_loss=0.847]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.90it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.02it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.02it/s, train_loss=0.912]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.29it/s, train_loss=0.912]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.29it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.29it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.29it/s, train_loss=0.558]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.98it/s, train_loss=0.558]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.98it/s, train_loss=1.43] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.98it/s, train_loss=1.43]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.98it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.00it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.00it/s, train_loss=0.63] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.97it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.97it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.09it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.09it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.17it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.17it/s, train_loss=1.34] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.20it/s, train_loss=1.34]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.20it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.30it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.30it/s, train_loss=0.595]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.03it/s, train_loss=0.595]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.03it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.11it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.11it/s, train_loss=0.764]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.10it/s, train_loss=0.764]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.10it/s, train_loss=0.713]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.08it/s, train_loss=0.713]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.08it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.99it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.99it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.35it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.35it/s, train_loss=0.765]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.15it/s, train_loss=0.765]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.15it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.27it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.27it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.05it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.05it/s, train_loss=1.14] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.06it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.06it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.02it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.02it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.78it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.78it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.86it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.86it/s, train_loss=0.86] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.76it/s, train_loss=0.86]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.76it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.84it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.84it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.81it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.81it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.65it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.65it/s, train_loss=0.664]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.89it/s, train_loss=0.664]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.89it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.10it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.10it/s, train_loss=0.563]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.22it/s, train_loss=0.563]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.22it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.54it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.54it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.31it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.31it/s, train_loss=1.08] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.03it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.03it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.98it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.98it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=0.272]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 average loss: 0.6332\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|█         | 11/110 [04:39<41:59, 25.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 11 current AUC: 0.9896 current accuracy: 0.8385 best AUC: 0.9896 at epoch: 11\n",
      "----------\n",
      "epoch 12/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.56]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.91it/s, train_loss=0.56]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.91it/s, train_loss=0.94]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.16it/s, train_loss=0.94]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.16it/s, train_loss=0.754]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.19it/s, train_loss=0.754]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.19it/s, train_loss=0.593]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.17it/s, train_loss=0.593]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.17it/s, train_loss=0.967]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.15it/s, train_loss=0.967]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.15it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.92it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.92it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.09it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.09it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.12it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.12it/s, train_loss=0.44] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.19it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.19it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.17it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.17it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.04it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.04it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.97it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.97it/s, train_loss=0.692]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.06it/s, train_loss=0.692]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.06it/s, train_loss=1.09] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.01it/s, train_loss=1.09]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.01it/s, train_loss=0.508]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.23it/s, train_loss=0.508]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.23it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.09it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.09it/s, train_loss=0.802]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.39it/s, train_loss=0.802]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.39it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.97it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.97it/s, train_loss=0.628]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.94it/s, train_loss=0.628]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.94it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.07it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.07it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.98it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.98it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=0.656]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.91it/s, train_loss=0.656]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.91it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.04it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.04it/s, train_loss=0.954]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.16it/s, train_loss=0.954]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.16it/s, train_loss=0.775]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.97it/s, train_loss=0.775]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.97it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.94it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.94it/s, train_loss=0.559]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.87it/s, train_loss=0.559]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.87it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.98it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.98it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.98it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.98it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.10it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.10it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.06it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.06it/s, train_loss=0.74] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.01it/s, train_loss=0.74]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.01it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.17it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.17it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.99it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.99it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.05it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.05it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.01it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.01it/s, train_loss=0.5]  \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.10it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.10it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.25it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.25it/s, train_loss=0.977]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.41it/s, train_loss=0.977]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.41it/s, train_loss=0.893]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.37it/s, train_loss=0.893]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.37it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.22it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.22it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.05it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.05it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.98it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.98it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.99it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.99it/s, train_loss=1.25] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=1.25]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=0.737]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.10it/s, train_loss=0.737]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.10it/s, train_loss=0.964]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.15it/s, train_loss=0.964]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.15it/s, train_loss=0.636]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.00it/s, train_loss=0.636]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.00it/s, train_loss=1.19] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.43it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.43it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.19it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.19it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.24it/s, train_loss=1.19]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.24it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.33it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.33it/s, train_loss=0.631]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.20it/s, train_loss=0.631]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.20it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.16it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.16it/s, train_loss=0.689]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.07it/s, train_loss=0.689]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.07it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.08it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.08it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.31it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.31it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.16it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.16it/s, train_loss=1.5]  \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  5.02it/s, train_loss=1.5]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.02it/s, train_loss=1.72]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.99it/s, train_loss=1.72]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.99it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.04it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.04it/s, train_loss=0.751]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.91it/s, train_loss=0.751]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.91it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.95it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.95it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  4.88it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.88it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=1.38] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.87it/s, train_loss=1.38]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.87it/s, train_loss=0.862]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.90it/s, train_loss=0.862]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.90it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.89it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.89it/s, train_loss=0.517]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  4.99it/s, train_loss=0.517]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.99it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.86it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.86it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.79it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.79it/s, train_loss=0.539]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.92it/s, train_loss=0.539]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.92it/s, train_loss=0.487]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.85it/s, train_loss=0.487]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.85it/s, train_loss=0.791]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.94it/s, train_loss=0.791]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.94it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.99it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.99it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.96it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.96it/s, train_loss=0.688]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.21it/s, train_loss=0.688]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.21it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.15it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.15it/s, train_loss=0.667]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.88it/s, train_loss=0.667]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.88it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.98it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.98it/s, train_loss=0.683]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.72it/s, train_loss=0.683]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.72it/s, train_loss=0.675]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:08,  4.70it/s, train_loss=0.675]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:08,  4.70it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.84it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.84it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.86it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.86it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.92it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.92it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.04it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.04it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.05it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.05it/s, train_loss=0.619]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.98it/s, train_loss=0.619]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.98it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.13it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.13it/s, train_loss=1.02] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.95it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.95it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.00it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.00it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.16it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.16it/s, train_loss=0.45] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.27it/s, train_loss=0.45]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.27it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.36it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.36it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.28it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.28it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.09it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.09it/s, train_loss=0.64] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.92it/s, train_loss=0.64]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.92it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.00it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.00it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.87it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.87it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.92it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.92it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.03it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.03it/s, train_loss=0.602]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.05it/s, train_loss=0.602]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.05it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.74it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.74it/s, train_loss=0.724]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.88it/s, train_loss=0.724]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.88it/s, train_loss=0.602]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.86it/s, train_loss=0.602]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.86it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.90it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.90it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.70it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.70it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.70it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.70it/s, train_loss=0.684]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.94it/s, train_loss=0.684]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.94it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.71it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.71it/s, train_loss=0.484]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.66it/s, train_loss=0.484]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.66it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.84it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.84it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.06it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.06it/s, train_loss=1.84] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.08it/s, train_loss=1.84]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.08it/s, train_loss=1.13]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.89it/s, train_loss=1.13]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.89it/s, train_loss=1]   \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.75it/s, train_loss=1]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.75it/s, train_loss=0.696]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.51it/s, train_loss=0.696]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 average loss: 0.6044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  11%|█         | 12/110 [05:04<41:16, 25.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 12 current AUC: 0.9894 current accuracy: 0.8820 best AUC: 0.9896 at epoch: 11\n",
      "----------\n",
      "epoch 13/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.85it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.85it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.71it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.71it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.78it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.78it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.24it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.24it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.29it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.29it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.32it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.32it/s, train_loss=0.5]  \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.10it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.10it/s, train_loss=0.676]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.85it/s, train_loss=0.676]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.85it/s, train_loss=0.929]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.90it/s, train_loss=0.929]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.90it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.90it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.90it/s, train_loss=0.741]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.18it/s, train_loss=0.741]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.18it/s, train_loss=0.652]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.10it/s, train_loss=0.652]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.10it/s, train_loss=0.599]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.19it/s, train_loss=0.599]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.19it/s, train_loss=0.632]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.12it/s, train_loss=0.632]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.12it/s, train_loss=0.69] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.07it/s, train_loss=0.69]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.07it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.03it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.03it/s, train_loss=0.52]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.11it/s, train_loss=0.52]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.11it/s, train_loss=0.724]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.10it/s, train_loss=0.724]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.10it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.23it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.23it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.29it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.29it/s, train_loss=2.03] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.14it/s, train_loss=2.03]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.14it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.94it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.94it/s, train_loss=0.73] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.14it/s, train_loss=0.73]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.14it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.98it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.98it/s, train_loss=0.79]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.97it/s, train_loss=0.79]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.97it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.10it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.10it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.90it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.90it/s, train_loss=0.487]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.89it/s, train_loss=0.487]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.89it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.86it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.86it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:19,  4.68it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:19,  4.68it/s, train_loss=0.77] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:20,  4.51it/s, train_loss=0.77]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:20,  4.51it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:19,  4.60it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:19,  4.60it/s, train_loss=0.944]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:19,  4.66it/s, train_loss=0.944]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:19,  4.66it/s, train_loss=0.636]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.94it/s, train_loss=0.636]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  4.94it/s, train_loss=0.649]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.01it/s, train_loss=0.649]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.01it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.12it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.12it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.21it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.21it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.16it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.16it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.19it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.19it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.05it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.05it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.33it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.33it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.13it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.13it/s, train_loss=0.754]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.25it/s, train_loss=0.754]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.25it/s, train_loss=0.5]  \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.14it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.14it/s, train_loss=0.924]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.30it/s, train_loss=0.924]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.30it/s, train_loss=0.765]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.25it/s, train_loss=0.765]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.25it/s, train_loss=0.622]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=0.622]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.05it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.05it/s, train_loss=0.542]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.08it/s, train_loss=0.542]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.08it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.15it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.15it/s, train_loss=1.26] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.90it/s, train_loss=1.26]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.90it/s, train_loss=0.552]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.08it/s, train_loss=0.552]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.08it/s, train_loss=1.73] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.24it/s, train_loss=1.73]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.24it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.19it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.19it/s, train_loss=0.703]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.11it/s, train_loss=0.703]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.11it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.21it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.21it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.11it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.11it/s, train_loss=0.473]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.28it/s, train_loss=0.473]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.28it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.28it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.28it/s, train_loss=0.58] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.16it/s, train_loss=0.58]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.16it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.26it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.26it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.25it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.25it/s, train_loss=0.708]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.06it/s, train_loss=0.708]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.06it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.13it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.13it/s, train_loss=0.629]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.15it/s, train_loss=0.629]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.15it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.30it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.30it/s, train_loss=0.769]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.34it/s, train_loss=0.769]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.34it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.10it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.10it/s, train_loss=0.935]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.08it/s, train_loss=0.935]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.08it/s, train_loss=0.51] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.19it/s, train_loss=0.51]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.19it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  4.99it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.99it/s, train_loss=0.24] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.18it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.18it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.01it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.01it/s, train_loss=0.599]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.09it/s, train_loss=0.599]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.09it/s, train_loss=1.32] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.96it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.96it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  4.87it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.87it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.92it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.92it/s, train_loss=0.829]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.11it/s, train_loss=0.829]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.11it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.15it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.15it/s, train_loss=0.483]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.11it/s, train_loss=0.483]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.11it/s, train_loss=0.599]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.98it/s, train_loss=0.599]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.98it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.97it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.97it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.84it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.84it/s, train_loss=0.608]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.82it/s, train_loss=0.608]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.82it/s, train_loss=0.44] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.95it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.95it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.95it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.95it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.84it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.84it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.77it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.77it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.90it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.90it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.84it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.84it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.84it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.84it/s, train_loss=1.03] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.85it/s, train_loss=1.03]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.85it/s, train_loss=1.53]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.79it/s, train_loss=1.53]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.79it/s, train_loss=0.947]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.24it/s, train_loss=0.947]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.24it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.06it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.06it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.10it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.10it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.99it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.99it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.44] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.85it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.85it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.03it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.03it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.13it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.13it/s, train_loss=0.764]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.07it/s, train_loss=0.764]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.07it/s, train_loss=0.896]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.896]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=1.07] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.97it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.97it/s, train_loss=0.577]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.04it/s, train_loss=0.577]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.04it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.00it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.00it/s, train_loss=0.851]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.86it/s, train_loss=0.851]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.86it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.12it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.12it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.03it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.03it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.01it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.01it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.12it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.12it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.89it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.89it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.99it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.99it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.07it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.07it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.98it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.98it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.21it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.21it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.93it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.93it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.93it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.93it/s, train_loss=0.588]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.08it/s, train_loss=0.588]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.08it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.94it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.94it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.85it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.85it/s, train_loss=0.601]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.66it/s, train_loss=0.601]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 average loss: 0.5572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  12%|█▏        | 13/110 [05:29<40:36, 25.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 13 current AUC: 0.9896 current accuracy: 0.8696 best AUC: 0.9896 at epoch: 11\n",
      "----------\n",
      "epoch 14/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.802]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.08it/s, train_loss=0.802]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.08it/s, train_loss=0.583]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.93it/s, train_loss=0.583]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.93it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.11it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.11it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.26it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.26it/s, train_loss=1.02] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.05it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.05it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.01it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.01it/s, train_loss=0.611]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.05it/s, train_loss=0.611]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.05it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.87it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.87it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.08it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.08it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:20,  5.36it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:20,  5.36it/s, train_loss=0.647]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.31it/s, train_loss=0.647]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.31it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.94it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.94it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.79it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.79it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.71it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.71it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  4.98it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.98it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.18it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.18it/s, train_loss=0.649]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.28it/s, train_loss=0.649]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.28it/s, train_loss=0.586]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.97it/s, train_loss=0.586]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.97it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.13it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.13it/s, train_loss=0.883]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.11it/s, train_loss=0.883]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.11it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.21it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.21it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.10it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.10it/s, train_loss=0.629]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.15it/s, train_loss=0.629]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.15it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.23it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.23it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.03it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.03it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.82it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.82it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.85it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.85it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.95it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.95it/s, train_loss=0.799]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.96it/s, train_loss=0.799]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.96it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.12it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.12it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.30it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.30it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.35it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.35it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.32it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.32it/s, train_loss=0.459]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.35it/s, train_loss=0.459]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.35it/s, train_loss=0.777]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.36it/s, train_loss=0.777]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.36it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.13it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.13it/s, train_loss=0.983]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.07it/s, train_loss=0.983]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.07it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.11it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.11it/s, train_loss=0.39] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.09it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.09it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.95it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.95it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.11it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.11it/s, train_loss=0.552]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.99it/s, train_loss=0.552]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.99it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.05it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.05it/s, train_loss=0.956]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.15it/s, train_loss=0.956]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.15it/s, train_loss=0.639]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.94it/s, train_loss=0.639]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.94it/s, train_loss=0.731]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.94it/s, train_loss=0.731]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.94it/s, train_loss=0.908]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.07it/s, train_loss=0.908]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.07it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.13it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.13it/s, train_loss=3.27] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.40it/s, train_loss=3.27]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.40it/s, train_loss=0.867]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.15it/s, train_loss=0.867]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.15it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.97it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.97it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.83it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.83it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.93it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.93it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.74it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.74it/s, train_loss=0.926]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:14,  4.71it/s, train_loss=0.926]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:14,  4.71it/s, train_loss=0.37] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.99it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.99it/s, train_loss=0.6] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.88it/s, train_loss=0.6]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.88it/s, train_loss=0.921]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.05it/s, train_loss=0.921]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.05it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.545]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.92it/s, train_loss=0.545]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.92it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.02it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.02it/s, train_loss=0.805]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.15it/s, train_loss=0.805]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.15it/s, train_loss=1.14] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.84it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.84it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.99it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.99it/s, train_loss=0.752]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.98it/s, train_loss=0.752]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.98it/s, train_loss=1.01] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.04it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.04it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.99it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.99it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.83it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.83it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.09it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.09it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.87it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.87it/s, train_loss=0.52] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.82it/s, train_loss=0.52]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.82it/s, train_loss=0.426]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.83it/s, train_loss=0.426]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.83it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.67it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.67it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.75it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.75it/s, train_loss=0.634]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.85it/s, train_loss=0.634]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.85it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.93it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.93it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.82it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.82it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.71it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.71it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.89it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.89it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.93it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.93it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.02it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.02it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=0.907]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.27it/s, train_loss=0.907]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.27it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.16it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.16it/s, train_loss=0.54] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.12it/s, train_loss=0.54]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.12it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.78it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.78it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.86it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.86it/s, train_loss=0.646]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.89it/s, train_loss=0.646]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.89it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.13it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.13it/s, train_loss=0.882]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.86it/s, train_loss=0.882]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.86it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.06it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.06it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.97it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.97it/s, train_loss=0.674]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.83it/s, train_loss=0.674]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.83it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.03it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.03it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.05it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.05it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.05it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.05it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.18it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.18it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.01it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.01it/s, train_loss=0.551]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.06it/s, train_loss=0.551]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.06it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.16it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.16it/s, train_loss=0.36] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.09it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.09it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.15it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.15it/s, train_loss=0.809]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.26it/s, train_loss=0.809]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.26it/s, train_loss=0.814]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.18it/s, train_loss=0.814]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.18it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.91it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.91it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.85it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.85it/s, train_loss=0.652]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.79it/s, train_loss=0.652]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.79it/s, train_loss=1.07] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.91it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.91it/s, train_loss=0.48]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.85it/s, train_loss=0.48]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.85it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.91it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.91it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.19it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.19it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.44it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.44it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.27it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.27it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.02it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.02it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.97it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.97it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.92it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.92it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.95it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.95it/s, train_loss=0.372]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.02it/s, train_loss=0.372]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.02it/s, train_loss=0.426]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.03it/s, train_loss=0.426]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.03it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.76it/s, train_loss=0.369]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 average loss: 0.5366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  13%|█▎        | 14/110 [05:54<40:02, 25.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 14 current AUC: 0.9880 current accuracy: 0.8509 best AUC: 0.9896 at epoch: 11\n",
      "----------\n",
      "epoch 15/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.601]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.66it/s, train_loss=0.601]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.66it/s, train_loss=0.886]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.68it/s, train_loss=0.886]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.68it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.18it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.18it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.31it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.31it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:20,  5.62it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:20,  5.62it/s, train_loss=0.928]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:20,  5.61it/s, train_loss=0.928]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:20,  5.61it/s, train_loss=1.02] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.34it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.34it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.00it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.00it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  4.98it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.98it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.93it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.93it/s, train_loss=0.753]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=0.753]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=0.553]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.05it/s, train_loss=0.553]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.05it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.36it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.36it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.19it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.19it/s, train_loss=1.13] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.02it/s, train_loss=1.13]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.02it/s, train_loss=0.761]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.86it/s, train_loss=0.761]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.86it/s, train_loss=0.582]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.00it/s, train_loss=0.582]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.00it/s, train_loss=0.46] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.06it/s, train_loss=0.46]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.06it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.13it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.13it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.11it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.11it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.06it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.06it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.99it/s, train_loss=0.626]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.99it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.98it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.98it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.85it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.85it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.96it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.96it/s, train_loss=0.785]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.15it/s, train_loss=0.785]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.15it/s, train_loss=0.745]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.00it/s, train_loss=0.745]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.00it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.94it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.94it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.86it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.86it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.83it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.83it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.94it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.94it/s, train_loss=0.557]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.97it/s, train_loss=0.557]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.97it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.91it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.91it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.95it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.95it/s, train_loss=0.766]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.87it/s, train_loss=0.766]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.87it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.08it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.08it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.05it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.05it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.12it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.12it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.03it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.03it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.13it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.13it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.24it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.24it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.08it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.08it/s, train_loss=0.5]  \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.86it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.86it/s, train_loss=0.556]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.94it/s, train_loss=0.556]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.94it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.82it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.82it/s, train_loss=0.715]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.94it/s, train_loss=0.715]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.94it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.91it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.91it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.88it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.88it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.93it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.93it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.97it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.97it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.12it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.12it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.14it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.14it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.30it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.30it/s, train_loss=0.54] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.26it/s, train_loss=0.54]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.26it/s, train_loss=0.484]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.09it/s, train_loss=0.484]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.09it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.06it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.06it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.21it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.21it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.31it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.31it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.38it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.38it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.36it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.36it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.45it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.45it/s, train_loss=0.876]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.39it/s, train_loss=0.876]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.39it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.17it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.17it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.40it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.40it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.42it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.42it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.35it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.35it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.13it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.13it/s, train_loss=0.683]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.34it/s, train_loss=0.683]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.34it/s, train_loss=0.595]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  5.09it/s, train_loss=0.595]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.09it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.02it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.02it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.98it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.98it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.95it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.95it/s, train_loss=1.01] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  4.81it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.81it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.86it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.86it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.02it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.02it/s, train_loss=0.997]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.11it/s, train_loss=0.997]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.11it/s, train_loss=0.561]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.19it/s, train_loss=0.561]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.19it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.22it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.22it/s, train_loss=1.12] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.09it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.09it/s, train_loss=1.04]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.96it/s, train_loss=1.04]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.96it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.13it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.13it/s, train_loss=0.459]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.02it/s, train_loss=0.459]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.02it/s, train_loss=0.95] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  4.78it/s, train_loss=0.95]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.78it/s, train_loss=0.866]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.92it/s, train_loss=0.866]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.92it/s, train_loss=0.568]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.85it/s, train_loss=0.568]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.85it/s, train_loss=0.84] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.08it/s, train_loss=0.84]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.08it/s, train_loss=0.88]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.16it/s, train_loss=0.88]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.16it/s, train_loss=0.559]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.79it/s, train_loss=0.559]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.79it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.88it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.88it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.94it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.94it/s, train_loss=0.655]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.84it/s, train_loss=0.655]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.84it/s, train_loss=0.89] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.84it/s, train_loss=0.89]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.84it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.91it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.91it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.86it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.86it/s, train_loss=0.812]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.69it/s, train_loss=0.812]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.69it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.92it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.92it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.06it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.06it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.00it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.00it/s, train_loss=0.755]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  5.00it/s, train_loss=0.755]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  5.00it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.95it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.95it/s, train_loss=0.58] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.03it/s, train_loss=0.58]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.03it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.12it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.12it/s, train_loss=0.852]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.31it/s, train_loss=0.852]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.31it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.18it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.18it/s, train_loss=0.793]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.25it/s, train_loss=0.793]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.25it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.04it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.04it/s, train_loss=0.542]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.98it/s, train_loss=0.542]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.98it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.87it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.87it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.90it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.90it/s, train_loss=0.607]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.72it/s, train_loss=0.607]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.72it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.94it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.94it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.89it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.89it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.99it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.99it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.11it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.11it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.20it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.20it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.44it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.44it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.31it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.31it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.24it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.24it/s, train_loss=0.46] \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 average loss: 0.4953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  14%|█▎        | 15/110 [06:18<39:26, 24.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 15 current AUC: 0.9870 current accuracy: 0.8820 best AUC: 0.9896 at epoch: 11\n",
      "----------\n",
      "epoch 16/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.86it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.86it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.88it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.88it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.07it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.07it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.07it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.07it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.04it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.04it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.98it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.98it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.18it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.18it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.12it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.12it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.08it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.08it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.25it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.25it/s, train_loss=1.11] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.20it/s, train_loss=1.11]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.20it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.06it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.06it/s, train_loss=0.379]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.71it/s, train_loss=0.379]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.71it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.69it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.69it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.76it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.76it/s, train_loss=1.51] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.90it/s, train_loss=1.51]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.90it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.08it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.08it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.10it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.10it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.99it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.99it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.07it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.07it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.93it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.93it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.01it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.01it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.06it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.06it/s, train_loss=0.572]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.14it/s, train_loss=0.572]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.14it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.15it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.15it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.30it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.30it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.37it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.37it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:16,  5.49it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:16,  5.49it/s, train_loss=0.919]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:16,  5.56it/s, train_loss=0.919]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:16,  5.56it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:16,  5.61it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:16,  5.61it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:15,  5.63it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:15,  5.63it/s, train_loss=0.877]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.56it/s, train_loss=0.877]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.56it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.47it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.47it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.10it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.10it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.12it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.12it/s, train_loss=0.763]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.08it/s, train_loss=0.763]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.08it/s, train_loss=1.02] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.19it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.19it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.43it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.43it/s, train_loss=1.12] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.30it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.30it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:07<00:15,  5.36it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.36it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.17it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.17it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.02it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.02it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.86it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.86it/s, train_loss=0.887]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.84it/s, train_loss=0.887]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.84it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:15,  5.03it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.03it/s, train_loss=0.656]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.85it/s, train_loss=0.656]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.85it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.86it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.86it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.88it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.88it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.91it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.91it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:14,  5.06it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.06it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.92it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.92it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.28it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.28it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.20it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.20it/s, train_loss=0.946]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.11it/s, train_loss=0.946]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.11it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.79it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.79it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.83it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.83it/s, train_loss=0.555]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:13,  4.76it/s, train_loss=0.555]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:13,  4.76it/s, train_loss=1.15] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.83it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.83it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.97it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.97it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.03it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.03it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.04it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.04it/s, train_loss=0.765]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.03it/s, train_loss=0.765]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.03it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.01it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.01it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.13it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.13it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.31it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.31it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.11it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.11it/s, train_loss=1.11] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.32it/s, train_loss=1.11]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.32it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.16it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.16it/s, train_loss=0.59] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.00it/s, train_loss=0.59]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.00it/s, train_loss=0.737]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.84it/s, train_loss=0.737]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.84it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.90it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.90it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.15it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.15it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.31it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.31it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.07it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.07it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.94it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.94it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.18it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.18it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.98it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.98it/s, train_loss=1.06] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.03it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.03it/s, train_loss=0.698]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.21it/s, train_loss=0.698]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.21it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.08it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.08it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.25it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.25it/s, train_loss=0.761]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.19it/s, train_loss=0.761]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.19it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.09it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.09it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.04it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.04it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.12it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.12it/s, train_loss=0.39] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.34it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.34it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.05it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.05it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.01it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.01it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.18it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.18it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.04it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.04it/s, train_loss=1.02] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.08it/s, train_loss=1.02]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.08it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.02it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.02it/s, train_loss=1.17] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.16it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.16it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.10it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.10it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.19it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.19it/s, train_loss=0.927]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.12it/s, train_loss=0.927]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.12it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.99it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.99it/s, train_loss=0.456]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.98it/s, train_loss=0.456]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.98it/s, train_loss=0.548]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.548]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.698]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.99it/s, train_loss=0.698]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.99it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.02it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.02it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.02it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.02it/s, train_loss=0.558]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.09it/s, train_loss=0.558]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.09it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.15it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.15it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.03it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.03it/s, train_loss=0.669]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.10it/s, train_loss=0.669]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.10it/s, train_loss=0.587]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.09it/s, train_loss=0.587]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.09it/s, train_loss=1.27] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.02it/s, train_loss=1.27]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.02it/s, train_loss=0.5] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.07it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.07it/s, train_loss=0.753]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=0.753]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=1.28] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.15it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.15it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.96it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.96it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.06it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.06it/s, train_loss=0.651]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.05it/s, train_loss=0.651]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.05it/s, train_loss=0.54] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.12it/s, train_loss=0.54]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.12it/s, train_loss=0.82]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.19it/s, train_loss=0.82]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.19it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.07it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.07it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.08it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.08it/s, train_loss=0.703]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 average loss: 0.5136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  15%|█▍        | 16/110 [06:43<38:49, 24.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 16 current AUC: 0.9874 current accuracy: 0.8447 best AUC: 0.9896 at epoch: 11\n",
      "----------\n",
      "epoch 17/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.21it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.21it/s, train_loss=1.29] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.10it/s, train_loss=1.29]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.10it/s, train_loss=0.724]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.30it/s, train_loss=0.724]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.30it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.25it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.25it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.08it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.08it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.04it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.04it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.91it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.91it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.02it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.02it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  4.90it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.90it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.81it/s, train_loss=0.679]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.81it/s, train_loss=0.886]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.87it/s, train_loss=0.886]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.87it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.09it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.09it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.22it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.22it/s, train_loss=0.508]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.09it/s, train_loss=0.508]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.09it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.18it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.18it/s, train_loss=0.864]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.27it/s, train_loss=0.864]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.27it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.99it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.99it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.02it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.02it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.20it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.20it/s, train_loss=0.571]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.571]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.03it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.03it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.19it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.19it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.14it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.14it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:20,  4.81it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.81it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.92it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.92it/s, train_loss=0.48] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.48]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.97it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.97it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.09it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.09it/s, train_loss=0.689]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.20it/s, train_loss=0.689]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.20it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.19it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.19it/s, train_loss=0.37] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.09it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.09it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.20it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.20it/s, train_loss=1.07] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.92it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.92it/s, train_loss=0.747]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.99it/s, train_loss=0.747]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.99it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.91it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.91it/s, train_loss=0.737]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  5.00it/s, train_loss=0.737]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  5.00it/s, train_loss=0.39] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.47it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.47it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.42it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.42it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:14,  5.53it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:14,  5.53it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.25it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.25it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.18it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.18it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.30it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.30it/s, train_loss=0.806]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.22it/s, train_loss=0.806]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.22it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.00it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.00it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.06it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.06it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.89it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.89it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.84it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.84it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.02it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.02it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.06it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.06it/s, train_loss=1.05] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.20it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.20it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.21it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.21it/s, train_loss=0.566]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.33it/s, train_loss=0.566]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.33it/s, train_loss=1.06] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.44it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.44it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.49it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.49it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.42it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.42it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.34it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.34it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.08it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.08it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.09it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.09it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.92it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.92it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  4.82it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.82it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.94it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.94it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.95it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.95it/s, train_loss=0.508]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.16it/s, train_loss=0.508]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.16it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.31it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.31it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.20it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.20it/s, train_loss=1.01] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.91it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.91it/s, train_loss=0.631]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.87it/s, train_loss=0.631]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.87it/s, train_loss=0.656]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.98it/s, train_loss=0.656]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.98it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.91it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.91it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  4.78it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.78it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.67it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.67it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.85it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.85it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.99it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.99it/s, train_loss=0.677]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.91it/s, train_loss=0.677]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.91it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  4.97it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.97it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.03it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.03it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.01it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.01it/s, train_loss=0.591]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.83it/s, train_loss=0.591]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.83it/s, train_loss=1.32] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.07it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.07it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.00it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.00it/s, train_loss=0.991]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.04it/s, train_loss=0.991]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.04it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.34it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.34it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.551]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.12it/s, train_loss=0.551]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.12it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  4.99it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.99it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.96it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.96it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.89it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.89it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.86it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.86it/s, train_loss=0.966]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.79it/s, train_loss=0.966]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.79it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.79it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.79it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.96it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.96it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.94it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.94it/s, train_loss=0.616]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.95it/s, train_loss=0.616]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.95it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.95it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.95it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.09it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.09it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.03it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.03it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.04it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.04it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.90it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.90it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.79it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.79it/s, train_loss=0.638]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.07it/s, train_loss=0.638]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.07it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.31it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.31it/s, train_loss=0.517]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.51it/s, train_loss=0.517]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.51it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.54it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.54it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.61it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.61it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.13it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.13it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.07it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.07it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.08it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.08it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.08it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.08it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.03it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.03it/s, train_loss=0.865]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.12it/s, train_loss=0.865]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.12it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.26it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.26it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.18it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.18it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.28it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.28it/s, train_loss=0.726]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.49it/s, train_loss=0.726]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.49it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.30it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.30it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.39] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.15it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.15it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.05it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.05it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.19it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.19it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.36it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.36it/s, train_loss=0.253]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 average loss: 0.4864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  15%|█▌        | 17/110 [07:07<38:16, 24.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 17 current AUC: 0.9862 current accuracy: 0.8696 best AUC: 0.9896 at epoch: 11\n",
      "----------\n",
      "epoch 18/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.57]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.17it/s, train_loss=0.57]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.17it/s, train_loss=0.898]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.75it/s, train_loss=0.898]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.75it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.04it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.04it/s, train_loss=0.64] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.85it/s, train_loss=0.64]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.85it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.17it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.17it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.28it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.28it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.28it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.28it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.04it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.04it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.82it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.82it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.85it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.85it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.00it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.00it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.93it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.93it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.99it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.99it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.09it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.09it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.13it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.13it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.98it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.98it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.17it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.17it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.23it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.23it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.01it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.01it/s, train_loss=0.19]  \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.01it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.01it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.95it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.95it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.06it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.06it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.04it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.04it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.02it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.02it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.94it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.94it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.96it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.96it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.97it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.97it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.14it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.14it/s, train_loss=1.05] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.11it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.11it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.08it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.08it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.18it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.18it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.16it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.16it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.10it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.10it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.08it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.08it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.89it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.89it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.88it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.88it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.00it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.00it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.55] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.08it/s, train_loss=0.55]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.08it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.05it/s, train_loss=1.17]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.05it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.11it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.11it/s, train_loss=0.548]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.10it/s, train_loss=0.548]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.10it/s, train_loss=0.577]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.17it/s, train_loss=0.577]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.17it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.85it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.85it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.09it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.09it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.94it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.94it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.03it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.03it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.07it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.07it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.94it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.94it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.92it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.92it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.95it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.95it/s, train_loss=0.488]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.02it/s, train_loss=0.488]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.02it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.92it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.92it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.79it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.79it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.83it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.83it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.88it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.88it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.96it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.96it/s, train_loss=0.39] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.90it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.90it/s, train_loss=0.592]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.06it/s, train_loss=0.592]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.06it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.17it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.17it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.28it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.28it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.28it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.28it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.20it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.20it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.13it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.13it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.07it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.07it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.21it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.21it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.25it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.25it/s, train_loss=0.644]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.19it/s, train_loss=0.644]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.19it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.08it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.08it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.09it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.09it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.12it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.12it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.13it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.13it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.25it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.25it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.55it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:08,  5.55it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.15it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.15it/s, train_loss=0.488]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.14it/s, train_loss=0.488]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.14it/s, train_loss=1.08] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.15it/s, train_loss=1.08]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.15it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.18it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.18it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.11it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.11it/s, train_loss=0.88] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.12it/s, train_loss=0.88]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.12it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.05it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.05it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.16it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.16it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.18it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.18it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.05it/s, train_loss=0.648]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.05it/s, train_loss=0.46] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.03it/s, train_loss=0.46]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.03it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.09it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.09it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.30it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.30it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.19it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.19it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.18it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.18it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.00it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.00it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.561]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.87it/s, train_loss=0.561]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.87it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.91it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.91it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.91it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.91it/s, train_loss=0.604]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.86it/s, train_loss=0.604]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.86it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.87it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.87it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.88it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.88it/s, train_loss=0.655]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.15it/s, train_loss=0.655]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.15it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.82it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.82it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.77it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.77it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.91it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.91it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.98it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.98it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.17it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.17it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.09it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.09it/s, train_loss=0.968]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.23it/s, train_loss=0.968]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.23it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=0.646]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.88it/s, train_loss=0.646]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.88it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.00it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.00it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.89it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.89it/s, train_loss=0.873]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.98it/s, train_loss=0.873]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.98it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.02it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.02it/s, train_loss=0.805]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.01it/s, train_loss=0.805]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.01it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.15it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.15it/s, train_loss=0.895]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.04it/s, train_loss=0.895]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.04it/s, train_loss=0.967]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.03it/s, train_loss=0.967]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.03it/s, train_loss=0.475]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.13it/s, train_loss=0.475]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.13it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.94it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.94it/s, train_loss=0.41] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.04it/s, train_loss=0.41]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.04it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.90it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.90it/s, train_loss=0.164]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 average loss: 0.4329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  16%|█▋        | 18/110 [07:32<37:52, 24.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 18 current AUC: 0.9889 current accuracy: 0.8634 best AUC: 0.9896 at epoch: 11\n",
      "----------\n",
      "epoch 19/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.28it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.28it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.93it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.93it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.04it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.04it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.11it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.11it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.09it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.09it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.19it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.19it/s, train_loss=0.0758]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.25it/s, train_loss=0.0758]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.25it/s, train_loss=0.386] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.17it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.17it/s, train_loss=0.49] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  4.90it/s, train_loss=0.49]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.90it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.08it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.08it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.12it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.12it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.00it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.00it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.14it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.14it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.18it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.18it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.20it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.20it/s, train_loss=0.473]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.08it/s, train_loss=0.473]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.08it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.12it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.12it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.22it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.22it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.87it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.87it/s, train_loss=0.994]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.91it/s, train_loss=0.994]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.91it/s, train_loss=0.517]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.01it/s, train_loss=0.517]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.01it/s, train_loss=0.597]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.17it/s, train_loss=0.597]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.17it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.02it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.02it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.13it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.13it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.07it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.07it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.91it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.91it/s, train_loss=0.574]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.87it/s, train_loss=0.574]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.87it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.09it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.09it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.05it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.05it/s, train_loss=0.767]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.17it/s, train_loss=0.767]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.17it/s, train_loss=0.26] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.09it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.09it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.86it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.86it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.04it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.04it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.05it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.05it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.92it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.92it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.06it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.06it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.05it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.05it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.96it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.96it/s, train_loss=0.542]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.97it/s, train_loss=0.542]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.97it/s, train_loss=0.628]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.79it/s, train_loss=0.628]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.79it/s, train_loss=1.32] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=1.32]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.95it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.95it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.12it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.12it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.07it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.07it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.11it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.11it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.11it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.11it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.26it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.26it/s, train_loss=0.629]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.02it/s, train_loss=0.629]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.02it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.00it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.00it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.91it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.91it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.27it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.27it/s, train_loss=0.572]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.21it/s, train_loss=0.572]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.21it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.14it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.14it/s, train_loss=0.805]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.05it/s, train_loss=0.805]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.05it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.98it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.98it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.97it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.97it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.29it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.29it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.37it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.37it/s, train_loss=0.726]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.27it/s, train_loss=0.726]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.27it/s, train_loss=0.974]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.07it/s, train_loss=0.974]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.07it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.12it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.12it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.24it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.24it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.40it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.40it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.15it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.15it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.11it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.11it/s, train_loss=0.575]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.10it/s, train_loss=0.575]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.10it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.94it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.94it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.18it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.18it/s, train_loss=0.963]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.01it/s, train_loss=0.963]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.01it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  5.07it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.07it/s, train_loss=1.15] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.16it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.16it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.14it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.14it/s, train_loss=1.74] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.15it/s, train_loss=1.74]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.15it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  4.93it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.93it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.96it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.96it/s, train_loss=0.691]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.96it/s, train_loss=0.691]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.96it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.99it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.99it/s, train_loss=0.856]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.21it/s, train_loss=0.856]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.21it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.28it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.28it/s, train_loss=0.72] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.22it/s, train_loss=0.72]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.22it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.06it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.06it/s, train_loss=0.604]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.29it/s, train_loss=0.604]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.29it/s, train_loss=0.909]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.16it/s, train_loss=0.909]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.16it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.28it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.28it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.20it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.20it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.02it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.02it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.92it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.92it/s, train_loss=0.824]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.07it/s, train_loss=0.824]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.07it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.99it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.99it/s, train_loss=0.782]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.16it/s, train_loss=0.782]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.16it/s, train_loss=0.651]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.87it/s, train_loss=0.651]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.87it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.88it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.88it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.98it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.98it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.34it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.34it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.31it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.31it/s, train_loss=1.69] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.37it/s, train_loss=1.69]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.37it/s, train_loss=0.483]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.16it/s, train_loss=0.483]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.16it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.06it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.06it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.25it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.25it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.27it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.27it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.27it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.27it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.49it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.49it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.45it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.45it/s, train_loss=0.666]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:02,  5.61it/s, train_loss=0.666]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:02,  5.61it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:20<00:02,  5.28it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.28it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.16it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.16it/s, train_loss=0.52] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.08it/s, train_loss=0.52]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.08it/s, train_loss=1.63]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.18it/s, train_loss=1.63]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.18it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.06it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.06it/s, train_loss=0.691]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:01,  5.02it/s, train_loss=0.691]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.02it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.96it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.96it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.03it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.03it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.18it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.18it/s, train_loss=0.684]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.45it/s, train_loss=0.684]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.45it/s, train_loss=0.42] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:22<00:00,  5.26it/s, train_loss=0.42]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.26it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.15it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.15it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.19it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.19it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.32it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.32it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.16it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.16it/s, train_loss=1.36] \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 average loss: 0.4875\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  17%|█▋        | 19/110 [07:58<37:53, 24.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 19 current AUC: 0.9921 current accuracy: 0.8447 best AUC: 0.9921 at epoch: 19\n",
      "----------\n",
      "epoch 20/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.56it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.56it/s, train_loss=1.09] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:26,  4.58it/s, train_loss=1.09]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:26,  4.58it/s, train_loss=0.809]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:26,  4.50it/s, train_loss=0.809]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:26,  4.50it/s, train_loss=0.4]  \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:25,  4.65it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:25,  4.65it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.84it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.84it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.82it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.82it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  4.96it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  4.96it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.99it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  4.99it/s, train_loss=0.6]  \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.05it/s, train_loss=0.6]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.05it/s, train_loss=0.924]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.12it/s, train_loss=0.924]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.12it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.21it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.21it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.28it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.28it/s, train_loss=0.539]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.25it/s, train_loss=0.539]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:20,  5.25it/s, train_loss=0.26] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.08it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.08it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.30it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.30it/s, train_loss=0.709]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.03it/s, train_loss=0.709]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.03it/s, train_loss=0.622]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.20it/s, train_loss=0.622]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.20it/s, train_loss=0.551]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.13it/s, train_loss=0.551]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.13it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.08it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.08it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.29it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.29it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.11it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.11it/s, train_loss=0.457]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.07it/s, train_loss=0.457]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.07it/s, train_loss=0.46] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.25it/s, train_loss=0.46]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.25it/s, train_loss=0.591]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.96it/s, train_loss=0.591]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.96it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.02it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.02it/s, train_loss=0.614]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.614]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.95it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.95it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.05it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.05it/s, train_loss=0.426]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.05it/s, train_loss=0.426]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.05it/s, train_loss=0.516]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.19it/s, train_loss=0.516]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.19it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.05it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.05it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.30it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.30it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.30it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.30it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.15it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.15it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.11it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.11it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.19it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.19it/s, train_loss=1.23] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.05it/s, train_loss=1.23]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.05it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.27it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.27it/s, train_loss=0.45] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.26it/s, train_loss=0.45]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.26it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.17it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.17it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.07it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.07it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.24it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.24it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.25it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.25it/s, train_loss=0.613]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.07it/s, train_loss=0.613]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.07it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.12it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.12it/s, train_loss=1.26] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.05it/s, train_loss=1.26]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.05it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.29it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.29it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.17it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.17it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.18it/s, train_loss=0.953]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.18it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.12it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.12it/s, train_loss=0.29] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.00it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.00it/s, train_loss=0.848]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.96it/s, train_loss=0.848]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.96it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.96it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.96it/s, train_loss=0.752]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.20it/s, train_loss=0.752]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.20it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.08it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.08it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.05it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.05it/s, train_loss=0.348] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.38it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.38it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.17it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.17it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:11,  5.12it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.12it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.31it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.31it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.39it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.39it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.25it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.25it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.04it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.04it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.26it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.26it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.19it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.19it/s, train_loss=0.523]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.13it/s, train_loss=0.523]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.13it/s, train_loss=1.21] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.18it/s, train_loss=1.21]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.18it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.19it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.19it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.17it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.17it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.00it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.00it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.94it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.94it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.01it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.01it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  5.02it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.02it/s, train_loss=0.467]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.05it/s, train_loss=0.467]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.05it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.602]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.84it/s, train_loss=0.602]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.84it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.87it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.87it/s, train_loss=0.36] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.74it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.74it/s, train_loss=0.703]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.84it/s, train_loss=0.703]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.84it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.81it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.81it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:08,  4.72it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:08,  4.72it/s, train_loss=0.738]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.73it/s, train_loss=0.738]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.73it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.67it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.67it/s, train_loss=0.996]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.85it/s, train_loss=0.996]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.85it/s, train_loss=0.688]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.87it/s, train_loss=0.688]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.87it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.90it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.90it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.94it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.94it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.15it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.15it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.15it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.15it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.93it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.93it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=1.3] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.91it/s, train_loss=1.3]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.91it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.03it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.03it/s, train_loss=0.652]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.17it/s, train_loss=0.652]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.17it/s, train_loss=0.34] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.97it/s, train_loss=0.34]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.97it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.83it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.83it/s, train_loss=0.827]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.91it/s, train_loss=0.827]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.91it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.96it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.96it/s, train_loss=0.727]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.727]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.06it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.06it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.80it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.80it/s, train_loss=1.5]  \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.80it/s, train_loss=1.5]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.80it/s, train_loss=0.539]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.84it/s, train_loss=0.539]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.84it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.68it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.68it/s, train_loss=0.677]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.74it/s, train_loss=0.677]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.74it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.02it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.02it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.21it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.21it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.36it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.36it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.18it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.18it/s, train_loss=0.879]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=0.879]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=0.73] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.13it/s, train_loss=0.73]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.13it/s, train_loss=0.739]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.18it/s, train_loss=0.739]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.18it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.25it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.25it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.22it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.22it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.96it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.96it/s, train_loss=0.463]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.08it/s, train_loss=0.463]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.08it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.95it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.95it/s, train_loss=0.574]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.95it/s, train_loss=0.574]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.95it/s, train_loss=0.885]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 average loss: 0.4750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  18%|█▊        | 20/110 [08:22<37:19, 24.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 20 current AUC: 0.9899 current accuracy: 0.8571 best AUC: 0.9921 at epoch: 19\n",
      "----------\n",
      "epoch 21/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  6.03it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  6.03it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:20,  5.85it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:20,  5.85it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.51it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.51it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.37it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.37it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:21,  5.36it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:21,  5.36it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.09it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.09it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.22it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.22it/s, train_loss=0.68] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.32it/s, train_loss=0.68]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.32it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.29it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.29it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.14it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.14it/s, train_loss=0.566]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.04it/s, train_loss=0.566]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.04it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.37it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.37it/s, train_loss=1.04] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.17it/s, train_loss=1.04]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.17it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.36it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.36it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.22it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.22it/s, train_loss=0.468]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.22it/s, train_loss=0.468]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.22it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.40it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.40it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.31it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.31it/s, train_loss=0.948]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.12it/s, train_loss=0.948]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.12it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.15it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.15it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.10it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.10it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.15it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.15it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.04it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.04it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.09it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.09it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.23it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.23it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:04<00:18,  5.18it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.18it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.19it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.19it/s, train_loss=0.63] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.27it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.27it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.34it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.34it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:16,  5.49it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:16,  5.49it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:05<00:17,  5.28it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.28it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.10it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.10it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.72it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.72it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.78it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.78it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:18,  4.82it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:18,  4.82it/s, train_loss=0.459]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:06<00:16,  5.07it/s, train_loss=0.459]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.07it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.95it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.95it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.01it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.01it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.99it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.99it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:07<00:16,  4.90it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.90it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.87it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.87it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.86it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.86it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.87it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.87it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.97it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.97it/s, train_loss=1.15] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:15,  4.85it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.85it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.03it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.03it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.16it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.16it/s, train_loss=0.746]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.33it/s, train_loss=0.746]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.33it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.03it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.03it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:14,  5.02it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.02it/s, train_loss=0.788]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.88it/s, train_loss=0.788]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.88it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.84it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.84it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.16it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.16it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.26it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.26it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.23it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.23it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.26it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.26it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:11,  5.44it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:11,  5.44it/s, train_loss=0.432]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.34it/s, train_loss=0.432]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.34it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.16it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.16it/s, train_loss=0.606]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  5.08it/s, train_loss=0.606]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.08it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.08it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.08it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.10it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.10it/s, train_loss=0.44] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.99it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.99it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.96it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.96it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  5.07it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.07it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.13it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.13it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.04it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.04it/s, train_loss=0.605]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.11it/s, train_loss=0.605]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.11it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.14it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.14it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.12it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.12it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  5.00it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  5.00it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.86it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.86it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.84it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.84it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.89it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.89it/s, train_loss=0.739]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  4.83it/s, train_loss=0.739]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.83it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.97it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.97it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.86it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.86it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.04it/s, train_loss=0.612]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.04it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.91it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.91it/s, train_loss=0.473]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.06it/s, train_loss=0.473]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.06it/s, train_loss=1.16] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.79it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.79it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.75it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.75it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.78it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.78it/s, train_loss=0.85] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  4.76it/s, train_loss=0.85]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.76it/s, train_loss=0.803]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.85it/s, train_loss=0.803]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.85it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.88it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.88it/s, train_loss=0.69] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.83it/s, train_loss=0.69]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.83it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.94it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.94it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.75it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.75it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.72it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.72it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.67it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.67it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.68it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.68it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.76it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.76it/s, train_loss=1.06] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.89it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.89it/s, train_loss=0.583]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.07it/s, train_loss=0.583]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.07it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.94it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.94it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.88it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.88it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.97it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.97it/s, train_loss=0.727]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.05it/s, train_loss=0.727]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.05it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.21it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.21it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.32it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.32it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.10it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.10it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.03it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.03it/s, train_loss=0.575]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.01it/s, train_loss=0.575]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.01it/s, train_loss=0.34] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.08it/s, train_loss=0.34]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.08it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.02it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.02it/s, train_loss=0.604]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.11it/s, train_loss=0.604]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.11it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.98it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.98it/s, train_loss=0.571]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.92it/s, train_loss=0.571]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.92it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.90it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.90it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.80it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.80it/s, train_loss=1.15] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.99it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.99it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.98it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.98it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.97it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.97it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=0.852]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.02it/s, train_loss=0.852]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.02it/s, train_loss=0.74] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.23it/s, train_loss=0.74]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.23it/s, train_loss=0.832]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.14it/s, train_loss=0.832]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.14it/s, train_loss=0.171]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 average loss: 0.4477\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  19%|█▉        | 21/110 [08:48<37:22, 25.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 21 current AUC: 0.9940 current accuracy: 0.8696 best AUC: 0.9940 at epoch: 21\n",
      "----------\n",
      "epoch 22/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:28,  4.24it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:28,  4.24it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.97it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.97it/s, train_loss=0.439]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.09it/s, train_loss=0.439]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.09it/s, train_loss=0.759]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.30it/s, train_loss=0.759]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.30it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.10it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.10it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.12it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.12it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.94it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.94it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.87it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.87it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.11it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.11it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.10it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.10it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.41it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.41it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.46it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.46it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.10it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.10it/s, train_loss=1.25] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.14it/s, train_loss=1.25]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.14it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  4.93it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.93it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.03it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.03it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.15it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.15it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.00it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.00it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.80it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.80it/s, train_loss=0.547]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:21,  4.86it/s, train_loss=0.547]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.86it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.91it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.91it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.99it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.99it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.19it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.19it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.04it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.04it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.94it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.94it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.85it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.85it/s, train_loss=0.915]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.78it/s, train_loss=0.915]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.78it/s, train_loss=0.784]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.96it/s, train_loss=0.784]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.96it/s, train_loss=0.6]  \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.06it/s, train_loss=0.6]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.06it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.11it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.11it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.18it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.18it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.13it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.13it/s, train_loss=0.468]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.10it/s, train_loss=0.468]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.10it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.98it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.98it/s, train_loss=1.01] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.10it/s, train_loss=1.01]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.10it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.91it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.91it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.76it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.76it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.95it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.95it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.20it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.20it/s, train_loss=0.725]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.10it/s, train_loss=0.725]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.10it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.23it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.23it/s, train_loss=0.588]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.17it/s, train_loss=0.588]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.17it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.12it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.12it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.23it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.23it/s, train_loss=0.176] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.93it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.93it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.98it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.98it/s, train_loss=0.667]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.93it/s, train_loss=0.667]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.93it/s, train_loss=0.532]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.21it/s, train_loss=0.532]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.21it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.25it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.25it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.39it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.39it/s, train_loss=0.479]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.36it/s, train_loss=0.479]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.36it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.33it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.33it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.61it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.61it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.49it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.49it/s, train_loss=0.963]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.23it/s, train_loss=0.963]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.23it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.10it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.10it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.25it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.25it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.27it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.27it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.15it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.15it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.12it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.12it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:11,  5.22it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.22it/s, train_loss=0.36] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.99it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.99it/s, train_loss=0.606]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.14it/s, train_loss=0.606]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.14it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.24it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.24it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.18it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.18it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.29it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.29it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.48it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.48it/s, train_loss=0.411] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.39it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.39it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:09,  5.47it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:09,  5.47it/s, train_loss=0.663]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.48it/s, train_loss=0.663]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.48it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.54it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.54it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.45it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.45it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.42it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.42it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:08,  5.34it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:08,  5.34it/s, train_loss=0.582]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.17it/s, train_loss=0.582]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.17it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.38it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.38it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:14<00:08,  5.37it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.37it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.32it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.32it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.05it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.05it/s, train_loss=1.15] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.10it/s, train_loss=1.15]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.10it/s, train_loss=0.879]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.04it/s, train_loss=0.879]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.04it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:15<00:07,  5.04it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.04it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.13it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.13it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.18it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.18it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.16it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.16it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.09it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.09it/s, train_loss=0.572]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:16<00:06,  5.06it/s, train_loss=0.572]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.06it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.17it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.17it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.28it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.28it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.23it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.23it/s, train_loss=0.768]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.24it/s, train_loss=0.768]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.24it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:17<00:05,  5.17it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.17it/s, train_loss=0.83] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.24it/s, train_loss=0.83]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.24it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.22it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.22it/s, train_loss=0.32] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.95it/s, train_loss=0.32]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.95it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.96it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.96it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:18<00:04,  5.11it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.11it/s, train_loss=0.717]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.717]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.96it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.96it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.01it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.01it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:19<00:04,  4.95it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.07it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.07it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.80it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.80it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.96it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.96it/s, train_loss=0.684]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.16it/s, train_loss=0.684]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.16it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:20<00:02,  5.13it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.13it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.11it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.11it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.99it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.99it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.94it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.94it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.98it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.98it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:01,  5.06it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.06it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.93it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.93it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.80it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.80it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.87it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.87it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.03it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.03it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:22<00:00,  5.01it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.01it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.13it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.13it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.14it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.14it/s, train_loss=0.935]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.74it/s, train_loss=0.935]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.74it/s, train_loss=0.756]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.89it/s, train_loss=0.756]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.89it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:23<00:00,  5.73it/s, train_loss=0.273]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 average loss: 0.4272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 22/110 [09:13<36:36, 24.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 22 current AUC: 0.9936 current accuracy: 0.9068 best AUC: 0.9940 at epoch: 21\n",
      "----------\n",
      "epoch 23/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.885]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.24it/s, train_loss=0.885]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.24it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.586]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.22it/s, train_loss=0.586]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.22it/s, train_loss=0.4]  \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.41it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.41it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.12it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.12it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.07it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.07it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.86it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.86it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.89it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.89it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.88it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.88it/s, train_loss=0.977]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.01it/s, train_loss=0.977]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.01it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.19it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.19it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.15it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.15it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.14it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.14it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.06it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.06it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.14it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.14it/s, train_loss=0.44] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.06it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.06it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.99it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.99it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.04it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.04it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.16it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.16it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.06it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.06it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.96it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.96it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.08it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.08it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.06it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.06it/s, train_loss=0.7]  \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.92it/s, train_loss=0.7]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.92it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.06it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.06it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.88it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.88it/s, train_loss=0.37] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.95it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.95it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.20it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.20it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.26it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.26it/s, train_loss=0.548]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.10it/s, train_loss=0.548]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.10it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.14it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.14it/s, train_loss=0.65] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.95it/s, train_loss=0.65]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.95it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.93it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.93it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:18,  4.81it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.81it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.75it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.75it/s, train_loss=0.468]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.79it/s, train_loss=0.468]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.79it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.86it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.86it/s, train_loss=0.64] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.73it/s, train_loss=0.64]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:17,  4.73it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.69it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.69it/s, train_loss=0.52] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.78it/s, train_loss=0.52]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.78it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:17,  4.62it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:17,  4.62it/s, train_loss=0.4]  \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.77it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.77it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.81it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:16,  4.81it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.78it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.78it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.08it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.08it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.91it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.91it/s, train_loss=0.793]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.94it/s, train_loss=0.793]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.94it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.83it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:15,  4.83it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.83it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.83it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.91it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.91it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.09it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.09it/s, train_loss=0.999]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.85it/s, train_loss=0.999]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.85it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.76it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:14,  4.76it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.94it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.94it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.16it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.16it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.26it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.26it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.21it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.21it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.12it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  5.12it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.02it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.02it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.25it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.25it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.29it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.29it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.32it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.32it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.36it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:10,  5.36it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.99it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.99it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.28it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.28it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.26it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.26it/s, train_loss=0.661]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.05it/s, train_loss=0.661]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.05it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.03it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.03it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.97it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.97it/s, train_loss=0.6]  \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.00it/s, train_loss=0.6]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.00it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.76it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.76it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.80it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.80it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.77it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:10,  4.77it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.95it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.95it/s, train_loss=0.44] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.05it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.05it/s, train_loss=0.559]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.26it/s, train_loss=0.559]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.26it/s, train_loss=0.69] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.08it/s, train_loss=0.69]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.08it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.23it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.23it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.21it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.21it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.98it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.98it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.04it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.04it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.01it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.01it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.00it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.00it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.15it/s, train_loss=0.543]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.15it/s, train_loss=0.506]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.31it/s, train_loss=0.506]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.31it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.17it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.17it/s, train_loss=0.745]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.06it/s, train_loss=0.745]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.06it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.74it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.74it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.94it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.94it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.15it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.15it/s, train_loss=0.24] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.25it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.25it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.25it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.25it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.11it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.11it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.22it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.22it/s, train_loss=0.63] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.12it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.12it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.26it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.26it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.05it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.05it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.11it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.11it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.95it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.95it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.89it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.89it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  5.00it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  5.00it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.10it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.10it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.98it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.98it/s, train_loss=0.774]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.98it/s, train_loss=0.774]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.98it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.07it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.07it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.561]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.82it/s, train_loss=0.561]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.82it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.90it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.90it/s, train_loss=0.734]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.05it/s, train_loss=0.734]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.05it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.94it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.94it/s, train_loss=1.03] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.80it/s, train_loss=1.03]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.80it/s, train_loss=0.487]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.71it/s, train_loss=0.487]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.71it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.82it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.82it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.86it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.86it/s, train_loss=0.605]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.68it/s, train_loss=0.605]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.68it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.73it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.73it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.70it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.70it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.75it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.75it/s, train_loss=0.812]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.94it/s, train_loss=0.812]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.94it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.10it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.10it/s, train_loss=0.257]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 average loss: 0.4128\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  21%|██        | 23/110 [09:39<36:42, 25.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 23 current AUC: 0.9967 current accuracy: 0.8882 best AUC: 0.9967 at epoch: 23\n",
      "----------\n",
      "epoch 24/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.808]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.70it/s, train_loss=0.808]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.70it/s, train_loss=0.615]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.615]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.97it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.97it/s, train_loss=0.18] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.02it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  5.02it/s, train_loss=0.62]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.91it/s, train_loss=0.62]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.91it/s, train_loss=0.789]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.09it/s, train_loss=0.789]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.09it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.93it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.93it/s, train_loss=0.24] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.00it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.00it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.02it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.02it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.09it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.09it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.28it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.28it/s, train_loss=1.81] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.31it/s, train_loss=1.81]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.31it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.07it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.07it/s, train_loss=0.473]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.16it/s, train_loss=0.473]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.16it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.28it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.28it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.49it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.49it/s, train_loss=0.539]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.45it/s, train_loss=0.539]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.45it/s, train_loss=0.893]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.893]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.04it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.04it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.05it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.05it/s, train_loss=0.741]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.741]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.04it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.04it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.04it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.04it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.93it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.93it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.10it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.10it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.04it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.04it/s, train_loss=0.574]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.04it/s, train_loss=0.574]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.04it/s, train_loss=0.951]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.87it/s, train_loss=0.951]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.87it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.88it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.88it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.74it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.74it/s, train_loss=0.683]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:19,  4.67it/s, train_loss=0.683]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:19,  4.67it/s, train_loss=0.532]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.71it/s, train_loss=0.532]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.71it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.78it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.78it/s, train_loss=0.696]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.96it/s, train_loss=0.696]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.96it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.88it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.88it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.99it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.99it/s, train_loss=0.555]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.98it/s, train_loss=0.555]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.98it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.19it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.19it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.32it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.32it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.28it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.28it/s, train_loss=0.452]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:14,  5.44it/s, train_loss=0.452]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:14,  5.44it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.15it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.15it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.93it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.93it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:16,  4.78it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.78it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.92it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.92it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.97it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.97it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.96it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.96it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.92it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.92it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.07it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.07it/s, train_loss=0.66] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.09it/s, train_loss=0.66]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.09it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.94it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.94it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.91it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.91it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.81it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.81it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.82it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.82it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.96it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.96it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.04it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.04it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.96it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.96it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.89it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.89it/s, train_loss=0.59] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.83it/s, train_loss=0.59]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.83it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.05it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.05it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.96it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.96it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.98it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.98it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.07it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.07it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.20it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.20it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.10it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.10it/s, train_loss=0.821]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.10it/s, train_loss=0.821]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.10it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.29it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.29it/s, train_loss=0.506]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.23it/s, train_loss=0.506]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.23it/s, train_loss=0.0897]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.23it/s, train_loss=0.0897]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.23it/s, train_loss=0.421] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.15it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.15it/s, train_loss=0.692]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.02it/s, train_loss=0.692]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.02it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.11it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.11it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.24it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.24it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.10it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.10it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.88it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.88it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.86it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.86it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.90it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.90it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.01it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.01it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.12it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.12it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.90it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.90it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.02it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.02it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.09it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.09it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.22it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.22it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.38it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:06,  5.38it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.34it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.34it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.22it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.22it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.07it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.07it/s, train_loss=0.555]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.98it/s, train_loss=0.555]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.98it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.82it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.82it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.79it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.79it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.96it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.96it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.84it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.84it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.86it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.86it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.09it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.09it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.00it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.00it/s, train_loss=0.558]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.02it/s, train_loss=0.558]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.02it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.06it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.06it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.88it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.88it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.02it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.09it/s, train_loss=0.699]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.09it/s, train_loss=0.2]  \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.13it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.13it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.01it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.01it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.07it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.07it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.27it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.27it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.21it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.21it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.01it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.01it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.69it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.69it/s, train_loss=0.595]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.72it/s, train_loss=0.595]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.72it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.89it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.89it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.09it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.09it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.91it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.91it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.81it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.81it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.93it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.93it/s, train_loss=0.55] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.01it/s, train_loss=0.55]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.01it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.04it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.04it/s, train_loss=0.432]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.99it/s, train_loss=0.432]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.99it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.94it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.94it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.17it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.17it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.03it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.03it/s, train_loss=0.531]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.87it/s, train_loss=0.531]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.87it/s, train_loss=0.551]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 average loss: 0.3958\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  22%|██▏       | 24/110 [10:05<36:36, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 24 current AUC: 0.9978 current accuracy: 0.9193 best AUC: 0.9978 at epoch: 24\n",
      "----------\n",
      "epoch 25/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:27,  4.48it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:27,  4.48it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.82it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.82it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.11it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.11it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.14it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:22,  5.14it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.03it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.03it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.08it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.08it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.07it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.07it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.05it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  5.05it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.89it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.89it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.18it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.18it/s, train_loss=0.577]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.24it/s, train_loss=0.577]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.24it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.16it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.16it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.35it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.35it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  4.99it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.99it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.05it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.05it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.90it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.90it/s, train_loss=0.29] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.89it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.89it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.80it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.80it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.88it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.88it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.18it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.18it/s, train_loss=0.69] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.08it/s, train_loss=0.69]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.08it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.05it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.05it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.98it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.98it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.93it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.93it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.07it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.07it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.95it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.95it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.05it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.05it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.06it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.06it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.01it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.01it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.08it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.08it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.09it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.09it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.23it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.23it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.00it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.00it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.92it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.92it/s, train_loss=0.656]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  5.00it/s, train_loss=0.656]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  5.00it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.03it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.03it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.98it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.98it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.00it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.00it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.21it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.21it/s, train_loss=0.0644]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.31it/s, train_loss=0.0644]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.31it/s, train_loss=0.257] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.36it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.36it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.25it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.25it/s, train_loss=1.04] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.16it/s, train_loss=1.04]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.16it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.11it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.11it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.87it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.87it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.89it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.89it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.03it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.03it/s, train_loss=0.787]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.98it/s, train_loss=0.787]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.98it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.08it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.08it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.17it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.17it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.26it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.26it/s, train_loss=0.0933]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.22it/s, train_loss=0.0933]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.22it/s, train_loss=0.636] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.91it/s, train_loss=0.636]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.91it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.07it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.07it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.84it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.84it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.80it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.80it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.12it/s, train_loss=0.538]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.12it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.05it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.05it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.11it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.11it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.12it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.12it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.16it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.16it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.14it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.14it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.31it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.31it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.02it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.02it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.93it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.93it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.22it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.22it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.25it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.25it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.11it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.11it/s, train_loss=0.372]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.09it/s, train_loss=0.372]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.09it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.06it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.06it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.95it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.95it/s, train_loss=0.609]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.92it/s, train_loss=0.609]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.92it/s, train_loss=0.372]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.09it/s, train_loss=0.372]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.09it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.23it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.23it/s, train_loss=0.54] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.54]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.27it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.27it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.16it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.16it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.30it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.30it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.22it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.22it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.29it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.29it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.21it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.21it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.12it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.12it/s, train_loss=0.031]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.25it/s, train_loss=0.031]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.25it/s, train_loss=0.37] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.35it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.35it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.24it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.24it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.04it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.04it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.13it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.13it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.11it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.11it/s, train_loss=0.0798]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.00it/s, train_loss=0.0798]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.00it/s, train_loss=0.227] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.13it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.13it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.03it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.03it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.88it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.88it/s, train_loss=0.475]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=0.475]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.84it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.84it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.83it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.83it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.77it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.77it/s, train_loss=0.653]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.58it/s, train_loss=0.653]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.58it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.74it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.74it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:04,  4.66it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:04,  4.66it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.65it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.65it/s, train_loss=0.44] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.91it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.91it/s, train_loss=0.4] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.03it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.03it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.17it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.17it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.14it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.14it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.23it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.23it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.14it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.14it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.98it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.98it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.98it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.98it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.98it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.98it/s, train_loss=0.37] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.02it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.02it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.99it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.99it/s, train_loss=0.0997]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.02it/s, train_loss=0.0997]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.02it/s, train_loss=0.0788]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.22it/s, train_loss=0.0788]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.22it/s, train_loss=0.166] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.10it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.10it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.31it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.31it/s, train_loss=0.42] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.41it/s, train_loss=0.42]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.41it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.15it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.15it/s, train_loss=0.069]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 average loss: 0.3353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  23%|██▎       | 25/110 [10:29<35:47, 25.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 25 current AUC: 0.9970 current accuracy: 0.9130 best AUC: 0.9978 at epoch: 24\n",
      "----------\n",
      "epoch 26/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0999]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.22it/s, train_loss=0.0999]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.22it/s, train_loss=0.261] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.30it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.30it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.98it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.98it/s, train_loss=0.452]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.96it/s, train_loss=0.452]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  4.96it/s, train_loss=0.085]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.75it/s, train_loss=0.085]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.75it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.98it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.98it/s, train_loss=0.32] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.05it/s, train_loss=0.32]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.05it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.19it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.19it/s, train_loss=0.616]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.04it/s, train_loss=0.616]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.04it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.01it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.01it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.12it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.12it/s, train_loss=0.081]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:19,  5.53it/s, train_loss=0.081]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:19,  5.53it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:19,  5.50it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:19,  5.50it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.29it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.29it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.33it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.33it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.32it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.32it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.23it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.23it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.91it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.91it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.00it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.00it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.67it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.67it/s, train_loss=0.822]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.88it/s, train_loss=0.822]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.88it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.79it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.79it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.05it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.05it/s, train_loss=0.209] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.09it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.09it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.27it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.27it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.03it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.03it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.172] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.99it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.99it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.03it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.03it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.05it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.05it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.98it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.98it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.91it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.91it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.86it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.86it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.85it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.85it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.87it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.87it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.76it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.76it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.90it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.90it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.11it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.11it/s, train_loss=0.602]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.01it/s, train_loss=0.602]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.01it/s, train_loss=0.682]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.91it/s, train_loss=0.682]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.91it/s, train_loss=0.817]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.05it/s, train_loss=0.817]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.05it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.96it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.96it/s, train_loss=1.13] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.01it/s, train_loss=1.13]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.01it/s, train_loss=0.4] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.10it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.10it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.07it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.07it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.20it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.20it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.00it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.00it/s, train_loss=0.767]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.91it/s, train_loss=0.767]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.91it/s, train_loss=0.544]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.91it/s, train_loss=0.544]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.91it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.99it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.99it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.01it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.01it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.00it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.00it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.05it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.05it/s, train_loss=0.59] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.15it/s, train_loss=0.59]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.15it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.14it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.14it/s, train_loss=0.902]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.25it/s, train_loss=0.902]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.25it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.91it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.91it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.81it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.81it/s, train_loss=0.484]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.02it/s, train_loss=0.484]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.02it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.88it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.88it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.615]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.95it/s, train_loss=0.615]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.95it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.20it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.20it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.05it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.05it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.08it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.08it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.05it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.05it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.97it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.97it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.18it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.18it/s, train_loss=0.0942]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.12it/s, train_loss=0.0942]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.12it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.01it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.01it/s, train_loss=1.48]  \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.11it/s, train_loss=1.48]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.11it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.01it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.01it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.17it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.17it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.05it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.05it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.04it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.04it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.98it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.98it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.04it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.04it/s, train_loss=0.5]  \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.78it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.78it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.78it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.78it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.87it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.87it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.87it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.87it/s, train_loss=0.401] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:08,  4.74it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:08,  4.74it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.82it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.82it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.95it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.95it/s, train_loss=0.571]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.03it/s, train_loss=0.571]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.03it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.20it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.20it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.17it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.17it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.11it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.11it/s, train_loss=0.651]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.15it/s, train_loss=0.651]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.15it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.20it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.20it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.88it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.88it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.69it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.69it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.73it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.73it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.99it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.99it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.16it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.16it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.99it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.99it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.07it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.07it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.00it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.00it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.05it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.05it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.92it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.92it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.03it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.03it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.08it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.08it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.11it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.11it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.92it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.92it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.90it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.90it/s, train_loss=0.379]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.17it/s, train_loss=0.379]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.17it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.02it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.02it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.05it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.05it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.04it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.04it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.13it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.13it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.99it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.99it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.24it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.24it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.18it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.18it/s, train_loss=0.34] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.04it/s, train_loss=0.34]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.04it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.11it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.11it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.10it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.10it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.06it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.06it/s, train_loss=0.481]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 average loss: 0.3596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  24%|██▎       | 26/110 [10:54<35:10, 25.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 26 current AUC: 0.9941 current accuracy: 0.8758 best AUC: 0.9978 at epoch: 24\n",
      "----------\n",
      "epoch 27/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  5.83it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  5.83it/s, train_loss=0.18] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.03it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.03it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.23it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.23it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.02it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  5.02it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.92it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.92it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.94it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.94it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.21it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.21it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.24it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.24it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.04it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.04it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.95it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.95it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.98it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.98it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.05it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.05it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.97it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.97it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.01it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.01it/s, train_loss=0.24] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.98it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.98it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.07it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.07it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.01it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.01it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.19it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.19it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.16it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.16it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.21it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.21it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=1.89] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.94it/s, train_loss=1.89]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.94it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.20it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.20it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.09it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.09it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.08it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.08it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.12it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.12it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.88it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.88it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.89it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.89it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.93it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.93it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.88it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.88it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.94it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.94it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.10it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.10it/s, train_loss=0.902]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.09it/s, train_loss=0.902]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.09it/s, train_loss=1.22] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.07it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.07it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.19it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.19it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.99it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.99it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.93it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.93it/s, train_loss=0.662]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.06it/s, train_loss=0.662]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.06it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.15it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.15it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.14it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.14it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.656]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.656]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.17it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.17it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.23it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.23it/s, train_loss=0.704]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.16it/s, train_loss=0.704]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.16it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=0.553]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.93it/s, train_loss=0.553]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.93it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.01it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.01it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.16it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.16it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.00it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.00it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.21it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.21it/s, train_loss=0.547]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.07it/s, train_loss=0.547]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.07it/s, train_loss=0.064]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.90it/s, train_loss=0.064]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.90it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.93it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.93it/s, train_loss=0.557]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.02it/s, train_loss=0.557]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.02it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.10it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.10it/s, train_loss=0.41] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.09it/s, train_loss=0.41]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.09it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.33it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.33it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.14it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.14it/s, train_loss=0.0852]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.19it/s, train_loss=0.0852]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.19it/s, train_loss=0.249] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  5.00it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  5.00it/s, train_loss=0.692]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.06it/s, train_loss=0.692]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.06it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.12it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.12it/s, train_loss=0.686]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.03it/s, train_loss=0.686]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.03it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.11it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.11it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.24it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.24it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.11it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.11it/s, train_loss=0.18] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.03it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.03it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.18it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.18it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.05it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.05it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.99it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.99it/s, train_loss=0.35] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.98it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.98it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.12it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.12it/s, train_loss=0.38] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.06it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.06it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.29it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.29it/s, train_loss=0.427]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.29it/s, train_loss=0.427]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.29it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.06it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.06it/s, train_loss=0.683]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=0.683]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=0.989]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.19it/s, train_loss=0.989]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.19it/s, train_loss=0.372]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.10it/s, train_loss=0.372]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.10it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.06it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.06it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.11it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.11it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.08it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.08it/s, train_loss=0.722]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.20it/s, train_loss=0.722]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.20it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.25it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.25it/s, train_loss=0.453] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.18it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.18it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.10it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.10it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.24it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.24it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.93it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.93it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.09it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.09it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.05it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.05it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.89it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.89it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.85it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.85it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.01it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.01it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.91it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.91it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.605]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.17it/s, train_loss=0.605]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.17it/s, train_loss=0.0724]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.08it/s, train_loss=0.0724]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.08it/s, train_loss=0.484] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.06it/s, train_loss=0.484]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.06it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.01it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.01it/s, train_loss=0.0899]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.0899]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.381] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.99it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.99it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.91it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.91it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.91it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.91it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.96it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.96it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.24it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.24it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.09it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.09it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.47it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.47it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.27it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.27it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.26it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.26it/s, train_loss=0.837]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.22it/s, train_loss=0.837]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.22it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.07it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.07it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.02it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.02it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.83it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.83it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.84it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.84it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.84it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.84it/s, train_loss=0.561]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.90it/s, train_loss=0.561]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.90it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.90it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.90it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.89it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.89it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.75it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.75it/s, train_loss=0.11] \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 average loss: 0.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  25%|██▍       | 27/110 [11:19<34:32, 24.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 27 current AUC: 0.9918 current accuracy: 0.9006 best AUC: 0.9978 at epoch: 24\n",
      "----------\n",
      "epoch 28/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.30it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.30it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.95it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.95it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.21it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.21it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.02it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.02it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.92it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.92it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.86it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.86it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.93it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.93it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.90it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.90it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.05it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.05it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.80it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.80it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.85it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.85it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.06it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.06it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.07it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  5.07it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.96it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.96it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.10it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.10it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.93it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.93it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.18it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.18it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.08it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.08it/s, train_loss=0.964]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.96it/s, train_loss=0.964]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.96it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.96it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.96it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.79it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.79it/s, train_loss=0.654]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.82it/s, train_loss=0.654]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:20,  4.82it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.00it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.00it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.89it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.89it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:20,  4.74it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:20,  4.74it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:20,  4.61it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:20,  4.61it/s, train_loss=0.819]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.77it/s, train_loss=0.819]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:19,  4.77it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.85it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.85it/s, train_loss=0.29] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.04it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.04it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.29it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.29it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.17it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.17it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.17it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  5.17it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.18it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.18it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.26it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.26it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.27it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.27it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.27it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.27it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:16,  5.08it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.87it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.87it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.86it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.86it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.92it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.92it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.98it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.98it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.28it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.28it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.25it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.25it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.24it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.24it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.17it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.17it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.32it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.32it/s, train_loss=0.791]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.30it/s, train_loss=0.791]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.30it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.12it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.12it/s, train_loss=0.0896]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.05it/s, train_loss=0.0896]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.05it/s, train_loss=0.136] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.24it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.24it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.06it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.06it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.11it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.11it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.93it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.93it/s, train_loss=0.74] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.05it/s, train_loss=0.74]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.05it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.17it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.17it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.23it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.23it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.05it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.05it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.97it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.97it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.26it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.26it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.15it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.15it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.06it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.06it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.19it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.19it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.17it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.17it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.25it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.25it/s, train_loss=0.0703]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.07it/s, train_loss=0.0703]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.07it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.10it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.10it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.81it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.81it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.99it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.99it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.89it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.89it/s, train_loss=0.069]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.86it/s, train_loss=0.069]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.86it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.77it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.77it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.78it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.78it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.76it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.76it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.87it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.87it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.88it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.88it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=0.59] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.96it/s, train_loss=0.59]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.96it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.09it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.09it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.11it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.11it/s, train_loss=0.17] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.21it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.21it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.22it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.22it/s, train_loss=0.53] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.60it/s, train_loss=0.53]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:06,  5.60it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.36it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.36it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.24it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.24it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.81it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.81it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.91it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.91it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.87it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.87it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.87it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.87it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.94it/s, train_loss=0.453]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.94it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.73it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.73it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.89it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.89it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.82it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.82it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.90it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.90it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.82it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.82it/s, train_loss=0.0943]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.78it/s, train_loss=0.0943]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.78it/s, train_loss=0.521] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.94it/s, train_loss=0.521]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.94it/s, train_loss=0.694]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.94it/s, train_loss=0.694]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.94it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.94it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.94it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.08it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.08it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.91it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.91it/s, train_loss=0.37] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.09it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.09it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.23it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.23it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.16it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.16it/s, train_loss=0.798]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.13it/s, train_loss=0.798]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.13it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.05it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.05it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.47it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.47it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.43it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.43it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.37it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.37it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.42it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.42it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.50it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.50it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.19it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.19it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.07it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.07it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  5.00it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  5.00it/s, train_loss=0.85] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.81it/s, train_loss=0.85]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.81it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.97it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.97it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.91it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.91it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.89it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.89it/s, train_loss=1]    \n",
      "\u001b[A                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 average loss: 0.3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  25%|██▌       | 28/110 [11:44<34:02, 24.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 28 current AUC: 0.9919 current accuracy: 0.8820 best AUC: 0.9978 at epoch: 24\n",
      "----------\n",
      "epoch 29/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.65it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.65it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.89it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.89it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.30it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.30it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.23it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.23it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:21,  5.45it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:21,  5.45it/s, train_loss=0.0656]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.42it/s, train_loss=0.0656]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.42it/s, train_loss=0.14]  \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.37it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.37it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.12it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.12it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.35it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.35it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.25it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.25it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.26it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.26it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.36it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.36it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.11it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.11it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.92it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.92it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:22,  4.78it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.78it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.68it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.68it/s, train_loss=0.432]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:22,  4.77it/s, train_loss=0.432]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:22,  4.77it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.81it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.81it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:22,  4.63it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:22,  4.63it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:22,  4.57it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:22,  4.57it/s, train_loss=0.553]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.72it/s, train_loss=0.553]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.72it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.67it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.67it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.83it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.83it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.06it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:19,  5.06it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.98it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.98it/s, train_loss=0.39] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.06it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.06it/s, train_loss=0.834]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.13it/s, train_loss=0.834]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.13it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.99it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.99it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.18it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.18it/s, train_loss=0.759]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.18it/s, train_loss=0.759]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.18it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.97it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.97it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.13it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.13it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.11it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.11it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.19it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.19it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.03it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.03it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.09it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.09it/s, train_loss=0.47] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.20it/s, train_loss=0.47]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.20it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.34it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.34it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.22it/s, train_loss=0.617]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.22it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.34it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.34it/s, train_loss=0.633]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.29it/s, train_loss=0.633]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.29it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.12it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.12it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.19it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.19it/s, train_loss=0.601]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.20it/s, train_loss=0.601]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.20it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.09it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.09it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.87it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.87it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.93it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.93it/s, train_loss=0.622]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.88it/s, train_loss=0.622]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.88it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.11it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.11it/s, train_loss=0.24] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.99it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.99it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.91it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.91it/s, train_loss=0.523]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.84it/s, train_loss=0.523]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.84it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.78it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.78it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.80it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.80it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.93it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.93it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.14it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.14it/s, train_loss=0.609]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=0.609]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.98it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.98it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.04it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.04it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.09it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.09it/s, train_loss=0.635]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.87it/s, train_loss=0.635]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.87it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.77it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.77it/s, train_loss=0.595]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.93it/s, train_loss=0.595]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.93it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.92it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.92it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.86it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.86it/s, train_loss=0.639]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.78it/s, train_loss=0.639]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.78it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.83it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.83it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.96it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.96it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.22it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.22it/s, train_loss=0.499]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.13it/s, train_loss=0.499]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.13it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.05it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.05it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.22it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.22it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.20it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.20it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.21it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.21it/s, train_loss=1.14] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.93it/s, train_loss=1.14]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.93it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.14it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.14it/s, train_loss=0.0794]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.94it/s, train_loss=0.0794]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.94it/s, train_loss=0.338] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.95it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.95it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.12it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.12it/s, train_loss=0.631]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.02it/s, train_loss=0.631]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.02it/s, train_loss=0.607]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.16it/s, train_loss=0.607]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.16it/s, train_loss=0.755]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.27it/s, train_loss=0.755]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.27it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.39it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.39it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:06,  5.55it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:06,  5.55it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.37it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:06,  5.37it/s, train_loss=0.751]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.31it/s, train_loss=0.751]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.31it/s, train_loss=0.432]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.42it/s, train_loss=0.432]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.42it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.33it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.33it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.42it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.42it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.13it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.13it/s, train_loss=0.38] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.97it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.97it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.07it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.07it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.17it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.17it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.42it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.42it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.05it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.05it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.04it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.04it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.94it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.94it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.92it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.92it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.94it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.94it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.01it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.01it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.17it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.17it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.24it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.24it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.34it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.34it/s, train_loss=1.05] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.25it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.25it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.05it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.05it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.84it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.84it/s, train_loss=0.48]  \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.89it/s, train_loss=0.48]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.89it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.72it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.72it/s, train_loss=0.726]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.90it/s, train_loss=0.726]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.90it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.95it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.95it/s, train_loss=0.53] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.17it/s, train_loss=0.53]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.17it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.18it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.18it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.03it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.03it/s, train_loss=0.32] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.83it/s, train_loss=0.32]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.83it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.80it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.80it/s, train_loss=0.63] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.92it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.92it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.74it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.74it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.99it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.99it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.92it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.92it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.11it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.11it/s, train_loss=0.273]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 average loss: 0.3781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  26%|██▋       | 29/110 [12:08<33:31, 24.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 29 current AUC: 0.9903 current accuracy: 0.8882 best AUC: 0.9978 at epoch: 24\n",
      "----------\n",
      "epoch 30/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.49it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.49it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.71it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.71it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.73it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.73it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:25,  4.67it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:25,  4.67it/s, train_loss=0.817]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.94it/s, train_loss=0.817]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.94it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.16it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.16it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.10it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.10it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.22it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.22it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.14it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:21,  5.14it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.07it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.07it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.84it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.84it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.89it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.89it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.83it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.83it/s, train_loss=0.521]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.96it/s, train_loss=0.521]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  4.96it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.05it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.05it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.12it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.12it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.17it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.17it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.02it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.02it/s, train_loss=0.733]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.03it/s, train_loss=0.733]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  5.03it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.83it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.83it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.99it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.99it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.09it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.09it/s, train_loss=0.86] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.17it/s, train_loss=0.86]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.17it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.10it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:19,  5.10it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.96it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.96it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.07it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.07it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.06it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.06it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.79it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:19,  4.79it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.85it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.85it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.84it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.84it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:19,  4.71it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:19,  4.71it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.78it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.78it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.97it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  4.97it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.21it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.21it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.22it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.22it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.33it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.33it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.18it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.18it/s, train_loss=0.42] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.27it/s, train_loss=0.42]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.27it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.02it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.02it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.90it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.90it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.15it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.15it/s, train_loss=0.833]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.32it/s, train_loss=0.833]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.32it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.34it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.34it/s, train_loss=0.0502]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.43it/s, train_loss=0.0502]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.43it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:13,  5.62it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:13,  5.62it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.54it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.54it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.29it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.29it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.21it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.21it/s, train_loss=0.756]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.17it/s, train_loss=0.756]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.17it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.25it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.25it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.95it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.95it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.99it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.99it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.91it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.91it/s, train_loss=0.777]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.87it/s, train_loss=0.777]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.87it/s, train_loss=0.468]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.92it/s, train_loss=0.468]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.92it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.99it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.99it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.02it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.02it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.29it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.29it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.23it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.23it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.13it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.13it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.16it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.16it/s, train_loss=0.434] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.29it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.29it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.19it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.19it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.08it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.08it/s, train_loss=0.0599]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.16it/s, train_loss=0.0599]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.16it/s, train_loss=0.262] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.15it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.15it/s, train_loss=0.0944]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.15it/s, train_loss=0.0944]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.15it/s, train_loss=0.16]  \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.27it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.27it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.08it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.08it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.26it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.26it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.99it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.99it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.06it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.06it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.16it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.16it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  5.09it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.09it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.10it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.10it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.17it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.17it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.35it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.35it/s, train_loss=0.37] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.39it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.39it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.94it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.94it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.95it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.95it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.99it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.99it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.14it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.14it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.88it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.88it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.05it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.05it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.99it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.99it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.93it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.93it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.18it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.18it/s, train_loss=0.367] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.61it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.61it/s, train_loss=1.79] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.66it/s, train_loss=1.79]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.66it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.22it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.22it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.09it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.09it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.98it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.98it/s, train_loss=0.633]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.03it/s, train_loss=0.633]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.03it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.08it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.08it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.17it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.17it/s, train_loss=0.426]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.426]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.89it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.89it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.12it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.12it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.13it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.13it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.34it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.34it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.19it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.19it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.05it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.05it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.03it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.03it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.02it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.02it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.17it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.17it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.10it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.10it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.14it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.14it/s, train_loss=0.52] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.96it/s, train_loss=0.52]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.96it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.91it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.91it/s, train_loss=1.06] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.97it/s, train_loss=1.06]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.97it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.05it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.05it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.07it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.07it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.00it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.00it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.13it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.13it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.14it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.14it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.14it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.14it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.09it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.09it/s, train_loss=1]    \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.30it/s, train_loss=1]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.30it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.24it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.24it/s, train_loss=0.868]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:23<00:00,  6.10it/s, train_loss=0.868]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 average loss: 0.3357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  27%|██▋       | 30/110 [12:33<32:58, 24.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 30 current AUC: 0.9912 current accuracy: 0.8634 best AUC: 0.9978 at epoch: 24\n",
      "----------\n",
      "epoch 31/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.87it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.87it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.08it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.08it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.94it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.94it/s, train_loss=0.427]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.77it/s, train_loss=0.427]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.77it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.86it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.86it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.68it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.68it/s, train_loss=0.457]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.85it/s, train_loss=0.457]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.85it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.05it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.05it/s, train_loss=0.0615]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.04it/s, train_loss=0.0615]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.04it/s, train_loss=0.276] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.27it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.27it/s, train_loss=0.42] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.26it/s, train_loss=0.42]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.26it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.32it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.32it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.41it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.41it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.24it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.24it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:19,  5.37it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:19,  5.37it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.31it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.31it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.09it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.09it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.30it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.30it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.34it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.34it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.12it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.12it/s, train_loss=0.0836]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.10it/s, train_loss=0.0836]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.10it/s, train_loss=0.274] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.02it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.02it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.05it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.05it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:20,  4.83it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.83it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.77it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.77it/s, train_loss=0.0652]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.88it/s, train_loss=0.0652]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.88it/s, train_loss=0.369] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.96it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.96it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.28it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.28it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.11it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.11it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.01it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.01it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.21it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.21it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.35it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.35it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.31it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.31it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.03it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.03it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.04it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.04it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.05it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.05it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.96it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.96it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.97it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.97it/s, train_loss=0.21]  \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.14it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.14it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.17it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.17it/s, train_loss=0.281] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.21it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.21it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.22it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.22it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:14,  5.37it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.37it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.42it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.42it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.39it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.39it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.37it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.37it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.18it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.18it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.08it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.08it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  5.00it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  5.00it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.11it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.11it/s, train_loss=0.12] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.19it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.19it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.12it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.12it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.09it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.09it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.29it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.29it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.15it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.15it/s, train_loss=0.718]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.16it/s, train_loss=0.718]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.16it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.00it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.00it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  5.06it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.06it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.11it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.11it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.41it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.41it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.22it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.22it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.85it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.85it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  4.83it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.83it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.80it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.80it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.60it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.60it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:11,  4.67it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:11,  4.67it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  4.86it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.86it/s, train_loss=0.24] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.84it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.84it/s, train_loss=0.0903]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.95it/s, train_loss=0.0903]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.95it/s, train_loss=0.16]  \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.93it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.93it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.14it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.14it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.14it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.14it/s, train_loss=0.66] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.03it/s, train_loss=0.66]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.03it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.02it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.02it/s, train_loss=0.599]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.99it/s, train_loss=0.599]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.99it/s, train_loss=0.722]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.14it/s, train_loss=0.722]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.14it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.11it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.11it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.21it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.21it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.03it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.03it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.35it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.35it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.43it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.43it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.30it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.30it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.10it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.10it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.14it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.14it/s, train_loss=0.29] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.12it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.12it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.20it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.20it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.16it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.16it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.96it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.96it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.13it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.13it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.99it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.99it/s, train_loss=0.602] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.91it/s, train_loss=0.602]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.91it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.99it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.99it/s, train_loss=0.591]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.84it/s, train_loss=0.591]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.84it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.73] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.07it/s, train_loss=0.73]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.07it/s, train_loss=1.21]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.83it/s, train_loss=1.21]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.83it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.94it/s, train_loss=0.749]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.94it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.99it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.99it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.99it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.99it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.92it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.92it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.99it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.99it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.11it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.11it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.01it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.01it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.78it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.78it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.72it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.72it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.81it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.81it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.81it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.81it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.74it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.74it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.96it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.96it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.97it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.97it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.06it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.06it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.05it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.05it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.97it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.97it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.13it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.13it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.19it/s, train_loss=0.618]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.19it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.99it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.99it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.97it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.97it/s, train_loss=1.81] \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31 average loss: 0.3279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  28%|██▊       | 31/110 [12:57<32:31, 24.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 31 current AUC: 0.9906 current accuracy: 0.8696 best AUC: 0.9978 at epoch: 24\n",
      "----------\n",
      "epoch 32/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.23it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.23it/s, train_loss=0.741]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.95it/s, train_loss=0.741]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.95it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.02it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.02it/s, train_loss=0.767]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.06it/s, train_loss=0.767]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.06it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.08it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.08it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.16it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.16it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.89it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.89it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.78it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.78it/s, train_loss=0.877]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.71it/s, train_loss=0.877]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.71it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.87it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.87it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.93it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.93it/s, train_loss=0.0985]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.98it/s, train_loss=0.0985]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.98it/s, train_loss=0.339] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.97it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.97it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.87it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.87it/s, train_loss=1.55] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.99it/s, train_loss=1.55]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.99it/s, train_loss=0.704]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.07it/s, train_loss=0.704]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.07it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.04it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.04it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.93it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.93it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.87it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:21,  4.87it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.02it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.02it/s, train_loss=0.596]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.596]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.13it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.13it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.09it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.09it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.16it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.16it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.06it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.06it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.89it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.89it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.95it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.95it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.08it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  5.08it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.99it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.99it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.19it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.19it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.42it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.42it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.32it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.32it/s, train_loss=0.589]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.09it/s, train_loss=0.589]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.09it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.13it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.13it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.01it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.01it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.09it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.09it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.15it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.15it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.12it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.12it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.08it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.08it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.18it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.18it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.21it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.21it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.04it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.04it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.39it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.39it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.10it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.10it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.09it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.09it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.13it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.13it/s, train_loss=0.701]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.17it/s, train_loss=0.701]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.17it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.14it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.14it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.11it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.11it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=0.0902]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.89it/s, train_loss=0.0902]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.89it/s, train_loss=0.221] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.09it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.09it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.24it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.24it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.12it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.12it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.18it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.18it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.93it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.93it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.91it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.91it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.96it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.96it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.93it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.93it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.94it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.94it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.22it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.22it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.20it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.20it/s, train_loss=0.17] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.00it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.00it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.78it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.78it/s, train_loss=0.5]  \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.81it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.81it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.78it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.78it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.64it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.64it/s, train_loss=0.696]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:11,  4.66it/s, train_loss=0.696]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:11,  4.66it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.70it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.70it/s, train_loss=0.847]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.92it/s, train_loss=0.847]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.92it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.98it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.98it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.15it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.15it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.12it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.12it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.82it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.82it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.77it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.77it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.76it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.76it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.82it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.82it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.93it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.93it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.03it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.03it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.90it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.90it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.69it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.69it/s, train_loss=0.545]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.90it/s, train_loss=0.545]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  4.90it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.76it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.76it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.05it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.05it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.19it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.19it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.21it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.21it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.15it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.15it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.11it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.11it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.99it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.99it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  5.00it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  5.00it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.0844]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.19it/s, train_loss=0.0844]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.19it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.18it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.18it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.22it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.22it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.14it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.14it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.02it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.02it/s, train_loss=0.2]  \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.15it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.15it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.20it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.20it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.24it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.24it/s, train_loss=0.845]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.53it/s, train_loss=0.845]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.53it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.36it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.36it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.12it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.12it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.29it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.29it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.22it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.22it/s, train_loss=0.0413]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.33it/s, train_loss=0.0413]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.33it/s, train_loss=0.436] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.07it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.07it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.84it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.84it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.97it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.97it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.72it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.72it/s, train_loss=0.38] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.96it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.96it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.91it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.91it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.11it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.11it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.08it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.08it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.99it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.99it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.01it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.01it/s, train_loss=0.089]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.93it/s, train_loss=0.089]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.93it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.94it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.94it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.97it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.97it/s, train_loss=0.099]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.00it/s, train_loss=0.099]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.00it/s, train_loss=0.573]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32 average loss: 0.3250\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  29%|██▉       | 32/110 [13:23<32:37, 25.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 32 current AUC: 0.9979 current accuracy: 0.8882 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 33/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.89it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.89it/s, train_loss=0.0793]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.14it/s, train_loss=0.0793]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.14it/s, train_loss=0.518] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.95it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.95it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.02it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.02it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.01it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.01it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.94it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.94it/s, train_loss=0.1]  \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.553]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.30it/s, train_loss=0.553]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.30it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:20,  5.34it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:20,  5.34it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.23it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.23it/s, train_loss=0.546] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.17it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.17it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.05it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.05it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.98it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.98it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.02it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.02it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.95it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.95it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.95it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.95it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.03it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.03it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.19it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.19it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.05it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.05it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.18it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.18it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.27it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.27it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.28it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.28it/s, train_loss=0.744]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.28it/s, train_loss=0.744]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.28it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.34it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.34it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.06it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.06it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.24it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.24it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.17it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.17it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.06it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.06it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.88it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.88it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.83it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.83it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.86it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.86it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.80it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.80it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:18,  4.72it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.72it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.89it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.89it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.79it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.79it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.87it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.87it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.06it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.06it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.14it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.14it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.29it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.29it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.02it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.02it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.05it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.05it/s, train_loss=0.36] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.95it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.95it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.95it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.95it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.07it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.07it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.04it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.04it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.78it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.78it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.12it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.12it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.01it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.01it/s, train_loss=0.0643]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.09it/s, train_loss=0.0643]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.09it/s, train_loss=0.464] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.10it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.10it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.16it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.16it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.97it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.97it/s, train_loss=0.68] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.00it/s, train_loss=0.68]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.00it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.83it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.83it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.11it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.11it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.18it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.18it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.04it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.04it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.05it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.05it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.95it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.95it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.76it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.76it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.03it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.03it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.06it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.06it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.96it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.96it/s, train_loss=0.575]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.00it/s, train_loss=0.575]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.00it/s, train_loss=0.744]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.01it/s, train_loss=0.744]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.01it/s, train_loss=0.0968]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.04it/s, train_loss=0.0968]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.04it/s, train_loss=0.276] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.09it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.09it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.03it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.03it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.08it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.08it/s, train_loss=0.259] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.98it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.98it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.83it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.83it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.13it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.13it/s, train_loss=0.24] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.93it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.93it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.84it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.84it/s, train_loss=0.0758]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.76it/s, train_loss=0.0758]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.76it/s, train_loss=0.403] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.88it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.88it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.25it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.25it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.31it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:07,  5.31it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.21it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.21it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.23it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.23it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.34it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.34it/s, train_loss=0.35] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.38it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.38it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.28it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.28it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.17it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.17it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.14it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.14it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.17it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.17it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.01it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.01it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.95it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.95it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.08it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.08it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.97it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.97it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.35it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.35it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.22it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.22it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.10it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.10it/s, train_loss=0.0639]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.0639]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.02it/s, train_loss=0.42]  \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.73it/s, train_loss=0.42]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.73it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.90it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.90it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.83it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.83it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.86it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.86it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.82it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.82it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.75it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.75it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.68it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.68it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.74it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.74it/s, train_loss=1.07] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.05it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.05it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.93it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.93it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.02it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.02it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.97it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.97it/s, train_loss=0.756]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.83it/s, train_loss=0.756]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.83it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.94it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.94it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.82it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.82it/s, train_loss=0.36] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.04it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.04it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.18it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.18it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.02it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.02it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.21it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.21it/s, train_loss=0.194] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.40it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.40it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.22it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.22it/s, train_loss=1.1]  \n",
      "\u001b[A                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33 average loss: 0.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  30%|███       | 33/110 [13:48<32:03, 24.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 33 current AUC: 0.9918 current accuracy: 0.8758 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 34/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.49it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.49it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.99it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.99it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.99it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.99it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.00it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.00it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.93it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.93it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.99it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.99it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.02it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.02it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.02it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.02it/s, train_loss=0.571]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.15it/s, train_loss=0.571]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.15it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.04it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.04it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.20it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.20it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.30it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.30it/s, train_loss=0.44] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.09it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.09it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.05it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.05it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.96it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.96it/s, train_loss=0.0693]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.02it/s, train_loss=0.0693]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.02it/s, train_loss=0.143] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.16it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.16it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.22it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.22it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:18,  5.40it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:18,  5.40it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.15it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.15it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.96it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.96it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.08it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.08it/s, train_loss=0.204] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.28it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.28it/s, train_loss=0.38] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.09it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.09it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.02it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.02it/s, train_loss=0.423] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.09it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.09it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.08it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.08it/s, train_loss=0.0715]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.12it/s, train_loss=0.0715]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.12it/s, train_loss=0.319] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.25it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.25it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.849]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.79it/s, train_loss=0.849]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.79it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.99it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.99it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.19it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.19it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.27it/s, train_loss=0.554]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.27it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.26it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.26it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.29it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.29it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.26it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.26it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.05it/s, train_loss=0.637]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.05it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.97it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.97it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  5.00it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  5.00it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.98it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.98it/s, train_loss=0.404] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.02it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.02it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.05it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.05it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.79it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.79it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.91it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.91it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.08it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.08it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.12it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.12it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.02it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.02it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.96it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.96it/s, train_loss=0.608]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.89it/s, train_loss=0.608]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.89it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.09it/s, train_loss=0.522]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.09it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.00it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.00it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.98it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.98it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.09it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.09it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.18it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.18it/s, train_loss=0.26] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:11,  5.46it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:11,  5.46it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.40it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.40it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.28it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.28it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:11,  5.18it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.18it/s, train_loss=0.0957]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.14it/s, train_loss=0.0957]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.14it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.15it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.15it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.99it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.99it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.90it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.90it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  4.94it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.94it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.02it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.02it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.96it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.96it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.07it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.07it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.13it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.13it/s, train_loss=0.2]  \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.20it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.20it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.33it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.33it/s, train_loss=0.494] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.28it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.28it/s, train_loss=0.0938]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.07it/s, train_loss=0.0938]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.07it/s, train_loss=0.386] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.36it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.36it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.08it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.08it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.09it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.09it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.23it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.23it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.90it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.90it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.84it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.84it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.89it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.89it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.07it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.07it/s, train_loss=0.582]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.19it/s, train_loss=0.582]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.19it/s, train_loss=0.64] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.33it/s, train_loss=0.64]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.33it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.52it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.52it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.49it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.49it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.38it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.38it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.15it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.15it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.09it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.09it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.93it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.93it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.13it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.13it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.11it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.11it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.12it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.12it/s, train_loss=0.0967]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.26it/s, train_loss=0.0967]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.26it/s, train_loss=0.134] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:18<00:04,  5.23it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.23it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.21it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.21it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.04it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.04it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.07it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.07it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.97it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.97it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:19<00:03,  5.17it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.17it/s, train_loss=0.0962]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.12it/s, train_loss=0.0962]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.12it/s, train_loss=0.375] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.23it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.23it/s, train_loss=0.76] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.06it/s, train_loss=0.76]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.06it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.03it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.03it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:20<00:02,  5.12it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.12it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.13it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.13it/s, train_loss=0.0899]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.12it/s, train_loss=0.0899]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.12it/s, train_loss=0.132] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.18it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.18it/s, train_loss=0.0986]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.19it/s, train_loss=0.0986]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.19it/s, train_loss=0.487] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:01,  5.24it/s, train_loss=0.487]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.24it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.11it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.11it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.91it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.91it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.77it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.77it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.85it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.85it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:22<00:01,  4.94it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.07it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.07it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.97it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.97it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.88it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.88it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.80it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.80it/s, train_loss=2.4]  \n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:23<00:00,  5.59it/s, train_loss=2.4]\n",
      "\u001b[A                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34 average loss: 0.3004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  31%|███       | 34/110 [14:13<31:27, 24.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 34 current AUC: 0.9921 current accuracy: 0.8696 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 35/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.86it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.86it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.87it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.87it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.87it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.87it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.90it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.90it/s, train_loss=0.74] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.08it/s, train_loss=0.74]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.08it/s, train_loss=0.4] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.10it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.10it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.28it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.28it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.28it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.28it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.10it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.10it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.19it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.19it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.14it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.14it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.42it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.42it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:19,  5.47it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:19,  5.47it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.28it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.28it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:19,  5.35it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:19,  5.35it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.20it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.20it/s, train_loss=0.0698]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.27it/s, train_loss=0.0698]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.27it/s, train_loss=0.126] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.33it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.33it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.19it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.19it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.23it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.23it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.40it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.40it/s, train_loss=0.634]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.21it/s, train_loss=0.634]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.21it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.17it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.17it/s, train_loss=0.237] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.951]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.93it/s, train_loss=0.951]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.93it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.09it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.09it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.15it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.15it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.09it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.09it/s, train_loss=0.0703]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.0703]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.158] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.02it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.02it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.01it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.01it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.92it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.92it/s, train_loss=0.664]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.16it/s, train_loss=0.664]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.16it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.14it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.14it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.97it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.97it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.04it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.04it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.15it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.15it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.18it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.18it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.98it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.98it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.16it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.16it/s, train_loss=0.49] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:07<00:15,  5.18it/s, train_loss=0.49]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.18it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.02it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.02it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.03it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.03it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.91it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.91it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:16,  4.75it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.75it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.86it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.86it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.83it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.83it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.21it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.21it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.05it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.05it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.15it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.15it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.14it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.14it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.96it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.96it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.05it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.05it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.96it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.96it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:13,  4.99it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.99it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.11it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.11it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.11it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.11it/s, train_loss=0.457]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.14it/s, train_loss=0.457]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.14it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:11,  5.20it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.20it/s, train_loss=0.26] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.16it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.16it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.97it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.97it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.86it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.86it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.00it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.00it/s, train_loss=0.6]  \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  4.88it/s, train_loss=0.6]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.88it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.88it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.88it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.01it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.01it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.10it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.10it/s, train_loss=0.64] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.85it/s, train_loss=0.64]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.85it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  4.96it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.96it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.93it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.93it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.88it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.88it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.68it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.68it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.71it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.71it/s, train_loss=0.149] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.87it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.87it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.97it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.97it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.05it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.05it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.03it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.03it/s, train_loss=0.0484]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.13it/s, train_loss=0.0484]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.13it/s, train_loss=0.185] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.13it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.13it/s, train_loss=0.457]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.32it/s, train_loss=0.457]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.32it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.26it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.26it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.37it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.37it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.56it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.56it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.35it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.35it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.35it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.35it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.10it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.10it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.14it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.14it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.08it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.08it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.00it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.00it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.07it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.07it/s, train_loss=0.556]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.556]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=1.23] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=1.23]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.98it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.98it/s, train_loss=0.628]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.93it/s, train_loss=0.628]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.93it/s, train_loss=0.26] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.08it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.08it/s, train_loss=0.073]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.08it/s, train_loss=0.073]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.08it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.09it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.09it/s, train_loss=0.0794]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.0794]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.331] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.06it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.06it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.24it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.24it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.04it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.04it/s, train_loss=0.6]  \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.05it/s, train_loss=0.6]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.05it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.05it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.05it/s, train_loss=0.29] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.99it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.99it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.77it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.77it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.14it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.14it/s, train_loss=0.47]  \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.06it/s, train_loss=0.47]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.06it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.04it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.04it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.03it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.03it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.27it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.27it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.25it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.25it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.26it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.26it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.08it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.08it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  5.00it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  5.00it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.15it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.15it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.17it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.17it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.26it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.26it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.11it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.11it/s, train_loss=0.921]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:23<00:00,  5.90it/s, train_loss=0.921]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35 average loss: 0.3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  32%|███▏      | 35/110 [14:37<30:55, 24.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 35 current AUC: 0.9896 current accuracy: 0.8634 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 36/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.532]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.17it/s, train_loss=0.532]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.17it/s, train_loss=0.38] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.11it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.11it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.87it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.87it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:25,  4.56it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:25,  4.56it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.70it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.70it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.78it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.78it/s, train_loss=0.994]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.84it/s, train_loss=0.994]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.84it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.73it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.73it/s, train_loss=0.484]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:24,  4.70it/s, train_loss=0.484]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:24,  4.70it/s, train_loss=0.0545]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.06it/s, train_loss=0.0545]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.06it/s, train_loss=0.263] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.96it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.96it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.08it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.08it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.09it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.09it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.06it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  5.06it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.87it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.87it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.08it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.08it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.83it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.83it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.82it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.82it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.80it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:21,  4.80it/s, train_loss=0.0702]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.92it/s, train_loss=0.0702]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.92it/s, train_loss=0.337] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.38] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.06it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.06it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.18it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.18it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.25it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:18,  5.25it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:17,  5.48it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:17,  5.48it/s, train_loss=0.0744]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.48it/s, train_loss=0.0744]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.48it/s, train_loss=0.302] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.24it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.24it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.25it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.25it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.12it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.12it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.09it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.09it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.16it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.16it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.07it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.07it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.95it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.95it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.95it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.95it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.02it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.02it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.16it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.16it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.04it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.04it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.552]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.09it/s, train_loss=0.552]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.09it/s, train_loss=0.0807]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.11it/s, train_loss=0.0807]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.11it/s, train_loss=0.435] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.98it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.98it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.19it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.19it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.27it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.27it/s, train_loss=0.142] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.17it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.17it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.09it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.09it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.28it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.28it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.86it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.86it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.88it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.88it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.90it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.90it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.80it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.80it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.78it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.78it/s, train_loss=0.308] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.84it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.84it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.93it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  4.93it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:14,  4.78it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:14,  4.78it/s, train_loss=0.124] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.79it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.79it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.89it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.89it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.72it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.72it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.71it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:13,  4.71it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.81it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.81it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.83it/s, train_loss=0.658]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.83it/s, train_loss=0.0848]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.90it/s, train_loss=0.0848]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.90it/s, train_loss=0.295] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.81it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.81it/s, train_loss=0.55] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.96it/s, train_loss=0.55]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  4.96it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.91it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.91it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.03it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.03it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.15it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.15it/s, train_loss=0.89] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.18it/s, train_loss=0.89]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  5.18it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.26it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.26it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.18it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.18it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.19it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.19it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.19it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.19it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.34it/s, train_loss=0.442]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:08,  5.34it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.34it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.34it/s, train_loss=0.587]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.13it/s, train_loss=0.587]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.13it/s, train_loss=0.082]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.30it/s, train_loss=0.082]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.30it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.18it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.18it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.16it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.16it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.22it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.22it/s, train_loss=0.0731]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.10it/s, train_loss=0.0731]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.10it/s, train_loss=1.22]  \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.20it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.20it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.01it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.01it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.38it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:06,  5.38it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.34it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.34it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.47it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.47it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.18it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.18it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.35it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.35it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.14it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.14it/s, train_loss=0.0916]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.00it/s, train_loss=0.0916]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.00it/s, train_loss=0.576] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.08it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.08it/s, train_loss=0.633]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.96it/s, train_loss=0.633]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.96it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.91it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.91it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.87it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.87it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.97it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.97it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.98it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.98it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.98it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.98it/s, train_loss=0.44]  \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.84it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.84it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.88it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.88it/s, train_loss=0.57] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.90it/s, train_loss=0.57]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.90it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.83it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.83it/s, train_loss=0.38] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.02it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.02it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.19it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.19it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.93it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.93it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.17it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.17it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.96it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.96it/s, train_loss=0.164] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.89it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.89it/s, train_loss=0.094]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.95it/s, train_loss=0.094]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.95it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.09it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.09it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.95it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.95it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.24it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.24it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.22it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.22it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.15it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.15it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.99it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.99it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.01it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.01it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.92it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.92it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.97it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.97it/s, train_loss=0.0763]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.32it/s, train_loss=0.0763]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.32it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.21it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.21it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  6.08it/s, train_loss=0.0304]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36 average loss: 0.2909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  33%|███▎      | 36/110 [15:02<30:30, 24.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 36 current AUC: 0.9926 current accuracy: 0.8882 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 37/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:18,  6.59it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:18,  6.59it/s, train_loss=0.26] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.54it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.54it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.07it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.07it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.05it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.05it/s, train_loss=0.733]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.14it/s, train_loss=0.733]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.14it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.12it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.12it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.19it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.19it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.24it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.24it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.10it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.10it/s, train_loss=0.38] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.09it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.09it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.09it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.09it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.07it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.07it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.04it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.04it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.17it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.17it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.02it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.02it/s, train_loss=0.0954]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.11it/s, train_loss=0.0954]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.11it/s, train_loss=0.247] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.95it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.95it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.83it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.83it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.78it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.78it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.88it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.88it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.97it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.97it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.75it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.75it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.83it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.83it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.121] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.22it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.22it/s, train_loss=0.0969]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.15it/s, train_loss=0.0969]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.15it/s, train_loss=0.323] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.01it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.01it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.74it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.74it/s, train_loss=0.0847]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.89it/s, train_loss=0.0847]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.89it/s, train_loss=0.267] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.93it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.93it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.91it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.91it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.06it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.06it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.10it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.10it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.09it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.09it/s, train_loss=0.627]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.07it/s, train_loss=0.627]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.07it/s, train_loss=0.0637]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.98it/s, train_loss=0.0637]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.98it/s, train_loss=0.129] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.00it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.00it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.23it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.23it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.10it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.10it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.21it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.21it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.04it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.04it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.89it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.89it/s, train_loss=0.2]  \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.97it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.97it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.82it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.82it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.82it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.82it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.94it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.94it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.78it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.78it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.98it/s, train_loss=0.671]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.98it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.83it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.83it/s, train_loss=0.32] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:15,  4.71it/s, train_loss=0.32]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:15,  4.71it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.82it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.82it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.95it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.95it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.21it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.21it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.03it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.03it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.89it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.89it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.97it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.97it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.99it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.99it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.97it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.97it/s, train_loss=0.0838]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.07it/s, train_loss=0.0838]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.07it/s, train_loss=0.196] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.96it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.96it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.11it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.11it/s, train_loss=0.483]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.16it/s, train_loss=0.483]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.16it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.09it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.09it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.09it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.09it/s, train_loss=0.934]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.30it/s, train_loss=0.934]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.30it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.99it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.99it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.00it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.00it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.05it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.05it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.92it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.92it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.97it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.97it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.86it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.86it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.89it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.89it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.99it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.99it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.13it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.13it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.06it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.06it/s, train_loss=0.771]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.03it/s, train_loss=0.771]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.03it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.85it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.85it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.94it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.94it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.91it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.91it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.81it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.81it/s, train_loss=0.0931]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.83it/s, train_loss=0.0931]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.83it/s, train_loss=0.122] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.89it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  4.89it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.91it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.91it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.90it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.90it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.79it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.79it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.94it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.94it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.18it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  5.18it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.97it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.97it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.04it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.04it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.89it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.89it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.84it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.84it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.98it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.98it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.99it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.99it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.97it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.97it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.0654]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.99it/s, train_loss=0.0654]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.99it/s, train_loss=0.707] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.87it/s, train_loss=0.707]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:20<00:04,  4.87it/s, train_loss=0.673]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.92it/s, train_loss=0.673]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.92it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.14it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.14it/s, train_loss=0.479]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.34it/s, train_loss=0.479]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.34it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.26it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.26it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.12it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  5.12it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.94it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.94it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.97it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.97it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.93it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.93it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.00it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  5.00it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.93it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.93it/s, train_loss=0.44]  \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.09it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.09it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.24it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.24it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.27it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.27it/s, train_loss=0.4]  \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.05it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.05it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.00it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.00it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.87it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.87it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.86it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.86it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.09it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.09it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.99it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.99it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.24it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.24it/s, train_loss=0.624]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  6.09it/s, train_loss=0.624]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37 average loss: 0.2946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  34%|███▎      | 37/110 [15:27<30:08, 24.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 37 current AUC: 0.9950 current accuracy: 0.8634 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 38/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.21it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.21it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.19it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.19it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.50it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.50it/s, train_loss=0.079]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.35it/s, train_loss=0.079]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.35it/s, train_loss=0.499]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.24it/s, train_loss=0.499]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.24it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.15it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.15it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.13it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.13it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.87it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.87it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.81it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.81it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.00it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.00it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.87it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.87it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.76it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.76it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.88it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.88it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.09it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.09it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.20it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.20it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.31it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.31it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.24it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.24it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.07it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.07it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.09it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.09it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.02it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.02it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.99it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.99it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.01it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.01it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.00it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.00it/s, train_loss=0.427]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.20it/s, train_loss=0.427]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.20it/s, train_loss=0.46] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.16it/s, train_loss=0.46]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.16it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.01it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.01it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.06it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.06it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.10it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.10it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.84it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.84it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.90it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.90it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.00it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.00it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.96it/s, train_loss=0.445]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.96it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.15it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.15it/s, train_loss=0.661]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.94it/s, train_loss=0.661]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.94it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.03it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.03it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.01it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.01it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.499]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.04it/s, train_loss=0.499]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.04it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.03it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.03it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.82it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.82it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.87it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.87it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.88it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.88it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.99it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.99it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.05it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.05it/s, train_loss=0.616]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.17it/s, train_loss=0.616]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.17it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.09it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.09it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.34it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.34it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.44it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.44it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.39it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.39it/s, train_loss=0.852]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:12,  5.47it/s, train_loss=0.852]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:12,  5.47it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.99it/s, train_loss=0.534]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.99it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.13it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.13it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.06it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.06it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.10it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.10it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.86it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.86it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.88it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.88it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.94it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.94it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.84it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.84it/s, train_loss=0.379]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.98it/s, train_loss=0.379]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.98it/s, train_loss=0.0951]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.30it/s, train_loss=0.0951]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.30it/s, train_loss=0.576] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.42it/s, train_loss=0.576]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.42it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.22it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.22it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.83it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.83it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.0797]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.12it/s, train_loss=0.0797]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.12it/s, train_loss=0.268] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.02it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.02it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.13it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.13it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.14it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.14it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.16it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.16it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.01it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.01it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.99it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.99it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.00it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.00it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.05it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.05it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.18it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.18it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.20it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.20it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:07,  5.44it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:07,  5.44it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.32it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.32it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.21it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.21it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.13it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.13it/s, train_loss=0.086]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.29it/s, train_loss=0.086]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.29it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.37it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.37it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.27it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.27it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.07it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.07it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.09it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.09it/s, train_loss=0.0939]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.19it/s, train_loss=0.0939]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.19it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.30it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.30it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.42it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.42it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.27it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.27it/s, train_loss=0.833]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.22it/s, train_loss=0.833]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.22it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.16it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.16it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.95it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.95it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.13it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.13it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.09it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.09it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.16it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.16it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.21it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.21it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.32it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.32it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.33it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.33it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:19<00:03,  5.44it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.44it/s, train_loss=0.594] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.26it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.26it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.98it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.98it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.80it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.80it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.82it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.82it/s, train_loss=0.625]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.06it/s, train_loss=0.625]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.06it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.04it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.04it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.16it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.16it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.99it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.99it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.88it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.88it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.82it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.82it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.02it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.02it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.08it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.08it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.05it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.05it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.08it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.08it/s, train_loss=0.0419]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.02it/s, train_loss=0.0419]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.02it/s, train_loss=0.247] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.01it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.01it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.12it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.12it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.20it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.20it/s, train_loss=0.0985]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.04it/s, train_loss=0.0985]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.04it/s, train_loss=1.46]  \n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:23<00:00,  5.79it/s, train_loss=1.46]\n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38 average loss: 0.2943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  35%|███▍      | 38/110 [15:51<29:38, 24.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 38 current AUC: 0.9960 current accuracy: 0.8944 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 39/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.30it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.30it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.80it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.80it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.65it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.65it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:25,  4.61it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:25,  4.61it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.82it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.82it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.04it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.04it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.03it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.03it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.08it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.08it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.00it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  5.00it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.04it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.04it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.84it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.84it/s, train_loss=0.0826]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.99it/s, train_loss=0.0826]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.99it/s, train_loss=0.311] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.03it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.03it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.97it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  4.97it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.05it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.05it/s, train_loss=0.858]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.15it/s, train_loss=0.858]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.15it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.36it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.36it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.43it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.43it/s, train_loss=0.0904]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.40it/s, train_loss=0.0904]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.40it/s, train_loss=0.307] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:18,  5.50it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:18,  5.50it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.38it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.38it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.55it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.55it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.98it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.98it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.06it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.06it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.95it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.95it/s, train_loss=0.0989]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.0989]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=1.22]  \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.93it/s, train_loss=1.22]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.93it/s, train_loss=0.0807]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.07it/s, train_loss=0.0807]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.07it/s, train_loss=0.545] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.10it/s, train_loss=0.545]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.10it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.06it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.06it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.13it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.13it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.86it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.86it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.97it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.97it/s, train_loss=1.16] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.89it/s, train_loss=1.16]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.89it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  5.00it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  5.00it/s, train_loss=0.458] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.88it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.88it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.90it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.90it/s, train_loss=0.566]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:17,  4.74it/s, train_loss=0.566]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:17,  4.74it/s, train_loss=0.0919]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:17,  4.61it/s, train_loss=0.0919]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:17,  4.61it/s, train_loss=0.685] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.80it/s, train_loss=0.685]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.80it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.69it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.69it/s, train_loss=0.064]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.85it/s, train_loss=0.064]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.85it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.91it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.91it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.78it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.78it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.71it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.71it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.86it/s, train_loss=0.518]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:15,  4.86it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.89it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.89it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.00it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.00it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.13it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.13it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.18it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.18it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.03it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.03it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.08it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.08it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.08it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.08it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.80it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.80it/s, train_loss=0.0638]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.79it/s, train_loss=0.0638]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.79it/s, train_loss=0.509] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.84it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:13,  4.84it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.18it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.18it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.14it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.14it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.14it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.14it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.98it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.98it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.96it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  4.96it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.90it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.90it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.95it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.95it/s, train_loss=0.667]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.87it/s, train_loss=0.667]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.87it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.95it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.95it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.95it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  4.95it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.13it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.13it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.92it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.92it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.0833]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.05it/s, train_loss=0.0833]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.05it/s, train_loss=0.23]  \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.18it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  5.18it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.09it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.09it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.13it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.13it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.97it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.97it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.03it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.03it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.11it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:08,  5.11it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.88it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.88it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.01it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.01it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.84it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.84it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.07it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  5.07it/s, train_loss=0.093]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.87it/s, train_loss=0.093]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.87it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.99it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.99it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.89it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.89it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.88it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.88it/s, train_loss=0.0863]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.99it/s, train_loss=0.0863]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  4.99it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.11it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.11it/s, train_loss=0.666]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.16it/s, train_loss=0.666]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.16it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.97it/s, train_loss=0.528]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.97it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.81it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.81it/s, train_loss=0.611]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.90it/s, train_loss=0.611]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.90it/s, train_loss=0.735]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.03it/s, train_loss=0.735]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.03it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.17it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.17it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.29it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.29it/s, train_loss=0.463] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.95it/s, train_loss=0.463]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:20<00:04,  4.95it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.03it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.03it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.85it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.85it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.04it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.04it/s, train_loss=0.555]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.16it/s, train_loss=0.555]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.16it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.27it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.27it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.12it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.12it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.89it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.89it/s, train_loss=0.0915]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.02it/s, train_loss=0.0915]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.02it/s, train_loss=0.254] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.09it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.09it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.00it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  5.00it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.81it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.81it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.82it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.82it/s, train_loss=0.639]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.80it/s, train_loss=0.639]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.80it/s, train_loss=0.643]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.91it/s, train_loss=0.643]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.91it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.07it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  5.07it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.08it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.08it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.96it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.96it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.12it/s, train_loss=0.496]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.12it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.20it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.20it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.26it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.26it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.10it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.10it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=2.33] \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 average loss: 0.3218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  35%|███▌      | 39/110 [16:16<29:17, 24.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 39 current AUC: 0.9956 current accuracy: 0.8882 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 40/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.735]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  5.02it/s, train_loss=0.735]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  5.02it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.38it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.38it/s, train_loss=0.0734]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.42it/s, train_loss=0.0734]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.42it/s, train_loss=0.28]  \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.27it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.27it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:24,  4.87it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.87it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.87it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.87it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.27it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.27it/s, train_loss=0.57] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.15it/s, train_loss=0.57]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.15it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.09it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.09it/s, train_loss=0.48] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.10it/s, train_loss=0.48]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.10it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.89it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.89it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.93it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.93it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.88it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.88it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  4.91it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.91it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.93it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.93it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.03it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.03it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.93it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.93it/s, train_loss=0.17] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.96it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  4.96it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.85it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.85it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.90it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.90it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.06it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.06it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.09it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.09it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.08it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.18it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.18it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.13it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.13it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.11it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.11it/s, train_loss=0.0729]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.96it/s, train_loss=0.0729]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.96it/s, train_loss=0.0801]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.21it/s, train_loss=0.0801]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.21it/s, train_loss=0.172] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.02it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.02it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.21it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.21it/s, train_loss=0.853]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.06it/s, train_loss=0.853]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.06it/s, train_loss=0.0759]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.06it/s, train_loss=0.0759]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.06it/s, train_loss=0.0428]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.01it/s, train_loss=0.0428]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.01it/s, train_loss=0.364] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.95it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.95it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.24it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.24it/s, train_loss=0.548]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.15it/s, train_loss=0.548]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.15it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.13it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.13it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.07it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.07it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.05it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.05it/s, train_loss=0.517]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.98it/s, train_loss=0.517]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.98it/s, train_loss=0.555]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.98it/s, train_loss=0.555]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.98it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.17it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.17it/s, train_loss=0.0677]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.44it/s, train_loss=0.0677]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.44it/s, train_loss=0.408] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.24it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.24it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.31it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.31it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.26it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.26it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.14it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.14it/s, train_loss=0.544]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.95it/s, train_loss=0.544]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.95it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.22it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.22it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.23it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.23it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.18it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.18it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.05it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.05it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.15it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.15it/s, train_loss=0.0988]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.23it/s, train_loss=0.0988]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.23it/s, train_loss=0.344] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.41it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.41it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:11,  5.49it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:11,  5.49it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.27it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.27it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.09it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.09it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.83it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.83it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.88it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.88it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.15it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.15it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.98it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.98it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.88it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.88it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.95it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.95it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.81it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.81it/s, train_loss=0.801]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.77it/s, train_loss=0.801]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.77it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.71it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.71it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.81it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.81it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.89it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.89it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.94it/s, train_loss=0.659]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.94it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  5.00it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  5.00it/s, train_loss=0.607]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.06it/s, train_loss=0.607]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.06it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.83it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.83it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.85it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.85it/s, train_loss=0.0801]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.81it/s, train_loss=0.0801]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.81it/s, train_loss=0.115] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.88it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.88it/s, train_loss=0.684]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.95it/s, train_loss=0.684]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.95it/s, train_loss=0.0637]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.98it/s, train_loss=0.0637]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.98it/s, train_loss=0.672] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.94it/s, train_loss=0.672]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.94it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.07it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.07it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.91it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.91it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.85it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.85it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.02it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.02it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.89it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.89it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.91it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.91it/s, train_loss=0.614]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.614]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.00it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.00it/s, train_loss=0.997] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.07it/s, train_loss=0.997]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.07it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.16it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.16it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.02it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.02it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.95it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.95it/s, train_loss=0.49] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.96it/s, train_loss=0.49]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.96it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.07it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.07it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.16it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.16it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.96it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.96it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.08it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.08it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.03it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.03it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.13it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.13it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.25it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.25it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.16it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.16it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.0722]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.10it/s, train_loss=0.0722]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.10it/s, train_loss=0.335] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.99it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.99it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.77it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.77it/s, train_loss=0.35] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.99it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.99it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.07it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.07it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.09it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.09it/s, train_loss=0.0568]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.18it/s, train_loss=0.0568]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.18it/s, train_loss=0.153] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.07it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.07it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.89it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.89it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.94it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.94it/s, train_loss=0.0959]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.19it/s, train_loss=0.0959]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.19it/s, train_loss=0.171] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.19it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.19it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.01it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.01it/s, train_loss=0.0528]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.07it/s, train_loss=0.0528]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.07it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.25it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.25it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.93it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.93it/s, train_loss=0.867]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.21it/s, train_loss=0.867]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.21it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.25it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.25it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.32it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.32it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  6.16it/s, train_loss=0.135]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40 average loss: 0.2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  36%|███▋      | 40/110 [16:41<28:50, 24.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 40 current AUC: 0.9960 current accuracy: 0.8944 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 41/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.39it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.39it/s, train_loss=0.0728]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.11it/s, train_loss=0.0728]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.11it/s, train_loss=0.663] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.92it/s, train_loss=0.663]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.92it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.96it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.96it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.13it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.13it/s, train_loss=0.0289]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.00it/s, train_loss=0.0289]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.00it/s, train_loss=0.345] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.01it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.01it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.83it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.83it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.94it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.94it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.10it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.10it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.01it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.01it/s, train_loss=0.0643]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.14it/s, train_loss=0.0643]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.14it/s, train_loss=0.548] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.08it/s, train_loss=0.548]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.08it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.02it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.02it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.15it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.15it/s, train_loss=0.34] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.00it/s, train_loss=0.34]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.00it/s, train_loss=0.597]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.94it/s, train_loss=0.597]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.94it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.01it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.01it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.88it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:21,  4.88it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.81it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.81it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.92it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.92it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.09it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.09it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.19it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.19it/s, train_loss=0.0816]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.03it/s, train_loss=0.0816]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.03it/s, train_loss=0.724] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.93it/s, train_loss=0.724]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.93it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.25it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.25it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.17it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.17it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.27it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.27it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.09it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.09it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.07it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.07it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.08it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.08it/s, train_loss=0.22]  \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.05it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.05it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.25it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.25it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.41it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.41it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.26it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.26it/s, train_loss=0.52] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.30it/s, train_loss=0.52]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.30it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.17it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.17it/s, train_loss=0.586]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.15it/s, train_loss=0.586]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.15it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.25it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.25it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.14it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.14it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.32it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.32it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.27it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.27it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.24it/s, train_loss=0.478]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.24it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.17it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.17it/s, train_loss=0.206] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:13,  5.55it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:13,  5.55it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:14,  5.42it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.42it/s, train_loss=0.0624]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.49it/s, train_loss=0.0624]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.49it/s, train_loss=0.736] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.17it/s, train_loss=0.736]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.17it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.00it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.00it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.89it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.89it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:14,  4.94it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.94it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.01it/s, train_loss=0.535]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.01it/s, train_loss=0.82] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.86it/s, train_loss=0.82]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.86it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.96it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.96it/s, train_loss=1.1]  \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.14it/s, train_loss=1.1]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.14it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.18it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.18it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.04it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.04it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.85it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.85it/s, train_loss=0.0966]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.86it/s, train_loss=0.0966]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.86it/s, train_loss=0.133] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.84it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.84it/s, train_loss=0.0813]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:11,  5.17it/s, train_loss=0.0813]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.17it/s, train_loss=0.395] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.04it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.04it/s, train_loss=0.0905]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.12it/s, train_loss=0.0905]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.12it/s, train_loss=0.266] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.13it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.13it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.12it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.12it/s, train_loss=0.1]  \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.17it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.17it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.01it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.01it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.93it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.93it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.94it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.94it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.98it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.98it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  5.00it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.00it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.89it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.89it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.87it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.87it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.84it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.84it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.83it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.83it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.88it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.88it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.90it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.90it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.78it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.78it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.86it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.86it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.97it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.97it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.0602]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.03it/s, train_loss=0.0602]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.03it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.09it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.09it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.91it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.91it/s, train_loss=0.375] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.12it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.12it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.97it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.97it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.93it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.93it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.91it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.91it/s, train_loss=0.29] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.88it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.88it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.82it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.82it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.87it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.87it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.99it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.99it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.97it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.97it/s, train_loss=0.191] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.85it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.85it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.96it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.96it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.88it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.88it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.87it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.87it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.07it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.07it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.24it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.24it/s, train_loss=0.089]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.15it/s, train_loss=0.089]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.15it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.33it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.33it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.19it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.19it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.31it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.31it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.23it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.23it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.35it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.35it/s, train_loss=0.0971]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:02,  5.46it/s, train_loss=0.0971]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:02,  5.46it/s, train_loss=0.311] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.30it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.30it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.23it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.23it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.38it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.38it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.16it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.16it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.42it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.42it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.17it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.17it/s, train_loss=0.0277]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.02it/s, train_loss=0.0277]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.02it/s, train_loss=0.407] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.08it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.08it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.28it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.28it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.24it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.24it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.17it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.17it/s, train_loss=0.675]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.14it/s, train_loss=0.675]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.14it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.14it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.14it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.02it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.02it/s, train_loss=0.0492]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.02it/s, train_loss=0.0492]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.02it/s, train_loss=1.72]  \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41 average loss: 0.2767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  37%|███▋      | 41/110 [17:05<28:22, 24.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 41 current AUC: 0.9939 current accuracy: 0.9006 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 42/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.33it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.33it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.79it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.79it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.97it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.97it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.02it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.02it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.10it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.10it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.02it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.02it/s, train_loss=0.118] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.96it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.96it/s, train_loss=0.32] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.12it/s, train_loss=0.32]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.12it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.17it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.17it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.07it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.07it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.18it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.18it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.02it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.02it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.32it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.32it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.37it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.37it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.26it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.26it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.10it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.10it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.07it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.07it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.10it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.10it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.95it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.95it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.92it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.92it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.73it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.73it/s, train_loss=0.218] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.91it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.91it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.94it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.94it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=0.93] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.06it/s, train_loss=0.93]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.06it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.19it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.19it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.01it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.01it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.18it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.18it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.38it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.38it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.35it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.35it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.0604]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.37it/s, train_loss=0.0604]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.37it/s, train_loss=0.281] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.42it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.42it/s, train_loss=0.572]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.47it/s, train_loss=0.572]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.47it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:15,  5.56it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:15,  5.56it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:06<00:15,  5.69it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:15,  5.69it/s, train_loss=0.0399]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.44it/s, train_loss=0.0399]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.44it/s, train_loss=0.0382]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.21it/s, train_loss=0.0382]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.21it/s, train_loss=0.151] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.07it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.07it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.09it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.09it/s, train_loss=0.0759]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:07<00:16,  4.99it/s, train_loss=0.0759]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.99it/s, train_loss=0.269] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.94it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.94it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.17it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.17it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.05it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.05it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:16,  4.77it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:16,  4.77it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:14,  5.07it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.07it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.03it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.03it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.31it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.31it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.14it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.14it/s, train_loss=0.17] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.28it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.28it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.08it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.08it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.11it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.11it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.92it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.92it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.85it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.85it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:14,  4.76it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:14,  4.76it/s, train_loss=0.0881]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.73it/s, train_loss=0.0881]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.73it/s, train_loss=0.157] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.75it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.75it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.77it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.77it/s, train_loss=0.0831]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.94it/s, train_loss=0.0831]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.94it/s, train_loss=0.29]  \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.09it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.09it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.98it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.98it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.09it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.09it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.569]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.85] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.90it/s, train_loss=0.85]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.90it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.92it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.92it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.84it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.84it/s, train_loss=0.35] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.94it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.94it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.78it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.78it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.80it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.80it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.89it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.89it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.18it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.18it/s, train_loss=0.733]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.04it/s, train_loss=0.733]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.04it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.92it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.92it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.93it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.93it/s, train_loss=0.0105]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.08it/s, train_loss=0.0105]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.08it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.03it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.03it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.06it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.06it/s, train_loss=0.205] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.30it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.30it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.20it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.20it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.13it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.13it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.05it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.81it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.81it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.97it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.97it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.78it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.78it/s, train_loss=0.0494]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.70it/s, train_loss=0.0494]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.70it/s, train_loss=0.26]  \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.95it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.95it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.92it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.92it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.03it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.03it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.07it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.07it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.30it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.30it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.98it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.98it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.90it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.90it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.86it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.86it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.92it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.92it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.87it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.87it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.02it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.02it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.95it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.95it/s, train_loss=0.651]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.89it/s, train_loss=0.651]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.89it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.89it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.89it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.00it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.00it/s, train_loss=0.382] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.95it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.95it/s, train_loss=0.0696]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.0696]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.0321]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.23it/s, train_loss=0.0321]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.23it/s, train_loss=0.137] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.19it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.19it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.24it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.24it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.24it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.24it/s, train_loss=0.589]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.29it/s, train_loss=0.589]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.29it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.30it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.30it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.27it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.27it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.15it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.15it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.14it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.14it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.27it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.27it/s, train_loss=0.0324]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.47it/s, train_loss=0.0324]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.47it/s, train_loss=0.164] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.20it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.20it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.12it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.12it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.24it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.24it/s, train_loss=0.791]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.04it/s, train_loss=0.791]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.04it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.03it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.03it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.97it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.97it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.93it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.93it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.17it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.17it/s, train_loss=2.35] \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42 average loss: 0.2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  38%|███▊      | 42/110 [17:30<27:56, 24.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 42 current AUC: 0.9944 current accuracy: 0.8820 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 43/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.79it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.79it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.98it/s, train_loss=0.712]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.98it/s, train_loss=0.0597]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.02it/s, train_loss=0.0597]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.02it/s, train_loss=0.266] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.87it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.87it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.01it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.01it/s, train_loss=0.0442]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.92it/s, train_loss=0.0442]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.92it/s, train_loss=0.114] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.84it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.84it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.83it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.83it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.81it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.81it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.83it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.83it/s, train_loss=0.228] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.13it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.13it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.17it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.17it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.20it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.20it/s, train_loss=0.475]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.17it/s, train_loss=0.475]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:20,  5.17it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.06it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.06it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.14it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.14it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.96it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.96it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.09it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.09it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.21it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.21it/s, train_loss=0.0616]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.21it/s, train_loss=0.0616]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.21it/s, train_loss=0.104] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.32it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.32it/s, train_loss=0.0485]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.23it/s, train_loss=0.0485]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.23it/s, train_loss=0.297] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.40it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.40it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.26it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.26it/s, train_loss=0.692]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.18it/s, train_loss=0.692]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.18it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.34it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.34it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.20it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.20it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.07it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.07it/s, train_loss=0.175] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.14it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.14it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.11it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.11it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.03it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.03it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.17it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.17it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.22it/s, train_loss=0.842]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.22it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.15it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.15it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.12it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.12it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.96it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.96it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.83it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.83it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.83it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.83it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.79it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.79it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.85it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.85it/s, train_loss=0.706]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.92it/s, train_loss=0.706]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.92it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.93it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.93it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.04it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.04it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.97it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.97it/s, train_loss=1.12] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.07it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.07it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.94it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.94it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.91it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.91it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.91it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.91it/s, train_loss=0.547]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.04it/s, train_loss=0.547]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.04it/s, train_loss=0.0329]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.08it/s, train_loss=0.0329]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.08it/s, train_loss=0.257] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.14it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.14it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.94it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.94it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.21it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.21it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.20it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.20it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.09it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.09it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.88it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.88it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.86it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.86it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.96it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.96it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.95it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.95it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:13,  4.76it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:13,  4.76it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.98it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.98it/s, train_loss=0.18] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.92it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.92it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.96it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.96it/s, train_loss=1.25] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.83it/s, train_loss=1.25]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.83it/s, train_loss=0.0194]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.94it/s, train_loss=0.0194]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.94it/s, train_loss=0.963] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.90it/s, train_loss=0.963]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.90it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.81it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.81it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.98it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.98it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.01it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.01it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.86it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.86it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.05it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.05it/s, train_loss=0.0726]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.0726]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.104] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.95it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.95it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.75it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.75it/s, train_loss=0.865]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.78it/s, train_loss=0.865]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.78it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.94it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.94it/s, train_loss=0.0764]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.07it/s, train_loss=0.0764]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.07it/s, train_loss=0.0946]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.87it/s, train_loss=0.0946]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.87it/s, train_loss=0.0752]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.73it/s, train_loss=0.0752]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.73it/s, train_loss=0.41]  \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.89it/s, train_loss=0.41]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.89it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.17it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.17it/s, train_loss=0.0775]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.03it/s, train_loss=0.0775]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.03it/s, train_loss=0.236] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.05it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.05it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.10it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  5.10it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.80it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.80it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.01it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.01it/s, train_loss=0.718]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.77it/s, train_loss=0.718]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.77it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.80it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.80it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.88it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  4.88it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.02it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.02it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.95it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.95it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.93it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.93it/s, train_loss=0.0772]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.0772]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.287] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.25it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.25it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.30it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.30it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.32it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.32it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.48it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.48it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.45it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.45it/s, train_loss=0.557]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.68it/s, train_loss=0.557]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.68it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.44it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.44it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.17it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.17it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.35it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.35it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.42it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.42it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.25it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.25it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.32it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.32it/s, train_loss=0.0915]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.16it/s, train_loss=0.0915]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.16it/s, train_loss=0.185] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.30it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.30it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.36it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.36it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.38it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.38it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.18it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.18it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.04it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.04it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.83it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.83it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.87it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.87it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.02it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.02it/s, train_loss=1.36] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.03it/s, train_loss=1.36]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.03it/s, train_loss=0.591]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.12it/s, train_loss=0.591]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.12it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.04it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.04it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.00it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.00it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.01it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.01it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.78it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.78it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.75it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.75it/s, train_loss=0.348]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43 average loss: 0.2933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  39%|███▉      | 43/110 [17:55<27:33, 24.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 43 current AUC: 0.9946 current accuracy: 0.9193 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 44/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.22it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.22it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.61it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.61it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.01it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.01it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.10it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.10it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:21,  5.43it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:21,  5.43it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.86it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.86it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.81it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.81it/s, train_loss=0.269] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.82it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.82it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.95it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.95it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.93it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.93it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.23it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.23it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.06it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.06it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.00it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.00it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.95it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.95it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.01it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.01it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.98it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.98it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.96it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.96it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.03it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.03it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.89it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.89it/s, train_loss=0.253] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.95it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.95it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.88it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.88it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.73it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.73it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.70it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:20,  4.70it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.84it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.84it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.00it/s, train_loss=0.433]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.00it/s, train_loss=0.0705]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.21it/s, train_loss=0.0705]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.21it/s, train_loss=0.512] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.93it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.93it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.92it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  4.92it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.87it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.87it/s, train_loss=0.05]  \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.83it/s, train_loss=0.05]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.83it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.80it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.80it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.90it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.90it/s, train_loss=0.395] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.89it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:18,  4.89it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.98it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.98it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.00it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.00it/s, train_loss=0.0625]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.93it/s, train_loss=0.0625]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.93it/s, train_loss=0.139] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.10it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.10it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.26it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:15,  5.26it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.09it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.09it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.88it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.88it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.80it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.80it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.04it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.04it/s, train_loss=0.625]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.80it/s, train_loss=0.625]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:16,  4.80it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.86it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.86it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.87it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.87it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.91it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.91it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.94it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.94it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.04it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  5.04it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.13it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.13it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.20it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.20it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.20it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.20it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.05it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.05it/s, train_loss=0.275] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.96it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  4.96it/s, train_loss=0.0247]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.79it/s, train_loss=0.0247]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.79it/s, train_loss=0.0964]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.98it/s, train_loss=0.0964]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.98it/s, train_loss=0.333] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.99it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.99it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.04it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.04it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.79it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:13,  4.79it/s, train_loss=0.0425]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.10it/s, train_loss=0.0425]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.10it/s, train_loss=0.324] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.28it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.28it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.35it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.35it/s, train_loss=0.38] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.24it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.24it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.30it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.30it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.30it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.30it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.31it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.31it/s, train_loss=0.0834]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.25it/s, train_loss=0.0834]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.25it/s, train_loss=0.451] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:09,  5.41it/s, train_loss=0.451]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:09,  5.41it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.22it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.22it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.08it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.08it/s, train_loss=0.0751]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.15it/s, train_loss=0.0751]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.15it/s, train_loss=0.26]  \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.99it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.99it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.08it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.08it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.11it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.11it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.06it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.06it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.97it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.97it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.90it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.90it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.89it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.89it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.13it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.13it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.14it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.14it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.29it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.29it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.35it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.35it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.26it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.26it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.11it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.11it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.25it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.25it/s, train_loss=0.242] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.04it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.04it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.02it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.02it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.91it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.91it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.91it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.91it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.75it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.75it/s, train_loss=0.0968]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.99it/s, train_loss=0.0968]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.99it/s, train_loss=0.244] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.94it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.94it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.02it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.02it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.83it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.83it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.83it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.83it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.85it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.85it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.11it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.11it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.0864]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.16it/s, train_loss=0.0864]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.16it/s, train_loss=0.895] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.00it/s, train_loss=0.895]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.00it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.95it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.95it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.86it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.86it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.81it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.81it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.81it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.81it/s, train_loss=0.312] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.76it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.76it/s, train_loss=0.32] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.69it/s, train_loss=0.32]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.69it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.96it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.96it/s, train_loss=0.0903]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.94it/s, train_loss=0.0903]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.94it/s, train_loss=0.163] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.99it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.99it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.98it/s, train_loss=0.458]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.98it/s, train_loss=0.54] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.86it/s, train_loss=0.54]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.86it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.01it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.01it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.11it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.11it/s, train_loss=0.148] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.91it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.91it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.95it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.95it/s, train_loss=0.256] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.83it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.83it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.84it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.84it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.72it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.72it/s, train_loss=0.627]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.64it/s, train_loss=0.627]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.64it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.73it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.73it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.95it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.95it/s, train_loss=0.685]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44 average loss: 0.2449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 44/110 [18:20<27:13, 24.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 44 current AUC: 0.9969 current accuracy: 0.9068 best AUC: 0.9979 at epoch: 32\n",
      "----------\n",
      "epoch 45/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.87it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.87it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.96it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.96it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.14it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.14it/s, train_loss=0.12] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.29it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.29it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.17it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.17it/s, train_loss=0.723]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.01it/s, train_loss=0.723]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  5.01it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.17it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.17it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.00it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.00it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.06it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.06it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.19it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.19it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.33it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.33it/s, train_loss=0.41] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=0.41]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.82it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.82it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.79it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.79it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.82it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.82it/s, train_loss=0.29] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.83it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.83it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.96it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.96it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.09it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.09it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.97it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  4.97it/s, train_loss=0.0664]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.90it/s, train_loss=0.0664]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.90it/s, train_loss=0.41]  \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.01it/s, train_loss=0.41]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.01it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.00it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.00it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.92it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.92it/s, train_loss=0.0785]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.10it/s, train_loss=0.0785]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.10it/s, train_loss=1]     \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.14it/s, train_loss=1]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.14it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.26it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.26it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.13it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.13it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.27it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.27it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.06it/s, train_loss=0.302]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.06it/s, train_loss=0.0871]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.00it/s, train_loss=0.0871]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.00it/s, train_loss=0.193] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.16it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.16it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.01it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.01it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.08it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.08it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.23it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.23it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.08it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.08it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.02it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.02it/s, train_loss=0.713]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=0.713]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.00it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.00it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.02it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.02it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.08it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.08it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.11it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.11it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.98it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.98it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.88it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.88it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.07it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.07it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.98it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.98it/s, train_loss=0.065] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.16it/s, train_loss=0.065]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.16it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.20it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.20it/s, train_loss=0.0571]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.08it/s, train_loss=0.0571]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.08it/s, train_loss=0.241] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.22it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.22it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.18it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.18it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.09it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.09it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.91it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.91it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.90it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.90it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.96it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.96it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.07it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.07it/s, train_loss=0.427]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.13it/s, train_loss=0.427]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.13it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.03it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.03it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.70it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.70it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:13,  4.67it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:13,  4.67it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.73it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.73it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.79it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.79it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.82it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.82it/s, train_loss=0.629]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.07it/s, train_loss=0.629]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.07it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.07it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.07it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.02it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.02it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.95it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.95it/s, train_loss=0.242] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.77it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.77it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.84it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.84it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.09it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.09it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.98it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.98it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.05it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.05it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.18it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.18it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.85it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.85it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.78it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.78it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.70it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.70it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.68it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.68it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.05it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.05it/s, train_loss=0.792]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.04it/s, train_loss=0.792]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.04it/s, train_loss=0.061]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=0.061]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.96it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.96it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.99it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.99it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.04it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.04it/s, train_loss=0.212] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.04it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.04it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.20it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.20it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.03it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.03it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.82it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  4.82it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.79it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.79it/s, train_loss=0.245] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.73it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.73it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.87it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.87it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.89it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.89it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.98it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.98it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.03it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.03it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.11it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.11it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.26it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.26it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.20it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.20it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.22it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.22it/s, train_loss=0.0646]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.07it/s, train_loss=0.0646]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.07it/s, train_loss=0.376] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.08it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.08it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.02it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.02it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.0587]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.01it/s, train_loss=0.0587]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.01it/s, train_loss=0.00906]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.86it/s, train_loss=0.00906]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.86it/s, train_loss=0.141]  \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.12it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.12it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.12it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.12it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.06it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.06it/s, train_loss=0.0823]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.94it/s, train_loss=0.0823]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.94it/s, train_loss=0.308] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.91it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.91it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.92it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.92it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  5.00it/s, train_loss=0.546]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  5.00it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.15it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.15it/s, train_loss=0.835]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.01it/s, train_loss=0.835]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.01it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.88it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.88it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.85it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.85it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.10it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.10it/s, train_loss=0.571]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.89it/s, train_loss=0.571]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.89it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.78it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.78it/s, train_loss=1.05]  \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.87it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.87it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.83it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.83it/s, train_loss=0.696]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45 average loss: 0.2707\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  41%|████      | 45/110 [18:46<27:16, 25.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 45 current AUC: 0.9990 current accuracy: 0.8820 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 46/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.21it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.21it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.98it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.98it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.09it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.09it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.99it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.99it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.12it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.12it/s, train_loss=0.0649]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.26it/s, train_loss=0.0649]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.26it/s, train_loss=0.049] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.41it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.41it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:20,  5.49it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:20,  5.49it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.17it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.17it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.13it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.13it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.12it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.12it/s, train_loss=0.439]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.02it/s, train_loss=0.439]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.02it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.14it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.14it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=0.593]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.25it/s, train_loss=0.593]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.25it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.55it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.55it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.28it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.28it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.21it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.21it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.04it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.04it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.13it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.13it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.13it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.13it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.02it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.02it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.13it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.13it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.26it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.26it/s, train_loss=0.247] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.20it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.20it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.36it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.36it/s, train_loss=0.286] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.22it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.22it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.09it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.09it/s, train_loss=0.0732]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.04it/s, train_loss=0.0732]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.04it/s, train_loss=0.147] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.98it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.98it/s, train_loss=0.061]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.95it/s, train_loss=0.061]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.95it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.08it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.08it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.09it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.09it/s, train_loss=0.218] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.97it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.97it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.15it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.15it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.86it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.86it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.06it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.06it/s, train_loss=0.304] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.27it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.27it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.26it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.26it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.11it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.11it/s, train_loss=0.563]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:07<00:15,  5.19it/s, train_loss=0.563]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.19it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.13it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.13it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.26it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.26it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.46it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.46it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.25it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.25it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:14,  5.32it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.32it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.19it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.19it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.07it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.07it/s, train_loss=0.0988]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.10it/s, train_loss=0.0988]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.10it/s, train_loss=0.0803]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.19it/s, train_loss=0.0803]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.19it/s, train_loss=0.345] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.22it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.22it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=0.45] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.87it/s, train_loss=0.45]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.87it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.00it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.00it/s, train_loss=0.0226]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.94it/s, train_loss=0.0226]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.94it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:13,  4.78it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.78it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.95it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.95it/s, train_loss=0.0507]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.88it/s, train_loss=0.0507]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.88it/s, train_loss=0.159] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.83it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.83it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.86it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.86it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  4.93it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.93it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.98it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.98it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.90it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.90it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.89it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.89it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.13it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.13it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  4.85it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.85it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.83it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.83it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.81it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.81it/s, train_loss=0.0763]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.88it/s, train_loss=0.0763]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.88it/s, train_loss=0.153] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.05it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.05it/s, train_loss=0.0666]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  4.99it/s, train_loss=0.0666]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.99it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.14it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.14it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.77it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.77it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.74it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.74it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.85it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.85it/s, train_loss=0.0707]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  5.06it/s, train_loss=0.0707]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.06it/s, train_loss=0.0753]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.03it/s, train_loss=0.0753]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.03it/s, train_loss=0.23]  \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.07it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.07it/s, train_loss=0.0654]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.99it/s, train_loss=0.0654]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.99it/s, train_loss=0.23]  \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.15it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.15it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.04it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.04it/s, train_loss=0.0978]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.02it/s, train_loss=0.0978]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.02it/s, train_loss=0.108] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.18it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.18it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.13it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.13it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.05it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.05it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.31it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.31it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.20it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.20it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.24it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.24it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.26it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.26it/s, train_loss=0.17] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.42it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.42it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.37it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.37it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.11it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.11it/s, train_loss=0.0731]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.18it/s, train_loss=0.0731]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.18it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.99it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.99it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.12it/s, train_loss=0.474]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.12it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.09it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.09it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.02it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.02it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.09it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.09it/s, train_loss=0.0593]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.32it/s, train_loss=0.0593]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.32it/s, train_loss=0.315] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.24it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.24it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.11it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.11it/s, train_loss=0.0843]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.09it/s, train_loss=0.0843]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.09it/s, train_loss=0.388] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.97it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.97it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.94it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.94it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.97it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.97it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.04it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.04it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.02it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.02it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.92it/s, train_loss=0.641]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.92it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.86it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.86it/s, train_loss=0.089] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.05it/s, train_loss=0.089]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.05it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.98it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.98it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.86it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.86it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.66it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.66it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.91it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.91it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.10it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.10it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.97it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.97it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.90it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.90it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.02it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.02it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.10it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.10it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.96it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.96it/s, train_loss=0.179] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.89it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.89it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:23<00:00,  5.73it/s, train_loss=0.311]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46 average loss: 0.2337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  42%|████▏     | 46/110 [19:10<26:40, 25.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 46 current AUC: 0.9985 current accuracy: 0.9503 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 47/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.52it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.52it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:26,  4.60it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:26,  4.60it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.58it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.58it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.73it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.73it/s, train_loss=0.021]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.94it/s, train_loss=0.021]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.94it/s, train_loss=0.0701]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.98it/s, train_loss=0.0701]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.98it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.18it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.18it/s, train_loss=0.0195]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.0195]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.39]  \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:20,  5.41it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:20,  5.41it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:20,  5.47it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:20,  5.47it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.31it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.31it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.13it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.13it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.13it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.13it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.15it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.15it/s, train_loss=0.0599]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.03it/s, train_loss=0.0599]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.03it/s, train_loss=0.284] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.79it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.79it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  5.00it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  5.00it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.96it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.96it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.10it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.10it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.96it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.96it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.86it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.86it/s, train_loss=0.0783]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.87it/s, train_loss=0.0783]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.87it/s, train_loss=0.654] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.09it/s, train_loss=0.654]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.09it/s, train_loss=0.42] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.21it/s, train_loss=0.42]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.21it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.19it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.19it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.89it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.89it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.04it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.04it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.80it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.80it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.96it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.96it/s, train_loss=0.0516]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.04it/s, train_loss=0.0516]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.04it/s, train_loss=0.263] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.97it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.97it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.20it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.20it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.10it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.10it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.02it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.02it/s, train_loss=0.71] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.09it/s, train_loss=0.71]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.09it/s, train_loss=0.0851]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.21it/s, train_loss=0.0851]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.21it/s, train_loss=0.269] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.16it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.16it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.08it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.08it/s, train_loss=0.0571]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.0571]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.452] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.19it/s, train_loss=0.452]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.19it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.16it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.16it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.85it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.85it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.04it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.04it/s, train_loss=0.0977]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.05it/s, train_loss=0.0977]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.05it/s, train_loss=0.281] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.97it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.97it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.98it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.98it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.97it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.97it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.99it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.99it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.01it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.01it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.23it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.23it/s, train_loss=0.257] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.11it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.11it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.21it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.21it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.10it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.10it/s, train_loss=0.0935]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.17it/s, train_loss=0.0935]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.17it/s, train_loss=0.245] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.19it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.19it/s, train_loss=0.0916]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.07it/s, train_loss=0.0916]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.07it/s, train_loss=0.26]  \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.32it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.32it/s, train_loss=0.0819]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.0819]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.262] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.19it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.19it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.93it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.93it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.14it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.14it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.05it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.05it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.88it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.88it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.03it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.03it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.85it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.85it/s, train_loss=0.0478]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.0478]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.211] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.14it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.14it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.12it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.12it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.17it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.17it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.94it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.94it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.89it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.89it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.02it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.02it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.00it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.00it/s, train_loss=0.179] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.09it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.09it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.03it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.03it/s, train_loss=0.0699]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.01it/s, train_loss=0.0699]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.01it/s, train_loss=0.244] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.17it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.17it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.09it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.09it/s, train_loss=0.944]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.22it/s, train_loss=0.944]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.22it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.12it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.12it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.10it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.10it/s, train_loss=0.382] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.0788]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.96it/s, train_loss=0.0788]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.96it/s, train_loss=0.0486]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.02it/s, train_loss=0.0486]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.02it/s, train_loss=0.314] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.10it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.10it/s, train_loss=0.0137]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.23it/s, train_loss=0.0137]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.23it/s, train_loss=0.494] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.28it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.28it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.10it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.10it/s, train_loss=0.564]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.04it/s, train_loss=0.564]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.04it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.24it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.24it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.27it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.27it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.09it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.09it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.89it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.89it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.92it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.92it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.23it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.23it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.28it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.28it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.41it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.41it/s, train_loss=0.08] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.27it/s, train_loss=0.08]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.27it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.11it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.11it/s, train_loss=0.0744]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.16it/s, train_loss=0.0744]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.16it/s, train_loss=0.505] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.02it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.02it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.95it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.95it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.97it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.97it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.69it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.69it/s, train_loss=0.0875]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.78it/s, train_loss=0.0875]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.78it/s, train_loss=0.193] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.02it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.02it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.10it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.10it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.82it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.82it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.28it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.28it/s, train_loss=0.604]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.24it/s, train_loss=0.604]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.24it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.12it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.12it/s, train_loss=0.0955]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.95it/s, train_loss=0.0955]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.95it/s, train_loss=0.223] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.05it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.05it/s, train_loss=0.0239]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.14it/s, train_loss=0.0239]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.14it/s, train_loss=0.192] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.05it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.05it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.24it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.24it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.21it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.21it/s, train_loss=0.697]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47 average loss: 0.2203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  43%|████▎     | 47/110 [19:35<26:07, 24.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 47 current AUC: 0.9979 current accuracy: 0.9006 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 48/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.28it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.28it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.41it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.41it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.03it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.03it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.08it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.08it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.20it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.20it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.93it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.93it/s, train_loss=0.0609]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.87it/s, train_loss=0.0609]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.87it/s, train_loss=0.149] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.90it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.90it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.87it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.87it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.90it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.90it/s, train_loss=0.38] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.13it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.13it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.06it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.06it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.18it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.18it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.24it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.24it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.24it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.24it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.06it/s, train_loss=0.695]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.06it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.92it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.92it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.75it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.75it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.96it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.96it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.90it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.90it/s, train_loss=1.27] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.99it/s, train_loss=1.27]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.99it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.97it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.97it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.13it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.13it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.09it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.09it/s, train_loss=0.115] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.01it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.01it/s, train_loss=0.17] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.91it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.91it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.81it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.81it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.77it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.77it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.89it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:19,  4.89it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.00it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.00it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.80it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.80it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.74it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.74it/s, train_loss=0.742]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.85it/s, train_loss=0.742]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.85it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.98it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  4.98it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.00it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.00it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.22it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.22it/s, train_loss=0.499]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.26it/s, train_loss=0.499]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.26it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.80it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:17,  4.80it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.78it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.78it/s, train_loss=0.542]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.83it/s, train_loss=0.542]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.83it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.95it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.95it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.12it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.12it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.01it/s, train_loss=0.504]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  5.01it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.90it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.90it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.90it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.90it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.86it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.86it/s, train_loss=0.12] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.85it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.85it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.81it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:15,  4.81it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.90it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.90it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.90it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.90it/s, train_loss=0.0806]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.04it/s, train_loss=0.0806]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.04it/s, train_loss=0.333] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.86it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.86it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.85it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:14,  4.85it/s, train_loss=0.0786]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.88it/s, train_loss=0.0786]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.88it/s, train_loss=0.0787]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.94it/s, train_loss=0.0787]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.94it/s, train_loss=0.186] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.90it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.90it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.09it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.09it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.99it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  4.99it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.96it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.96it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.91it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.91it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.95it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.95it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.04it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.04it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.88it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  4.88it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.85it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.85it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.91it/s, train_loss=0.502]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.91it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.09it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.09it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.92it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.92it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.89it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  4.89it/s, train_loss=0.948]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.01it/s, train_loss=0.948]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.01it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.04it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.04it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.19it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.19it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.23it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.23it/s, train_loss=1.18] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.95it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  4.95it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.04it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.04it/s, train_loss=0.2]  \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.99it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.99it/s, train_loss=0.0605]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.82it/s, train_loss=0.0605]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.82it/s, train_loss=0.346] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.80it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.80it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.02it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:08,  5.02it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.04it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.04it/s, train_loss=0.0686]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.0686]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.148] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.20it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.20it/s, train_loss=0.0481]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.23it/s, train_loss=0.0481]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  5.23it/s, train_loss=0.293] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.25it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.25it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.16it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.16it/s, train_loss=0.633]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.99it/s, train_loss=0.633]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.99it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.97it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.97it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.78it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  4.78it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.03it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.03it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.01it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.01it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.00it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.00it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.75it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.75it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.86it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.86it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.87it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.87it/s, train_loss=0.238] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.23it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.23it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.17it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.17it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.07it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.07it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.03it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:20<00:04,  5.03it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.96it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.96it/s, train_loss=0.0655]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.01it/s, train_loss=0.0655]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.01it/s, train_loss=0.213] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.16it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.16it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.05it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.05it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.23it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  5.23it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.20it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.20it/s, train_loss=0.0878]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.19it/s, train_loss=0.0878]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.19it/s, train_loss=0.284] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.25it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.25it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.19it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.19it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.09it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  5.09it/s, train_loss=0.1]  \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.94it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.94it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.78it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.78it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.91it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.91it/s, train_loss=0.729]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.03it/s, train_loss=0.729]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.03it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.80it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.80it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.01it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.01it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.91it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.91it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.91it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.91it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.73it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.73it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.97it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.97it/s, train_loss=0.0451]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.10it/s, train_loss=0.0451]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.10it/s, train_loss=0.143] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.16it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.16it/s, train_loss=0.0627]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48 average loss: 0.2778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  44%|████▎     | 48/110 [20:00<25:43, 24.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 48 current AUC: 0.9957 current accuracy: 0.8882 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 49/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.11it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.11it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.01it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.01it/s, train_loss=1.07] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.70it/s, train_loss=1.07]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.70it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.79it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.79it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.94it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.94it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.86it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.86it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.03it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.03it/s, train_loss=0.801]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.94it/s, train_loss=0.801]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  4.94it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.92it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.92it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.99it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.99it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.80it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.80it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.84it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.84it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.94it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  4.94it/s, train_loss=0.0937]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.05it/s, train_loss=0.0937]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.05it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.91it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.91it/s, train_loss=0.253] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.94it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.94it/s, train_loss=0.29] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.07it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.07it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.29it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:19,  5.29it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.23it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.23it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.35it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.35it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.20it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.20it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.25it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.25it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.26it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.26it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.61it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.61it/s, train_loss=0.0797]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.36it/s, train_loss=0.0797]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.36it/s, train_loss=0.344] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.36it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.36it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.27it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.27it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.19it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.19it/s, train_loss=0.214] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.21it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.21it/s, train_loss=0.246] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.33it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.33it/s, train_loss=0.0795]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.99it/s, train_loss=0.0795]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.99it/s, train_loss=0.166] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.18it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.18it/s, train_loss=0.0728]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.17it/s, train_loss=0.0728]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.17it/s, train_loss=0.194] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.98it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.98it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.06it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.06it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.27it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.27it/s, train_loss=0.0703]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.27it/s, train_loss=0.0703]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.27it/s, train_loss=0.204] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.20it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.20it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.88it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.88it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.90it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.90it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.89it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.89it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.89it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.89it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.90it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.90it/s, train_loss=0.48] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.83it/s, train_loss=0.48]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.83it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.01it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.01it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.07it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.07it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.16it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.16it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=0.0445]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.06it/s, train_loss=0.0445]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.06it/s, train_loss=0.13]  \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.90it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.90it/s, train_loss=0.097]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.87it/s, train_loss=0.097]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.87it/s, train_loss=0.0655]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.94it/s, train_loss=0.0655]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.94it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.14it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.14it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.08it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.08it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.09it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.09it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.96it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.96it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.82it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.82it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.04it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.04it/s, train_loss=0.5]  \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.95it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.95it/s, train_loss=0.586]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.95it/s, train_loss=0.586]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.95it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.88it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.88it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.91it/s, train_loss=0.621]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.91it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.92it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.92it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.01it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.01it/s, train_loss=0.0969]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.06it/s, train_loss=0.0969]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.06it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.11it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.11it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.91it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.91it/s, train_loss=0.556]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.84it/s, train_loss=0.556]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.84it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.85it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.85it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.97it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.97it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.11it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.11it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.94it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.94it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.0173]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=0.0173]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.92it/s, train_loss=0.166] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.99it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.99it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.17it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.17it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.36it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.36it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.14it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.14it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.95it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.95it/s, train_loss=0.521]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.98it/s, train_loss=0.521]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.98it/s, train_loss=0.0535]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.10it/s, train_loss=0.0535]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.10it/s, train_loss=0.218] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.17it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.17it/s, train_loss=0.829]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.12it/s, train_loss=0.829]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.12it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.14it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.14it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.04it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.04it/s, train_loss=0.0674]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.08it/s, train_loss=0.0674]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.08it/s, train_loss=0.0751]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.90it/s, train_loss=0.0751]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.90it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.88it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.88it/s, train_loss=0.197] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.08it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.08it/s, train_loss=0.0497]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.00it/s, train_loss=0.0497]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.00it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.98it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.98it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.92it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.92it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.01it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.01it/s, train_loss=0.26] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.08it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.08it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.98it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.98it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.96it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.96it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.76it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.76it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.95it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.95it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.89it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.89it/s, train_loss=1.05] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.93it/s, train_loss=1.05]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.93it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.93it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.93it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.91it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.91it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.86it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.86it/s, train_loss=0.338] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.81it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.81it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.93it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.93it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.10it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.10it/s, train_loss=0.0184]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.98it/s, train_loss=0.0184]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.98it/s, train_loss=0.249] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.04it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.04it/s, train_loss=0.0802]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.96it/s, train_loss=0.0802]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.96it/s, train_loss=0.208] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.75it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.75it/s, train_loss=0.0526]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.86it/s, train_loss=0.0526]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.86it/s, train_loss=0.136] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.84it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.84it/s, train_loss=0.0637]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.81it/s, train_loss=0.0637]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.81it/s, train_loss=0.63]  \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.92it/s, train_loss=0.63]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.92it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.96it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.96it/s, train_loss=0.667]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49 average loss: 0.2462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  45%|████▍     | 49/110 [20:25<25:17, 24.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 49 current AUC: 0.9914 current accuracy: 0.8882 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 50/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0841]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.84it/s, train_loss=0.0841]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.84it/s, train_loss=0.315] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.14it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.14it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.58it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.58it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.46it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.46it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:21,  5.34it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:21,  5.34it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.31it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.31it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.30it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.30it/s, train_loss=0.0952]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.12it/s, train_loss=0.0952]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.12it/s, train_loss=0.148] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.12it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.12it/s, train_loss=0.0849]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.00it/s, train_loss=0.0849]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.00it/s, train_loss=0.422] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.07it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.07it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.88it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.88it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.96it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.96it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.30it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.30it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.01it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.01it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.10it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.10it/s, train_loss=0.2]  \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.23it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.23it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.87it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.87it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.89it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.89it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:21,  4.70it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.70it/s, train_loss=0.134] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.79it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.79it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.89it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.89it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.89it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.89it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.78it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.78it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:20,  4.84it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.84it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.88it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.88it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.94it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.94it/s, train_loss=0.364] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.02it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.02it/s, train_loss=0.0995]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.0995]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.386] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.18it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.18it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.09it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.09it/s, train_loss=0.109] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.17it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.17it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.43it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.43it/s, train_loss=0.063] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.10it/s, train_loss=0.063]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.10it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.30it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.30it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.09it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.09it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.16it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.16it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.754]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.87it/s, train_loss=0.754]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.87it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.15it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.15it/s, train_loss=0.0636]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.06it/s, train_loss=0.0636]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.06it/s, train_loss=0.192] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.25it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.25it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.14it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.14it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.18it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.18it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.88it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.88it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.11it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.11it/s, train_loss=0.0749]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=0.0749]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=0.25]  \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.25it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.25it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.19it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.19it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.17it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.17it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.23it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.23it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=0.42] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.12it/s, train_loss=0.42]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.12it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.92it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.92it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.88it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.88it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.84it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.84it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.72it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.72it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.72it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.72it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.92it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.92it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.97it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.97it/s, train_loss=0.0753]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.98it/s, train_loss=0.0753]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.98it/s, train_loss=0.252] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.95it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.95it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.87it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.87it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.91it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.91it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.97it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.97it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.98it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.98it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.98it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.98it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.96it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.96it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.09it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.09it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.00it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.00it/s, train_loss=0.674]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.08it/s, train_loss=0.674]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.08it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.94it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.94it/s, train_loss=0.0767]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.07it/s, train_loss=0.0767]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.07it/s, train_loss=0.129] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.96it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.96it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.93it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.93it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.94it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.94it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.05it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.05it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.13it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.13it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.04it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.04it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.14it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.14it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.03it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.03it/s, train_loss=0.202] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.06it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.06it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.93it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.93it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.93it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.93it/s, train_loss=0.558]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.91it/s, train_loss=0.558]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.91it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.89it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.89it/s, train_loss=0.566]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.89it/s, train_loss=0.566]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.89it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:07,  4.71it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:07,  4.71it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:07,  4.53it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:07,  4.53it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.74it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.74it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.73it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.73it/s, train_loss=0.53] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.73it/s, train_loss=0.53]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.73it/s, train_loss=0.703]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.79it/s, train_loss=0.703]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.79it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.04it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.04it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.19it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.19it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.01it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.01it/s, train_loss=0.0624]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.96it/s, train_loss=0.0624]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.96it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.98it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.98it/s, train_loss=0.12]  \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.06it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.06it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.05it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.05it/s, train_loss=0.375] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.85it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.85it/s, train_loss=0.0624]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.91it/s, train_loss=0.0624]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.91it/s, train_loss=0.154] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.88it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.88it/s, train_loss=0.0394]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.86it/s, train_loss=0.0394]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.86it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.75it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.75it/s, train_loss=0.171] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.85it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.85it/s, train_loss=0.0722]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.99it/s, train_loss=0.0722]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  4.99it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.92it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.92it/s, train_loss=0.0439]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.06it/s, train_loss=0.0439]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.06it/s, train_loss=0.127] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.81it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.81it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.88it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.88it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.84it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.84it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.86it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.86it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.81it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.81it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.85it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.85it/s, train_loss=0.162] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.83it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.83it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.02it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.02it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.00it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.00it/s, train_loss=0.172]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 average loss: 0.2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  45%|████▌     | 50/110 [20:50<24:53, 24.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 50 current AUC: 0.9941 current accuracy: 0.8882 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 51/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0694]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.47it/s, train_loss=0.0694]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.47it/s, train_loss=0.183] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.02it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.02it/s, train_loss=0.12] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.17it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.17it/s, train_loss=0.0747]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.83it/s, train_loss=0.0747]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.83it/s, train_loss=0.0452]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.92it/s, train_loss=0.0452]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.92it/s, train_loss=0.0526]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.08it/s, train_loss=0.0526]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.08it/s, train_loss=0.673] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.10it/s, train_loss=0.673]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.10it/s, train_loss=0.044]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.01it/s, train_loss=0.044]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.01it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.80it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.80it/s, train_loss=0.466] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.87it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.87it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.03it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.03it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.93it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.93it/s, train_loss=0.282] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.88it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.88it/s, train_loss=0.0916]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.95it/s, train_loss=0.0916]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  4.95it/s, train_loss=0.13]  \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.99it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.99it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.06it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.06it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.00it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.00it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.11it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.11it/s, train_loss=0.0608]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.94it/s, train_loss=0.0608]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  4.94it/s, train_loss=0.161] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.93it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.93it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.14it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.14it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.32it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.32it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.12it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.12it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.15it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.15it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.09it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.09it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.96it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.96it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.10it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.10it/s, train_loss=0.0935]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.20it/s, train_loss=0.0935]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.20it/s, train_loss=0.268] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.08it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.08it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.98it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.98it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.79it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.79it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:19,  4.74it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:19,  4.74it/s, train_loss=0.12] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.81it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.81it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.78it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:18,  4.78it/s, train_loss=0.0515]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.79it/s, train_loss=0.0515]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.79it/s, train_loss=0.247] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.98it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.98it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.00it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.00it/s, train_loss=0.0708]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.03it/s, train_loss=0.0708]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.03it/s, train_loss=0.315] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.26it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.26it/s, train_loss=0.078]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.30it/s, train_loss=0.078]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.30it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.07it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.07it/s, train_loss=0.605]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.14it/s, train_loss=0.605]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.14it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.13it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.13it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.16it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.16it/s, train_loss=0.077]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.22it/s, train_loss=0.077]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.22it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.30it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.30it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.41it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.41it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.18it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.18it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.15it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.15it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.11it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.11it/s, train_loss=0.284] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.03it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.03it/s, train_loss=0.0954]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.21it/s, train_loss=0.0954]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.21it/s, train_loss=0.564] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.20it/s, train_loss=0.564]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.20it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.35it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.35it/s, train_loss=0.526] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.17it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.17it/s, train_loss=0.0605]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.40it/s, train_loss=0.0605]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.40it/s, train_loss=0.264] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.14it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.14it/s, train_loss=0.0318]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.92it/s, train_loss=0.0318]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.92it/s, train_loss=0.312] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.85it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.85it/s, train_loss=0.0573]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.87it/s, train_loss=0.0573]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.87it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.88it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.88it/s, train_loss=0.418] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.79it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.79it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.87it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.87it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.00it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.00it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.97it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.97it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.93it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.93it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.91it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.91it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.88it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.88it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.90it/s, train_loss=0.567]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.90it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.88it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.88it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.15it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.15it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.12it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.12it/s, train_loss=0.0564]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.16it/s, train_loss=0.0564]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.16it/s, train_loss=0.0845]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.27it/s, train_loss=0.0845]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.27it/s, train_loss=0.382] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.09it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.09it/s, train_loss=0.0823]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.00it/s, train_loss=0.0823]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.00it/s, train_loss=0.227] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.24it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.24it/s, train_loss=0.607]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.14it/s, train_loss=0.607]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.14it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.97it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.97it/s, train_loss=0.0796]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.85it/s, train_loss=0.0796]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.85it/s, train_loss=0.113] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.97it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.97it/s, train_loss=0.0821]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  5.00it/s, train_loss=0.0821]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  5.00it/s, train_loss=0.0441]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.99it/s, train_loss=0.0441]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.99it/s, train_loss=0.742] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.93it/s, train_loss=0.742]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.93it/s, train_loss=0.0771]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.94it/s, train_loss=0.0771]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.94it/s, train_loss=0.071] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.99it/s, train_loss=0.071]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.99it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.85it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.85it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.02it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.02it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.90it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.90it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.97it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.97it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.15it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.15it/s, train_loss=0.0649]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.89it/s, train_loss=0.0649]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.89it/s, train_loss=0.265] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.77it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.77it/s, train_loss=0.4]  \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.76it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.76it/s, train_loss=0.46]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.72it/s, train_loss=0.46]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.72it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.79it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.79it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.09it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.09it/s, train_loss=0.0496]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.91it/s, train_loss=0.0496]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.91it/s, train_loss=0.361] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.81it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.81it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.72it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.72it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.69it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.69it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.85it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.85it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.93it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.93it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.86it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  4.86it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.89it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.89it/s, train_loss=0.44] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.10it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.10it/s, train_loss=0.0375]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.10it/s, train_loss=0.0375]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.10it/s, train_loss=0.261] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.04it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.04it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.96it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.96it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.02it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.02it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.92it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.92it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.97it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.97it/s, train_loss=0.042]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.27it/s, train_loss=0.042]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.27it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.16it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.16it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.16it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.16it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.10it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.10it/s, train_loss=0.58]  \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.95it/s, train_loss=0.58]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.95it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.80it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.80it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.88it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.88it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.80it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.80it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.89it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.89it/s, train_loss=0.66] \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51 average loss: 0.2174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  46%|████▋     | 51/110 [21:15<24:29, 24.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 51 current AUC: 0.9952 current accuracy: 0.8882 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 52/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.36it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.36it/s, train_loss=0.084]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.53it/s, train_loss=0.084]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.53it/s, train_loss=0.0591]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.38it/s, train_loss=0.0591]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.38it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.26it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.26it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:20,  5.61it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:20,  5.61it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.30it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.30it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.33it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.33it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.18it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.18it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:20,  5.44it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:20,  5.44it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.20it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.20it/s, train_loss=0.291] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.11it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.11it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.08it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.08it/s, train_loss=0.705]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.25it/s, train_loss=0.705]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.25it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.22it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.22it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:19,  5.36it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:19,  5.36it/s, train_loss=0.0137]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.19it/s, train_loss=0.0137]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.19it/s, train_loss=0.263] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.34it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.34it/s, train_loss=0.776]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.42it/s, train_loss=0.776]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.42it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:18,  5.60it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:18,  5.60it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:18,  5.49it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:18,  5.49it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:03<00:18,  5.37it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.37it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.25it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.25it/s, train_loss=0.104] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.13it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.13it/s, train_loss=0.588]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.99it/s, train_loss=0.588]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.99it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.25it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.25it/s, train_loss=0.191] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:04<00:18,  5.30it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.30it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.27it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.27it/s, train_loss=0.0964]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.22it/s, train_loss=0.0964]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.22it/s, train_loss=0.329] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.28it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.28it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:05<00:18,  4.96it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.96it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.99it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.99it/s, train_loss=0.26] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.95it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.95it/s, train_loss=0.067]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.18it/s, train_loss=0.067]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.18it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.17it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.17it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:06<00:17,  4.93it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.93it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.93it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.93it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.06it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.06it/s, train_loss=0.62] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.28it/s, train_loss=0.62]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.28it/s, train_loss=0.0402]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.11it/s, train_loss=0.0402]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.11it/s, train_loss=0.0796]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:07<00:16,  4.99it/s, train_loss=0.0796]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.99it/s, train_loss=0.345] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.03it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.03it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.17it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.17it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.25it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.25it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.22it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.22it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:14,  5.15it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.15it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=0.0514]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.36it/s, train_loss=0.0514]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.36it/s, train_loss=0.177] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.38it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.38it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.30it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.30it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.41it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.41it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:09<00:13,  5.24it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.24it/s, train_loss=0.00679]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.32it/s, train_loss=0.00679]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.32it/s, train_loss=0.263]  \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.46it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.46it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.11it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.11it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:13,  4.91it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:13,  4.91it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:10<00:13,  4.95it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.95it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.00it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.00it/s, train_loss=0.069]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.87it/s, train_loss=0.069]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.87it/s, train_loss=0.0447]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.94it/s, train_loss=0.0447]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.94it/s, train_loss=0.108] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  4.76it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  4.76it/s, train_loss=0.0921]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:11<00:12,  4.96it/s, train_loss=0.0921]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.96it/s, train_loss=0.198] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.89it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.89it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.03it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.03it/s, train_loss=0.0513]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.87it/s, train_loss=0.0513]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.87it/s, train_loss=0.0385]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  4.82it/s, train_loss=0.0385]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.82it/s, train_loss=0.177] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.0818]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.83it/s, train_loss=0.0818]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.83it/s, train_loss=0.0424]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.95it/s, train_loss=0.0424]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.95it/s, train_loss=0.203] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.08it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.08it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  4.99it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.99it/s, train_loss=0.17] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.89it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.89it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.01it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.01it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.77it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.77it/s, train_loss=0.0754]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.95it/s, train_loss=0.0754]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.95it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  5.10it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.10it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.93it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.93it/s, train_loss=0.0355]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.11it/s, train_loss=0.0355]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.11it/s, train_loss=0.187] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.07it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.07it/s, train_loss=0.674]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.99it/s, train_loss=0.674]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.99it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.94it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.94it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.95it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.95it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.95it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.95it/s, train_loss=0.0974]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.0974]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.0352]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.07it/s, train_loss=0.0352]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.07it/s, train_loss=0.0952]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.08it/s, train_loss=0.0952]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.08it/s, train_loss=0.163] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:16<00:06,  5.25it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.25it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.04it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.04it/s, train_loss=1.28] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.77it/s, train_loss=1.28]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.77it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.92it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.92it/s, train_loss=0.301] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.01it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.01it/s, train_loss=0.0885]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.87it/s, train_loss=0.0885]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.87it/s, train_loss=0.0919]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.0919]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.99it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.99it/s, train_loss=0.229] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.97it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.97it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.78it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.78it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.85it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.85it/s, train_loss=0.0198]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.07it/s, train_loss=0.0198]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.07it/s, train_loss=0.214] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.10it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.10it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.26it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.26it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.47it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.47it/s, train_loss=0.0946]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:19<00:03,  5.37it/s, train_loss=0.0946]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.37it/s, train_loss=0.368] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.09it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.09it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.09it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.09it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.04it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.04it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.97it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.97it/s, train_loss=0.137] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:20<00:03,  4.96it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.96it/s, train_loss=0.57] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=0.57]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=1.11]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.97it/s, train_loss=1.11]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.97it/s, train_loss=0.0403]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.97it/s, train_loss=0.0403]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.97it/s, train_loss=1.31]  \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.92it/s, train_loss=1.31]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.92it/s, train_loss=0.608]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:01,  5.04it/s, train_loss=0.608]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.95it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.95it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.04it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.04it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.06it/s, train_loss=0.562]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.06it/s, train_loss=0.0519]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.03it/s, train_loss=0.0519]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.03it/s, train_loss=0.373] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:22<00:00,  5.02it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.02it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.92it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.92it/s, train_loss=0.0523]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.13it/s, train_loss=0.0523]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.13it/s, train_loss=0.217] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.14it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.14it/s, train_loss=0.36] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.00it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.00it/s, train_loss=2.85]\n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52 average loss: 0.2599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  47%|████▋     | 52/110 [21:39<23:56, 24.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 52 current AUC: 0.9968 current accuracy: 0.8944 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 53/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:19,  6.07it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:19,  6.07it/s, train_loss=0.0994]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.44it/s, train_loss=0.0994]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.44it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.14it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.14it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.75it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.75it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  4.89it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.89it/s, train_loss=0.0626]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.71it/s, train_loss=0.0626]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.71it/s, train_loss=0.78]  \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:24,  4.75it/s, train_loss=0.78]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:24,  4.75it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.64it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.64it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:24,  4.70it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:24,  4.70it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:24,  4.59it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:24,  4.59it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.64it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.64it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.68it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.68it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:23,  4.69it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:23,  4.69it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.97it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  4.97it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.02it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.02it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.96it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.96it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  5.00it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  5.00it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.99it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.99it/s, train_loss=0.0583]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.92it/s, train_loss=0.0583]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  4.92it/s, train_loss=0.205] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.01it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.01it/s, train_loss=0.0853]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.16it/s, train_loss=0.0853]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.16it/s, train_loss=0.452] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.13it/s, train_loss=0.452]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.13it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.16it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.16it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.05it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:19,  5.05it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.07it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.07it/s, train_loss=0.0704]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.18it/s, train_loss=0.0704]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.18it/s, train_loss=0.296] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.10it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.10it/s, train_loss=0.0639]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.18it/s, train_loss=0.0639]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.18it/s, train_loss=0.2]   \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.87it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:19,  4.87it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:19,  4.72it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:19,  4.72it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.00it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.00it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.13it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.13it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.09it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  5.09it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.10it/s, train_loss=0.416]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.10it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.02it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.02it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.89it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.89it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.98it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.98it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.07it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:16,  5.07it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.98it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.98it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.06it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.06it/s, train_loss=1.18] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.28it/s, train_loss=1.18]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.28it/s, train_loss=0.0772]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.23it/s, train_loss=0.0772]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.23it/s, train_loss=0.178] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.28it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:14,  5.28it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.13it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.13it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.02it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.02it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.86it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.86it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.94it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  4.94it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.96it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.96it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.80it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.80it/s, train_loss=0.046]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.75it/s, train_loss=0.046]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.75it/s, train_loss=0.0574]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.85it/s, train_loss=0.0574]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.85it/s, train_loss=0.162] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.86it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  4.86it/s, train_loss=0.62] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.96it/s, train_loss=0.62]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.96it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.01it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.01it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.19it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.19it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.584]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.0764]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.42it/s, train_loss=0.0764]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:11,  5.42it/s, train_loss=0.158] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.13it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.13it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.03it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.03it/s, train_loss=0.383] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.96it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.96it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.78it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.78it/s, train_loss=0.2]  \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.87it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  4.87it/s, train_loss=0.0958]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.98it/s, train_loss=0.0958]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.98it/s, train_loss=0.491] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.07it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.07it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  5.00it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  5.00it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.93it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.93it/s, train_loss=0.499]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.95it/s, train_loss=0.499]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  4.95it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.90it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.90it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.86it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.86it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.78it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.78it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.80it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.80it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.02it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  5.02it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.09it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.09it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.03it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.03it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.99it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.99it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.18it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.18it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.16it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:08,  5.16it/s, train_loss=0.0833]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:07,  5.28it/s, train_loss=0.0833]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:07,  5.28it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.02it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.02it/s, train_loss=0.271] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.12it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.12it/s, train_loss=0.0781]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.0781]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.166] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.09it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  5.09it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.01it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.01it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.08it/s, train_loss=0.362]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.08it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.42it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.42it/s, train_loss=0.0931]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.03it/s, train_loss=0.0931]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.03it/s, train_loss=0.22]  \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.99it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  4.99it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.99it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.99it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.19it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.19it/s, train_loss=0.0318]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.02it/s, train_loss=0.0318]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.02it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.98it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.98it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.78it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.78it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.74it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.74it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.84it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.84it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.77it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.77it/s, train_loss=0.0307]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.0307]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.527] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.11it/s, train_loss=0.527]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:20<00:04,  5.11it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.99it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.99it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.11it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.11it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.24it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.24it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.30it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.30it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.98it/s, train_loss=0.355]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  4.98it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.07it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.07it/s, train_loss=0.0944]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.92it/s, train_loss=0.0944]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.92it/s, train_loss=0.228] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.85it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.85it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.90it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.90it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.83it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  4.83it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.14it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.14it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.09it/s, train_loss=0.375]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.09it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.05it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.05it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.03it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.03it/s, train_loss=0.0421]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.17it/s, train_loss=0.0421]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  5.17it/s, train_loss=0.678] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.08it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.08it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.17it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.17it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.97it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.97it/s, train_loss=0.0745]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.84it/s, train_loss=0.0745]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.84it/s, train_loss=0.172] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.01it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.01it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.13it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.13it/s, train_loss=0.0944]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53 average loss: 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  48%|████▊     | 53/110 [22:04<23:33, 24.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 53 current AUC: 0.9989 current accuracy: 0.9503 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 54/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.57it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.57it/s, train_loss=0.0508]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.91it/s, train_loss=0.0508]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.91it/s, train_loss=0.175] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.81it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.81it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.02it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  5.02it/s, train_loss=0.556]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.95it/s, train_loss=0.556]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.95it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.80it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.80it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.80it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.80it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.89it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.89it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.83it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.83it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.76it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.76it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.69it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.69it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.83it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.83it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:23,  4.61it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:23,  4.61it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.78it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.78it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.90it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.90it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.13it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.13it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.18it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.18it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.00it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.00it/s, train_loss=0.0588]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.01it/s, train_loss=0.0588]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  5.01it/s, train_loss=0.0722]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.95it/s, train_loss=0.0722]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.95it/s, train_loss=0.0609]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.05it/s, train_loss=0.0609]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.05it/s, train_loss=0.186] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.05it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.05it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.14it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.14it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.23it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:18,  5.23it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.01it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.01it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.98it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.98it/s, train_loss=0.0915]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.0915]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.125] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.96it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.96it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  5.03it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.22it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.22it/s, train_loss=0.278] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.20it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.20it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.31it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.31it/s, train_loss=0.0932]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.31it/s, train_loss=0.0932]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.31it/s, train_loss=0.0973]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.39it/s, train_loss=0.0973]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.39it/s, train_loss=0.208] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.42it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.42it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:15,  5.46it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:15,  5.46it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.35it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.35it/s, train_loss=0.0991]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.13it/s, train_loss=0.0991]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.13it/s, train_loss=0.186] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.08it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.95it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.95it/s, train_loss=0.0491]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.05it/s, train_loss=0.0491]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.05it/s, train_loss=0.0964]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.0964]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.122] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.14it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.14it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.09it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.09it/s, train_loss=0.428] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.87it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.87it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.82it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.82it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:16,  4.53it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:16,  4.53it/s, train_loss=0.2]  \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.59it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:15,  4.59it/s, train_loss=0.0924]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.65it/s, train_loss=0.0924]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.65it/s, train_loss=0.389] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.79it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.79it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.76it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.76it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.89it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.89it/s, train_loss=0.0696]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.91it/s, train_loss=0.0696]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  4.91it/s, train_loss=0.209] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.05it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.05it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.21it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.21it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.24it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.24it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.05it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.05it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.14it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  5.14it/s, train_loss=0.0882]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.16it/s, train_loss=0.0882]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.16it/s, train_loss=0.0959]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.15it/s, train_loss=0.0959]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.15it/s, train_loss=0.219] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.08it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.08it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.90it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.90it/s, train_loss=0.0919]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.79it/s, train_loss=0.0919]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:12,  4.79it/s, train_loss=0.258] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:12,  4.63it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:12,  4.63it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.71it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.71it/s, train_loss=0.282] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.79it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.79it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.91it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.91it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.01it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  5.01it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.08it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.08it/s, train_loss=0.144] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.09it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.09it/s, train_loss=0.18] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.07it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.07it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.08it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.08it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.99it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  4.99it/s, train_loss=0.587]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.02it/s, train_loss=0.587]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.02it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.75it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.75it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.79it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.79it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.77it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.77it/s, train_loss=0.0451]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.84it/s, train_loss=0.0451]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:08,  4.84it/s, train_loss=0.251] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.11it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.11it/s, train_loss=0.044]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.02it/s, train_loss=0.044]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.02it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.15it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.15it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.89it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.89it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.93it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  4.93it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.97it/s, train_loss=0.455]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.97it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.27it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.27it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.01it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.01it/s, train_loss=0.115] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.06it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.06it/s, train_loss=0.0638]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.26it/s, train_loss=0.0638]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  5.26it/s, train_loss=0.213] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.08it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.08it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.10it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.10it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.97it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.97it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.94it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.94it/s, train_loss=0.0786]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.95it/s, train_loss=0.0786]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.95it/s, train_loss=0.131] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.11it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.11it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.07it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.07it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.32it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.32it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.28it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.28it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.43it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.43it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.20it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.20it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.08it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.08it/s, train_loss=0.5]  \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.89it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.89it/s, train_loss=0.0893]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.79it/s, train_loss=0.0893]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.79it/s, train_loss=0.206] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.89it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  4.89it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.99it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.99it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.05it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.05it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.10it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.10it/s, train_loss=0.0497]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.34it/s, train_loss=0.0497]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.34it/s, train_loss=0.452] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.11it/s, train_loss=0.452]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.11it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.00it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.00it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.96it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.96it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.08it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.08it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.92it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.92it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.94it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.94it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.97it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.97it/s, train_loss=0.435] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.90it/s, train_loss=0.435]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.90it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.05it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.05it/s, train_loss=0.0755]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.29it/s, train_loss=0.0755]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.29it/s, train_loss=0.186] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.24it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.24it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.03it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.03it/s, train_loss=0.374] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.02it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.02it/s, train_loss=0.14] \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54 average loss: 0.1946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  49%|████▉     | 54/110 [22:29<23:10, 24.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 54 current AUC: 0.9974 current accuracy: 0.9441 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 55/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0456]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.90it/s, train_loss=0.0456]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.90it/s, train_loss=0.255] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:26,  4.60it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:26,  4.60it/s, train_loss=0.532]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.84it/s, train_loss=0.532]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.84it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.90it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.90it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.23it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.23it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.34it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.34it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.42it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.42it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.25it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.25it/s, train_loss=0.0583]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.06it/s, train_loss=0.0583]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.06it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.14it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.14it/s, train_loss=0.0816]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.07it/s, train_loss=0.0816]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.07it/s, train_loss=0.216] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.94it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.94it/s, train_loss=0.0319]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.97it/s, train_loss=0.0319]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.97it/s, train_loss=0.154] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.06it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.06it/s, train_loss=0.0558]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.16it/s, train_loss=0.0558]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.16it/s, train_loss=0.287] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.85it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.85it/s, train_loss=0.0353]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.99it/s, train_loss=0.0353]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.99it/s, train_loss=0.0604]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.98it/s, train_loss=0.0604]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.98it/s, train_loss=0.298] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.06it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.06it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.88it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.88it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.06it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.06it/s, train_loss=0.0677]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.15it/s, train_loss=0.0677]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.15it/s, train_loss=0.419] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.26it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.26it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.37it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.37it/s, train_loss=0.03] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.20it/s, train_loss=0.03]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.20it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.92it/s, train_loss=0.485]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.92it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.82it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.82it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:20,  4.56it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:20,  4.56it/s, train_loss=0.0836]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:20,  4.60it/s, train_loss=0.0836]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:20,  4.60it/s, train_loss=0.103] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:20,  4.52it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:20,  4.52it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.66it/s, train_loss=0.466]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.66it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.76it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.76it/s, train_loss=0.0558]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:19,  4.63it/s, train_loss=0.0558]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:19,  4.63it/s, train_loss=0.317] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.86it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:18,  4.86it/s, train_loss=0.0715]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.03it/s, train_loss=0.0715]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.03it/s, train_loss=0.193] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.12it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.12it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.10it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.10it/s, train_loss=0.516]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.03it/s, train_loss=0.516]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.03it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.04it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:16,  5.04it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.13it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.13it/s, train_loss=0.132] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.22it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.22it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.90it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.90it/s, train_loss=0.16]  \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.90it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.90it/s, train_loss=0.0953]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.95it/s, train_loss=0.0953]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  4.95it/s, train_loss=0.464] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.89it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.89it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.77it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.77it/s, train_loss=0.0409]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.95it/s, train_loss=0.0409]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.95it/s, train_loss=0.2]   \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.99it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.99it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.01it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  5.01it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.09it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.09it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.02it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.02it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.02it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.02it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.04it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.04it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.95it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  4.95it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.81it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.81it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.86it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.86it/s, train_loss=0.0298]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.37it/s, train_loss=0.0298]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.37it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.39it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.39it/s, train_loss=0.0949]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.21it/s, train_loss=0.0949]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.21it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.12it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.12it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.21it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.21it/s, train_loss=0.0493]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.10it/s, train_loss=0.0493]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.10it/s, train_loss=0.115] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.20it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.20it/s, train_loss=0.0663]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.10it/s, train_loss=0.0663]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.10it/s, train_loss=0.177] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.10it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.10it/s, train_loss=0.0705]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.06it/s, train_loss=0.0705]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.06it/s, train_loss=0.0985]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.06it/s, train_loss=0.0985]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.06it/s, train_loss=0.0717]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.99it/s, train_loss=0.0717]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.99it/s, train_loss=0.0952]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.98it/s, train_loss=0.0952]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.98it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.09it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.09it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.25it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.25it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.13it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.13it/s, train_loss=0.177] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.09it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.09it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.78it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.78it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.94it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.94it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.85it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.85it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.05it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.05it/s, train_loss=0.577] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.17it/s, train_loss=0.577]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.17it/s, train_loss=0.553]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.86it/s, train_loss=0.553]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.86it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.15it/s, train_loss=0.498]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.15it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.19it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.19it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.96it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.96it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.14it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.14it/s, train_loss=0.127] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.03it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.03it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.76it/s, train_loss=0.295]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.76it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.80it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.80it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.69it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.69it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.84it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.84it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.19it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.19it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.27it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.27it/s, train_loss=0.0903]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.38it/s, train_loss=0.0903]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.38it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.28it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.28it/s, train_loss=0.0429]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.06it/s, train_loss=0.0429]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.06it/s, train_loss=0.0971]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.18it/s, train_loss=0.0971]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.18it/s, train_loss=0.0822]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.23it/s, train_loss=0.0822]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.23it/s, train_loss=0.129] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.09it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.09it/s, train_loss=0.0378]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.09it/s, train_loss=0.0378]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.09it/s, train_loss=0.0982]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.22it/s, train_loss=0.0982]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.22it/s, train_loss=0.294] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.96it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.96it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.89it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.89it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.95it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.95it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.14it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.14it/s, train_loss=0.35] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.03it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.03it/s, train_loss=0.0194]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.81it/s, train_loss=0.0194]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.81it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.86it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.86it/s, train_loss=0.338] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.99it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.99it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.80it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.80it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.61it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.61it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.60it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.60it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.73it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.73it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.87it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.87it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.73it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.73it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.80it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.80it/s, train_loss=0.0332]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.79it/s, train_loss=0.0332]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.79it/s, train_loss=0.215] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.81it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.81it/s, train_loss=0.0959]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.94it/s, train_loss=0.0959]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.94it/s, train_loss=0.36]  \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.82it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.82it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.12it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.12it/s, train_loss=0.295] \n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55 average loss: 0.1790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 55/110 [22:54<22:46, 24.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 55 current AUC: 0.9927 current accuracy: 0.8696 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 56/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.19it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.19it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.81it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.81it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.12it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.12it/s, train_loss=0.0852]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.19it/s, train_loss=0.0852]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.19it/s, train_loss=0.738] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.14it/s, train_loss=0.738]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.14it/s, train_loss=0.18] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.33it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.33it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.07it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.07it/s, train_loss=0.0553]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.26it/s, train_loss=0.0553]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.26it/s, train_loss=0.00972]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.35it/s, train_loss=0.00972]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.35it/s, train_loss=0.0261] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.10it/s, train_loss=0.0261]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.10it/s, train_loss=0.144] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.16it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.16it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.17it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.17it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.14it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.14it/s, train_loss=0.37] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.88it/s, train_loss=0.37]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.88it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:22,  4.76it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.76it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.89it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.89it/s, train_loss=0.0222]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.80it/s, train_loss=0.0222]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.80it/s, train_loss=0.136] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.99it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.99it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.07it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.07it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.12it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.12it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.18it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.18it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.28it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.28it/s, train_loss=0.122] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.19it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.19it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.06it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.06it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.16it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.16it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.07it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.07it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.80it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.80it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.94it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.94it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.26] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.01it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.01it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.20it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.20it/s, train_loss=0.491] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.13it/s, train_loss=0.491]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.13it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.23it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.23it/s, train_loss=0.0667]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.29it/s, train_loss=0.0667]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.29it/s, train_loss=0.0605]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.36it/s, train_loss=0.0605]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.36it/s, train_loss=0.101] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.20it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.20it/s, train_loss=0.0356]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.18it/s, train_loss=0.0356]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.18it/s, train_loss=0.107] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.15it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.15it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.02it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.02it/s, train_loss=0.058]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.03it/s, train_loss=0.058]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.03it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.20it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.20it/s, train_loss=0.211] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:14,  5.45it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:14,  5.45it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.35it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.35it/s, train_loss=0.282] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.19it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.19it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.09it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.09it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:14,  5.09it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.09it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.01it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.01it/s, train_loss=0.0838]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.0838]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.0546]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.97it/s, train_loss=0.0546]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.97it/s, train_loss=0.366] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.03it/s, train_loss=0.366]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.03it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.02it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.02it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.98it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.98it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.09it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.09it/s, train_loss=0.0905]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.98it/s, train_loss=0.0905]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.98it/s, train_loss=0.114] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.97it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.97it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.87it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.87it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.06it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.06it/s, train_loss=0.171] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.16it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.16it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.23it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.23it/s, train_loss=0.095] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.12it/s, train_loss=0.095]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.12it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:11,  5.30it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.30it/s, train_loss=0.0793]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.33it/s, train_loss=0.0793]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.33it/s, train_loss=0.213] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.19it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.19it/s, train_loss=0.0563]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.90it/s, train_loss=0.0563]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.90it/s, train_loss=0.156] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.87it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.87it/s, train_loss=0.0507]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.10it/s, train_loss=0.0507]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.10it/s, train_loss=0.0826]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.0826]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.57]  \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.97it/s, train_loss=0.57]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.97it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.99it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.99it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.99it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.99it/s, train_loss=0.674]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  5.06it/s, train_loss=0.674]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.06it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.06it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.06it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.96it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.96it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.14it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.14it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.06it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.06it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  4.90it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.90it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.95it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.95it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.95it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.95it/s, train_loss=0.0952]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.18it/s, train_loss=0.0952]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.18it/s, train_loss=0.628] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.98it/s, train_loss=0.628]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.98it/s, train_loss=0.0802]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.95it/s, train_loss=0.0802]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.95it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.95it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.95it/s, train_loss=0.0444]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.13it/s, train_loss=0.0444]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.13it/s, train_loss=0.0748]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.18it/s, train_loss=0.0748]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.18it/s, train_loss=0.201] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.20it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.20it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.21it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.21it/s, train_loss=0.0989]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.23it/s, train_loss=0.0989]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.23it/s, train_loss=0.107] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.27it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.27it/s, train_loss=0.034]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.27it/s, train_loss=0.034]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.27it/s, train_loss=0.0597]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.15it/s, train_loss=0.0597]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.15it/s, train_loss=0.174] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.11it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.11it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.26it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.26it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.11it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.11it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.98it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.98it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.09it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.09it/s, train_loss=0.525] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.92it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.92it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.77it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.77it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.01it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.01it/s, train_loss=0.252] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.13it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.13it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.96it/s, train_loss=0.423]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.96it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.13it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.13it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.13it/s, train_loss=0.306]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.13it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.32it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.32it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.12it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.12it/s, train_loss=0.463] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.22it/s, train_loss=0.463]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.22it/s, train_loss=0.597]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.13it/s, train_loss=0.597]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.13it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.12it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.12it/s, train_loss=0.724]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.12it/s, train_loss=0.724]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.12it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.99it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.99it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.93it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.93it/s, train_loss=0.092]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.93it/s, train_loss=0.092]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.93it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.97it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.97it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.13it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.13it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.00it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.00it/s, train_loss=0.0676]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.93it/s, train_loss=0.0676]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.93it/s, train_loss=0.0529]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.90it/s, train_loss=0.0529]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.90it/s, train_loss=0.193] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.14it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.14it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.11it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.11it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.18it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.18it/s, train_loss=0.0763]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.87it/s, train_loss=0.0763]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.87it/s, train_loss=1.26]  \n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:23<00:00,  5.57it/s, train_loss=1.26]\n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56 average loss: 0.2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  51%|█████     | 56/110 [23:18<22:17, 24.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 56 current AUC: 0.9932 current accuracy: 0.9193 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 57/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.661]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.06it/s, train_loss=0.661]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.06it/s, train_loss=0.0868]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.88it/s, train_loss=0.0868]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.88it/s, train_loss=0.112] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.07it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.07it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.99it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.99it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.01it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.01it/s, train_loss=0.255] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.16it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.16it/s, train_loss=0.854]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.854]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.12it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.12it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.02it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.02it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.12it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.12it/s, train_loss=0.042]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.17it/s, train_loss=0.042]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.17it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.25it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.25it/s, train_loss=0.0723]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.06it/s, train_loss=0.0723]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.06it/s, train_loss=0.239] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.00it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.00it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.92it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.92it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.05it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.05it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.27it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.27it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.21it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.21it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.17it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.17it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.15it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.15it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.15it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.15it/s, train_loss=0.0978]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=0.0978]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:20,  4.80it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.80it/s, train_loss=0.173] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.99it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.99it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.13it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.13it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.92it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.92it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.24it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.24it/s, train_loss=0.0679]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.33it/s, train_loss=0.0679]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.33it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.37it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.37it/s, train_loss=0.00911]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.16it/s, train_loss=0.00911]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.16it/s, train_loss=0.333]  \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.95it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.95it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.88it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.88it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.07it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.07it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.31it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.31it/s, train_loss=0.176] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.44it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.44it/s, train_loss=0.0756]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.26it/s, train_loss=0.0756]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.26it/s, train_loss=0.038] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.03it/s, train_loss=0.038]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.03it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.11it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.11it/s, train_loss=0.02] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.31it/s, train_loss=0.02]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.31it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.19it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.19it/s, train_loss=0.487]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.09it/s, train_loss=0.487]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.09it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.07it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.07it/s, train_loss=0.691]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.93it/s, train_loss=0.691]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.93it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.99it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.99it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.99it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.99it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.86it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.86it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.94it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.94it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.04it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.04it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.87it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.87it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.99it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.99it/s, train_loss=0.0835]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.10it/s, train_loss=0.0835]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.10it/s, train_loss=0.482] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.22it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.22it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.16it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.16it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.08it/s, train_loss=0.581]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.08it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.96it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.96it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.04it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.04it/s, train_loss=0.176] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.06it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.06it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.08it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.08it/s, train_loss=0.364] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.10it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.10it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.13it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.13it/s, train_loss=0.0568]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.02it/s, train_loss=0.0568]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.02it/s, train_loss=0.171] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.20it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.20it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.22it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.22it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.13it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.13it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.96it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.96it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.86it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.86it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.90it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.90it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.75it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.75it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.88it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.88it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.92it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.92it/s, train_loss=0.0476]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.87it/s, train_loss=0.0476]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.87it/s, train_loss=0.387] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.10it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.10it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.02it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.02it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.25it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.25it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.15it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.15it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.36it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.36it/s, train_loss=0.0497]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.29it/s, train_loss=0.0497]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.29it/s, train_loss=0.0863]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.24it/s, train_loss=0.0863]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.24it/s, train_loss=0.157] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.28it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.28it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.18it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.18it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.93it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.93it/s, train_loss=0.0392]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.02it/s, train_loss=0.0392]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.02it/s, train_loss=0.199] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.77it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.77it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.04it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.04it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.09it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.09it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.12it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.12it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.98it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.98it/s, train_loss=0.023]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.98it/s, train_loss=0.023]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.98it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.23it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.23it/s, train_loss=0.686]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.07it/s, train_loss=0.686]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.07it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.09it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.09it/s, train_loss=0.06]  \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.18it/s, train_loss=0.06]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.18it/s, train_loss=0.0867]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.34it/s, train_loss=0.0867]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.34it/s, train_loss=0.0635]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.02it/s, train_loss=0.0635]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.02it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.93it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.93it/s, train_loss=0.198] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.00it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.00it/s, train_loss=1.77] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.02it/s, train_loss=1.77]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.02it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.98it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.98it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.07it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.07it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.13it/s, train_loss=0.513]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.13it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.30it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.30it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.14it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.14it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.22it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.22it/s, train_loss=0.711]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.00it/s, train_loss=0.711]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.00it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.07it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.07it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.94it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.94it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.22it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.22it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.31it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.31it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.06it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.06it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.17it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.17it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.93it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.93it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.95it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.95it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.93it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.93it/s, train_loss=0.137] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.62it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.62it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.90it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.90it/s, train_loss=0.95] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.96it/s, train_loss=0.95]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.96it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.20it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.20it/s, train_loss=0.141]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57 average loss: 0.2326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  52%|█████▏    | 57/110 [23:43<21:49, 24.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 57 current AUC: 0.9974 current accuracy: 0.9130 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 58/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.17it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.17it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.25it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.25it/s, train_loss=0.0488]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.78it/s, train_loss=0.0488]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.78it/s, train_loss=0.134] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.88it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.88it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.84it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.84it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.71it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.71it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:24,  4.63it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:24,  4.63it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.71it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.71it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.85it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.85it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.03it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.03it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.07it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.07it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.06it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.06it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.16it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.16it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.88it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.88it/s, train_loss=0.0627]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.96it/s, train_loss=0.0627]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.96it/s, train_loss=0.0193]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.18it/s, train_loss=0.0193]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.18it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.34it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.34it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.19it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.19it/s, train_loss=0.337] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.00it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  5.00it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.97it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.97it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.01it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.01it/s, train_loss=0.0497]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.03it/s, train_loss=0.0497]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.03it/s, train_loss=0.25]  \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.12it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.12it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.28it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.28it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.16it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.16it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.16it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.16it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.21it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.21it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.92it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.92it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.22it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.22it/s, train_loss=0.0805]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.25it/s, train_loss=0.0805]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.25it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.95it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.95it/s, train_loss=0.0525]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.88it/s, train_loss=0.0525]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.88it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.84it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.84it/s, train_loss=0.167] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.80it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:18,  4.80it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.75it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.75it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.67it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.67it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:18,  4.60it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:18,  4.60it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.94it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.94it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.00it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:16,  5.00it/s, train_loss=0.061]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.84it/s, train_loss=0.061]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.84it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.95it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.95it/s, train_loss=0.0551]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.11it/s, train_loss=0.0551]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.11it/s, train_loss=0.0888]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.27it/s, train_loss=0.0888]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.27it/s, train_loss=0.114] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.23it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:14,  5.23it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.09it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.09it/s, train_loss=0.117] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.17it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.17it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.08it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.08it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.18it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.18it/s, train_loss=0.311] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.00it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.00it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.07it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.07it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.91it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.91it/s, train_loss=0.00598]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=0.00598]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.07it/s, train_loss=1.12]   \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.93it/s, train_loss=1.12]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.93it/s, train_loss=0.00408]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.04it/s, train_loss=0.00408]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.04it/s, train_loss=0.118]  \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.02it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.02it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.04it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.04it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.00it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.00it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.0537]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.10it/s, train_loss=0.0537]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.10it/s, train_loss=0.384] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.93it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.93it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.86it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.86it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.97it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.97it/s, train_loss=0.0334]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.97it/s, train_loss=0.0334]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.97it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.02it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  5.02it/s, train_loss=0.346] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.97it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.97it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.01it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.01it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=0.0991]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.21it/s, train_loss=0.0991]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.21it/s, train_loss=0.264] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.29it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.29it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.13it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.13it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.79it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.79it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.90it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.90it/s, train_loss=0.249] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.86it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.86it/s, train_loss=0.875]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.97it/s, train_loss=0.875]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.97it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.01it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.01it/s, train_loss=0.563]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.88it/s, train_loss=0.563]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.88it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.02it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.02it/s, train_loss=0.0778]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.06it/s, train_loss=0.0778]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.06it/s, train_loss=0.0852]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.07it/s, train_loss=0.0852]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.07it/s, train_loss=0.133] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.08it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.08it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.03it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.03it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.15it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.15it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.06it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.06it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.13it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.13it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.20it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.20it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.96it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.96it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.0764]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.99it/s, train_loss=0.0764]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.99it/s, train_loss=0.389] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.389]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.01it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.01it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.17it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.17it/s, train_loss=0.706]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.706]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.12it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.12it/s, train_loss=0.0947]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.00it/s, train_loss=0.0947]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.00it/s, train_loss=0.0599]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.01it/s, train_loss=0.0599]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.01it/s, train_loss=0.13]  \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.21it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.21it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.21it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.21it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.26it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.26it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.20it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.20it/s, train_loss=0.0557]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.91it/s, train_loss=0.0557]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.91it/s, train_loss=0.406] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.77it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.77it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.96it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.96it/s, train_loss=0.328] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.91it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.91it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.98it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.98it/s, train_loss=0.132] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.00it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.00it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.15it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.15it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.02it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.02it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.11it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.11it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.01it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.01it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.06it/s, train_loss=0.305]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.06it/s, train_loss=0.17] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.25it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.25it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.94it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.94it/s, train_loss=0.0686]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.93it/s, train_loss=0.0686]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.93it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.04it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.04it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.87it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.87it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.95it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.95it/s, train_loss=0.673]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.85it/s, train_loss=0.673]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.85it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.94it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.94it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.90it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.90it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.97it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.97it/s, train_loss=1.03] \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58 average loss: 0.2067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  53%|█████▎    | 58/110 [24:08<21:26, 24.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 58 current AUC: 0.9948 current accuracy: 0.8696 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 59/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0512]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.61it/s, train_loss=0.0512]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.61it/s, train_loss=0.524] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.82it/s, train_loss=0.524]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.82it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.01it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.01it/s, train_loss=0.297] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.01it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  5.01it/s, train_loss=0.0695]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.0695]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.0472]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.07it/s, train_loss=0.0472]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.07it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.98it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.98it/s, train_loss=0.346] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.92it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.92it/s, train_loss=0.541]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.77it/s, train_loss=0.541]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.77it/s, train_loss=0.372]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.70it/s, train_loss=0.372]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.70it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.77it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.77it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.02it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.02it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.86it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.86it/s, train_loss=0.1]  \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.01it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.01it/s, train_loss=0.0848]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.89it/s, train_loss=0.0848]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.89it/s, train_loss=0.0603]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.07it/s, train_loss=0.0603]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.07it/s, train_loss=0.609] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.11it/s, train_loss=0.609]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.11it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.11it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  5.11it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.97it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.97it/s, train_loss=0.35] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.74it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.74it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.63it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.63it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:21,  4.68it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:21,  4.68it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.76it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:20,  4.76it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.79it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.79it/s, train_loss=0.051] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.70it/s, train_loss=0.051]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.70it/s, train_loss=0.681]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.681]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.0265]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.01it/s, train_loss=0.0265]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.01it/s, train_loss=0.403] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.93it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  4.93it/s, train_loss=0.0803]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.08it/s, train_loss=0.0803]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.08it/s, train_loss=0.126] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.03it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.03it/s, train_loss=0.0336]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.91it/s, train_loss=0.0336]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.91it/s, train_loss=0.405] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.94it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.94it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.19it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:16,  5.19it/s, train_loss=0.0726]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.18it/s, train_loss=0.0726]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.18it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.12it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.12it/s, train_loss=0.0851]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=0.0851]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=0.229] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.07it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.07it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.94it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:16,  4.94it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.91it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.91it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.94it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.94it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.98it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.98it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.00it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.00it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.92it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  4.92it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.92it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.92it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.92it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.92it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.23it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.23it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.28it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.28it/s, train_loss=0.807]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.22it/s, train_loss=0.807]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:13,  5.22it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.37it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.37it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.19it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.19it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.21it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.21it/s, train_loss=0.0839]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.07it/s, train_loss=0.0839]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.07it/s, train_loss=0.0813]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.16it/s, train_loss=0.0813]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  5.16it/s, train_loss=0.016] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.07it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.07it/s, train_loss=0.051]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.07it/s, train_loss=0.051]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.07it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.05it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.05it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.86it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.86it/s, train_loss=0.0368]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.93it/s, train_loss=0.0368]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  4.93it/s, train_loss=0.419] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.90it/s, train_loss=0.419]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.90it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.85it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.85it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.87it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.87it/s, train_loss=0.0488]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.06it/s, train_loss=0.0488]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.06it/s, train_loss=0.179] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.07it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  5.07it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.07it/s, train_loss=0.388]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.07it/s, train_loss=0.0893]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.15it/s, train_loss=0.0893]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.15it/s, train_loss=0.246] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.96it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.96it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.90it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.90it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.15it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  5.15it/s, train_loss=0.0547]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.28it/s, train_loss=0.0547]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.28it/s, train_loss=0.12]  \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.28it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.28it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.19it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.19it/s, train_loss=0.0954]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.04it/s, train_loss=0.0954]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.04it/s, train_loss=0.00915]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.08it/s, train_loss=0.00915]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  5.08it/s, train_loss=0.161]  \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.01it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.01it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.12it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.12it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.15it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.15it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.25it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.25it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.32it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.32it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.29it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:07,  5.29it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.16it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.16it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.24it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.24it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.03it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.03it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.84it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.84it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.82it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.82it/s, train_loss=0.247] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.89it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.89it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.02it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.02it/s, train_loss=0.397] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.81it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.81it/s, train_loss=0.09] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.06it/s, train_loss=0.09]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.06it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.12it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.12it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.14it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.14it/s, train_loss=0.0709]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.20it/s, train_loss=0.0709]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.20it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.23it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.23it/s, train_loss=0.323] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.97it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.97it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.03it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.03it/s, train_loss=0.28]  \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.98it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.98it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.21it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.21it/s, train_loss=0.549] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.20it/s, train_loss=0.549]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.20it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.99it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.99it/s, train_loss=0.0902]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.76it/s, train_loss=0.0902]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.76it/s, train_loss=0.315] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.70it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.70it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.80it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.80it/s, train_loss=0.0782]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.94it/s, train_loss=0.0782]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.94it/s, train_loss=0.406] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.95it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.95it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.11it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.11it/s, train_loss=0.673]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.05it/s, train_loss=0.673]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.05it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.89it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.89it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.93it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.93it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.81it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  4.81it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.85it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.85it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.25it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.25it/s, train_loss=0.242] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.07it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.07it/s, train_loss=0.0882]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.20it/s, train_loss=0.0882]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.20it/s, train_loss=0.189] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.27it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.27it/s, train_loss=0.483]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.01it/s, train_loss=0.483]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.01it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.04it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.04it/s, train_loss=0.568]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  5.00it/s, train_loss=0.568]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  5.00it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.75it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.75it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.79it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.79it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.88it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.88it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=0.604]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59 average loss: 0.2196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  54%|█████▎    | 59/110 [24:33<21:03, 24.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 59 current AUC: 0.9921 current accuracy: 0.9006 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 60/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.24it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.24it/s, train_loss=0.222] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.72it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.72it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.90it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.90it/s, train_loss=0.067]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.92it/s, train_loss=0.067]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  4.92it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.00it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.00it/s, train_loss=0.0708]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.89it/s, train_loss=0.0708]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.89it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.95it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.95it/s, train_loss=0.08]  \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.84it/s, train_loss=0.08]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.84it/s, train_loss=0.0224]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.81it/s, train_loss=0.0224]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.81it/s, train_loss=0.182] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.98it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.98it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.81it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.81it/s, train_loss=0.0998]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.85it/s, train_loss=0.0998]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.85it/s, train_loss=0.0509]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.15it/s, train_loss=0.0509]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.15it/s, train_loss=0.235] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.12it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  5.12it/s, train_loss=0.0704]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.98it/s, train_loss=0.0704]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.98it/s, train_loss=0.385] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.04it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.04it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.14it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.14it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.27it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.27it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.08it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.08it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.24it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.24it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.13it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.13it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.41it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.41it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.30it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.30it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.13it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.13it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.30it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.30it/s, train_loss=0.217] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.05it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.05it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.27it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.27it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.32it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.32it/s, train_loss=0.662]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.39it/s, train_loss=0.662]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.39it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.18it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.18it/s, train_loss=0.00431]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.21it/s, train_loss=0.00431]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.21it/s, train_loss=0.0457] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.07it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.07it/s, train_loss=0.269] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.98it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.98it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.08it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.08it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.23it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.23it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.26it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.26it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.31it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.31it/s, train_loss=0.0429]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.10it/s, train_loss=0.0429]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.10it/s, train_loss=0.235] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.99it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.99it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.90it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.90it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:17,  4.69it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:17,  4.69it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.77it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.77it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.66it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.66it/s, train_loss=0.53] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.92it/s, train_loss=0.53]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.92it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.02it/s, train_loss=0.526]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.02it/s, train_loss=0.0419]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.89it/s, train_loss=0.0419]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.89it/s, train_loss=0.131] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.09it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.09it/s, train_loss=0.0838]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.29it/s, train_loss=0.0838]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:13,  5.29it/s, train_loss=0.209] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.09it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.09it/s, train_loss=0.531]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.11it/s, train_loss=0.531]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.11it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.07it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.07it/s, train_loss=0.0481]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.02it/s, train_loss=0.0481]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.02it/s, train_loss=0.281] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.92it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.92it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.12it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.12it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.02it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.02it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.98it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.98it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.85it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.85it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.84it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.84it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.89it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.89it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.01it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.01it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.00it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.00it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.92it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.92it/s, train_loss=0.0389]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.13it/s, train_loss=0.0389]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.13it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.88it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.88it/s, train_loss=0.378] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.83it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.83it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.89it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.89it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.82it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.82it/s, train_loss=0.0944]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.90it/s, train_loss=0.0944]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.90it/s, train_loss=0.0867]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.98it/s, train_loss=0.0867]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.98it/s, train_loss=0.0312]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.97it/s, train_loss=0.0312]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.97it/s, train_loss=0.412] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.90it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.90it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.82it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.82it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.63it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:10,  4.63it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:10,  4.66it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:10,  4.66it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.72it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.72it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.85it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.85it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.66it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.66it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.71it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:09,  4.71it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.92it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.92it/s, train_loss=0.012]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.88it/s, train_loss=0.012]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.88it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.93it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.93it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.0885]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.13it/s, train_loss=0.0885]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.13it/s, train_loss=0.275] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.29it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:06,  5.29it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.54it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.54it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.36it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.36it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.12it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.12it/s, train_loss=0.00624]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.00624]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.326]  \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.00it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.00it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.14it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.14it/s, train_loss=0.377] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.14it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.14it/s, train_loss=0.0343]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.90it/s, train_loss=0.0343]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.90it/s, train_loss=0.014] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.83it/s, train_loss=0.014]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.83it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.93it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.93it/s, train_loss=0.12] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.87it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.87it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.00it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.00it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.11it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.11it/s, train_loss=0.0663]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.93it/s, train_loss=0.0663]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.93it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.04it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.04it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.01it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.01it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.86it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.86it/s, train_loss=0.0951]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.76it/s, train_loss=0.0951]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.76it/s, train_loss=0.271] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.72it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  4.72it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.76it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.76it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.03it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.03it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.11it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.11it/s, train_loss=0.0834]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.34it/s, train_loss=0.0834]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.34it/s, train_loss=0.216] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.39it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.39it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.14it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.14it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.13it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.13it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.32it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.32it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=0.0839]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.07it/s, train_loss=0.0839]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.07it/s, train_loss=0.178] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.88it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.88it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.91it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.91it/s, train_loss=0.762]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.762]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.848]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.86it/s, train_loss=0.848]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.86it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.04it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.04it/s, train_loss=0.0702]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.92it/s, train_loss=0.0702]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.92it/s, train_loss=0.255] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=0.534]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60 average loss: 0.1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  55%|█████▍    | 60/110 [24:57<20:40, 24.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 60 current AUC: 0.9981 current accuracy: 0.9441 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 61/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0597]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.56it/s, train_loss=0.0597]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.56it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.50it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.50it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.97it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.97it/s, train_loss=0.0238]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.97it/s, train_loss=0.0238]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  4.97it/s, train_loss=0.182] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.70it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.70it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:25,  4.57it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:25,  4.57it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.61it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.61it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.80it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.80it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.92it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.92it/s, train_loss=0.0868]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.91it/s, train_loss=0.0868]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.91it/s, train_loss=0.172] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  5.00it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  5.00it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.87it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.87it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.83it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.83it/s, train_loss=0.371] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.75it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.75it/s, train_loss=0.0641]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.86it/s, train_loss=0.0641]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.86it/s, train_loss=0.252] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.88it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.88it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.79it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.79it/s, train_loss=0.479]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.80it/s, train_loss=0.479]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:21,  4.80it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.91it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.91it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.85it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.85it/s, train_loss=0.255] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.74it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.74it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.09it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.09it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.15it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:19,  5.15it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.26it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.26it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.44it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.44it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.21it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.21it/s, train_loss=0.864] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.22it/s, train_loss=0.864]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.22it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.94it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  4.94it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.87it/s, train_loss=0.489]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.87it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.79it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.79it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.76it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.76it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:19,  4.61it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:19,  4.61it/s, train_loss=0.0998]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.88it/s, train_loss=0.0998]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:18,  4.88it/s, train_loss=0.254] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.85it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.85it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.95it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.95it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.95it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.95it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.08it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.08it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.31it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:15,  5.31it/s, train_loss=0.054]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.20it/s, train_loss=0.054]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.20it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.20it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.20it/s, train_loss=0.632]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.09it/s, train_loss=0.632]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.09it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.02it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.02it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.09it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  5.09it/s, train_loss=0.0569]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.08it/s, train_loss=0.0569]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.08it/s, train_loss=0.0774]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.87it/s, train_loss=0.0774]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.87it/s, train_loss=0.176] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.95it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.95it/s, train_loss=0.0557]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.09it/s, train_loss=0.0557]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.09it/s, train_loss=0.737] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.14it/s, train_loss=0.737]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  5.14it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.32it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.32it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.19it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.19it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.12it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.12it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.73it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.73it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.00it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  5.00it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.13it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.13it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.35it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.35it/s, train_loss=0.0658]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:11,  5.48it/s, train_loss=0.0658]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:11,  5.48it/s, train_loss=0.754] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.33it/s, train_loss=0.754]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.33it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.04it/s, train_loss=0.461]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  5.04it/s, train_loss=0.0681]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.08it/s, train_loss=0.0681]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.08it/s, train_loss=0.167] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.22it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.22it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.36it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.36it/s, train_loss=0.0813]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.32it/s, train_loss=0.0813]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.32it/s, train_loss=0.422] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.15it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.15it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.02it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.02it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.92it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.92it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.94it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.94it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.02it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.02it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.06it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.06it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.08it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.08it/s, train_loss=0.00604]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.89it/s, train_loss=0.00604]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.89it/s, train_loss=0.172]  \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.77it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.77it/s, train_loss=0.00654]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.91it/s, train_loss=0.00654]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.91it/s, train_loss=0.208]  \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.16it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  5.16it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.91it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.91it/s, train_loss=0.081]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.86it/s, train_loss=0.081]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.86it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.88it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.88it/s, train_loss=0.0269]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.94it/s, train_loss=0.0269]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.94it/s, train_loss=0.251] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.74it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:09,  4.74it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.96it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.96it/s, train_loss=0.0872]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.77it/s, train_loss=0.0872]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.77it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.81it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.81it/s, train_loss=0.234] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.11it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.11it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  4.98it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.04it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.04it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.99it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.99it/s, train_loss=0.0269]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.0269]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.399] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.85it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.85it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.90it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  4.90it/s, train_loss=0.183] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.14it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.14it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.14it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.14it/s, train_loss=0.0475]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.22it/s, train_loss=0.0475]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.22it/s, train_loss=0.273] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.15it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.15it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.04it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  5.04it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.94it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.94it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.13it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.13it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  5.00it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  5.00it/s, train_loss=0.0591]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.84it/s, train_loss=0.0591]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.84it/s, train_loss=0.148] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.98it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:20<00:04,  4.98it/s, train_loss=0.0849]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.15it/s, train_loss=0.0849]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.15it/s, train_loss=0.337] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.08it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.08it/s, train_loss=0.0949]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.12it/s, train_loss=0.0949]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.12it/s, train_loss=0.163] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.04it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.04it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.22it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  5.22it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.97it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.97it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.99it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.99it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.17it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.17it/s, train_loss=0.153] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.12it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.12it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.98it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.98it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.04it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.04it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.91it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.91it/s, train_loss=0.172] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.80it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.80it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.64it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.64it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.68it/s, train_loss=0.357]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.68it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.82it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.82it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.95it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.95it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.93it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.93it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.78it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.78it/s, train_loss=0.0886]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.74it/s, train_loss=0.0886]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.74it/s, train_loss=0.337] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.98it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.98it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.07it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.07it/s, train_loss=0.671]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61 average loss: 0.2069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  55%|█████▌    | 61/110 [25:22<20:17, 24.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 61 current AUC: 0.9958 current accuracy: 0.8944 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 62/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.72it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.72it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.55it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.55it/s, train_loss=0.213] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.42it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.42it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.26it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.26it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.25it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.25it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.30it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.30it/s, train_loss=0.268] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.39it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.39it/s, train_loss=0.0607]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.34it/s, train_loss=0.0607]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.34it/s, train_loss=0.374] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:20,  5.38it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:20,  5.38it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.31it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.31it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.21it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.21it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.03it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.03it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.94it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.94it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.02it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.02it/s, train_loss=0.122] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.08it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.08it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.92it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.92it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.91it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.91it/s, train_loss=0.218] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.83it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.83it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.88it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.88it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:21,  4.85it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.85it/s, train_loss=0.116] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.90it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.90it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.87it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.87it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.93it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.93it/s, train_loss=0.241] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.17it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.17it/s, train_loss=0.044]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.09it/s, train_loss=0.044]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.09it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.05it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.05it/s, train_loss=0.044]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.95it/s, train_loss=0.044]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.95it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.75it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.75it/s, train_loss=0.0963]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.72it/s, train_loss=0.0963]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.72it/s, train_loss=0.28]  \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:19,  4.67it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:19,  4.67it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.76it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.76it/s, train_loss=0.0577]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.86it/s, train_loss=0.0577]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.86it/s, train_loss=0.19]  \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.78it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.78it/s, train_loss=0.0247]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.97it/s, train_loss=0.0247]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.97it/s, train_loss=0.226] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.05it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.05it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.99it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.99it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.03it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.03it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.07it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.07it/s, train_loss=0.0656]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.23it/s, train_loss=0.0656]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.23it/s, train_loss=0.099] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.12it/s, train_loss=0.099]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.12it/s, train_loss=0.0666]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.29it/s, train_loss=0.0666]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.29it/s, train_loss=0.078] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.27it/s, train_loss=0.078]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.27it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.35it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.35it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.45it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.45it/s, train_loss=0.237] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.36it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.36it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.31it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.31it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.25it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.25it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.18it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.18it/s, train_loss=0.18]  \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.95it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.95it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.10it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.10it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.18it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.18it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.13it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.13it/s, train_loss=0.0204]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.86it/s, train_loss=0.0204]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.86it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.93it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.93it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.87it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.87it/s, train_loss=0.291] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.84it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.84it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.90it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.90it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.19it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.19it/s, train_loss=0.425] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.13it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.13it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.98it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.98it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.85it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.85it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.67it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.67it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.80it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.80it/s, train_loss=0.063]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.88it/s, train_loss=0.063]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.88it/s, train_loss=0.0797]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.77it/s, train_loss=0.0797]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.77it/s, train_loss=0.181] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.82it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.82it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.98it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.98it/s, train_loss=0.0289]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.92it/s, train_loss=0.0289]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.92it/s, train_loss=0.25]  \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.90it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.90it/s, train_loss=0.0634]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.01it/s, train_loss=0.0634]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.01it/s, train_loss=0.0324]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.87it/s, train_loss=0.0324]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.87it/s, train_loss=0.0859]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.94it/s, train_loss=0.0859]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.94it/s, train_loss=0.471] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.98it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.98it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.01it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.01it/s, train_loss=0.0829]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.99it/s, train_loss=0.0829]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.99it/s, train_loss=0.351] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.13it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.13it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.25it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.25it/s, train_loss=0.037] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.05it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.05it/s, train_loss=0.0439]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.14it/s, train_loss=0.0439]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.14it/s, train_loss=0.608] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.41it/s, train_loss=0.608]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.41it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.53it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.53it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.19it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.19it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.36it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.36it/s, train_loss=0.0473]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.96it/s, train_loss=0.0473]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.96it/s, train_loss=0.294] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.78it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.78it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.73it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.73it/s, train_loss=0.108] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.78it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.78it/s, train_loss=0.0943]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.97it/s, train_loss=0.0943]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.97it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.98it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.98it/s, train_loss=0.0198]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.09it/s, train_loss=0.0198]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.09it/s, train_loss=0.698] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.82it/s, train_loss=0.698]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.82it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.88it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.88it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.91it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.91it/s, train_loss=0.8]  \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.89it/s, train_loss=0.8]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.89it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.83it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.83it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.79it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.79it/s, train_loss=0.192] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.80it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.80it/s, train_loss=0.072]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.90it/s, train_loss=0.072]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.90it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.01it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.01it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.14it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.14it/s, train_loss=0.00754]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.15it/s, train_loss=0.00754]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.15it/s, train_loss=0.112]  \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.04it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.04it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.97it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.97it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.01it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.01it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.02it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.02it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.08it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.08it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.14it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.14it/s, train_loss=0.098] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.99it/s, train_loss=0.098]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.99it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.92it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.92it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.89it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.89it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.89it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.89it/s, train_loss=0.0782]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.12it/s, train_loss=0.0782]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.12it/s, train_loss=0.0994]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.0994]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.0504]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.16it/s, train_loss=0.0504]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.16it/s, train_loss=0.146] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.03it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.03it/s, train_loss=0.0934]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.78it/s, train_loss=0.0934]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.78it/s, train_loss=0.486] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.89it/s, train_loss=0.486]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.89it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.93it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.93it/s, train_loss=0.1]  \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.12it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.12it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.03it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.03it/s, train_loss=0.532]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62 average loss: 0.1654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  56%|█████▋    | 62/110 [25:47<19:51, 24.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 62 current AUC: 0.9901 current accuracy: 0.8882 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 63/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.65it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.65it/s, train_loss=0.0802]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.27it/s, train_loss=0.0802]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.27it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.87it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.87it/s, train_loss=0.1]  \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:25,  4.71it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:25,  4.71it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.97it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.97it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.11it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.11it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.08it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.08it/s, train_loss=0.0965]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.23it/s, train_loss=0.0965]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.23it/s, train_loss=0.0839]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.23it/s, train_loss=0.0839]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.23it/s, train_loss=0.0408]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.05it/s, train_loss=0.0408]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.05it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.20it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.20it/s, train_loss=0.0633]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.31it/s, train_loss=0.0633]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.31it/s, train_loss=0.369] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.37it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.37it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.21it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.21it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.17it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.17it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.17it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.17it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.01it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.01it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.94it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.94it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.04it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.04it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.27it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.27it/s, train_loss=0.0124]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.19it/s, train_loss=0.0124]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.19it/s, train_loss=0.155] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.14it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.14it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.13it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.13it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.17it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.17it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.86it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.86it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.84it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.84it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.93it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.93it/s, train_loss=0.0732]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.98it/s, train_loss=0.0732]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.98it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.82it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.82it/s, train_loss=0.133] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.88it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.88it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.13it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.13it/s, train_loss=0.0892]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.19it/s, train_loss=0.0892]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.19it/s, train_loss=0.214] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.09it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.09it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.99it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.99it/s, train_loss=0.0614]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.97it/s, train_loss=0.0614]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.97it/s, train_loss=0.0756]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.82it/s, train_loss=0.0756]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.82it/s, train_loss=0.0702]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.82it/s, train_loss=0.0702]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.82it/s, train_loss=0.0845]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.87it/s, train_loss=0.0845]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.87it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.84it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.84it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.87it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.87it/s, train_loss=0.217] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.92it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.92it/s, train_loss=0.0462]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.09it/s, train_loss=0.0462]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.09it/s, train_loss=0.158] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.14it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.14it/s, train_loss=0.0991]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.00it/s, train_loss=0.0991]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.00it/s, train_loss=0.233] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:16,  4.80it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.80it/s, train_loss=0.0932]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.83it/s, train_loss=0.0932]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.83it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.82it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.82it/s, train_loss=0.256] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.88it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.88it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.78it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:15,  4.78it/s, train_loss=0.404] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.68it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.68it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.79it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.79it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.98it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.98it/s, train_loss=0.0466]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.15it/s, train_loss=0.0466]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.15it/s, train_loss=0.132] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.88it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  4.88it/s, train_loss=0.0288]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.85it/s, train_loss=0.0288]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.85it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.74it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.74it/s, train_loss=0.195] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.76it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.76it/s, train_loss=0.0206]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.75it/s, train_loss=0.0206]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.75it/s, train_loss=0.205] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.87it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  4.87it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.89it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.89it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.88it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.88it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.95it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.95it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.92it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.92it/s, train_loss=0.17] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.06it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  5.06it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.99it/s, train_loss=0.578]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.99it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.00it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.00it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.96it/s, train_loss=0.598]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.96it/s, train_loss=0.68] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.18it/s, train_loss=0.68]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.18it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.10it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.10it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.32it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.32it/s, train_loss=0.0464]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.28it/s, train_loss=0.0464]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.28it/s, train_loss=0.216] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.15it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.15it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.12it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.12it/s, train_loss=0.728] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.95it/s, train_loss=0.728]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.95it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.18it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.18it/s, train_loss=0.0624]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.22it/s, train_loss=0.0624]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.22it/s, train_loss=0.123] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.02it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.02it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.14it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.14it/s, train_loss=0.275] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.00it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.00it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.90it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.90it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.91it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.91it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.14it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.14it/s, train_loss=0.0643]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.00it/s, train_loss=0.0643]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.00it/s, train_loss=0.0802]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.21it/s, train_loss=0.0802]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.21it/s, train_loss=0.405] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.13it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.13it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.15it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.15it/s, train_loss=0.109] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.02it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.02it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.93it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.93it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.73it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  4.73it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.63it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.63it/s, train_loss=0.16]  \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.62it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.62it/s, train_loss=0.0166]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.81it/s, train_loss=0.0166]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.81it/s, train_loss=0.282] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.00it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.00it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.96it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.96it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.92it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.92it/s, train_loss=0.1]  \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.03it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.03it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.84it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.84it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.89it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.89it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.94it/s, train_loss=0.408]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:20<00:04,  4.94it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.12it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.12it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.10it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.10it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.02it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  5.02it/s, train_loss=0.00737]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.15it/s, train_loss=0.00737]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.15it/s, train_loss=0.101]  \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.07it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.07it/s, train_loss=0.025]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.93it/s, train_loss=0.025]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.93it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.33it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.33it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.14it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  5.14it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.93it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.93it/s, train_loss=0.0948]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.12it/s, train_loss=0.0948]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.12it/s, train_loss=0.201] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.20it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.20it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.37it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.37it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.21it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.21it/s, train_loss=0.443] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.08it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.08it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.01it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.01it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.92it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.92it/s, train_loss=0.0592]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.94it/s, train_loss=0.0592]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.94it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.97it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.97it/s, train_loss=0.0632]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.00it/s, train_loss=0.0632]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.00it/s, train_loss=0.665] \n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.78it/s, train_loss=0.665]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63 average loss: 0.1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  57%|█████▋    | 63/110 [26:12<19:27, 24.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 63 current AUC: 0.9946 current accuracy: 0.9130 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 64/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.66it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.66it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.02it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.02it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.95it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.95it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.98it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.98it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.16it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.16it/s, train_loss=0.34] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.24it/s, train_loss=0.34]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.24it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.12it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.12it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.82it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.82it/s, train_loss=0.0529]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.78it/s, train_loss=0.0529]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.78it/s, train_loss=0.109] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.72it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.72it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.67it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.67it/s, train_loss=0.0748]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.90it/s, train_loss=0.0748]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.90it/s, train_loss=0.541] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.12it/s, train_loss=0.541]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.12it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.20it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.20it/s, train_loss=0.0342]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.37it/s, train_loss=0.0342]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.37it/s, train_loss=0.462] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.46it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.46it/s, train_loss=0.0652]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.35it/s, train_loss=0.0652]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.35it/s, train_loss=0.073] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:18,  5.58it/s, train_loss=0.073]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:18,  5.58it/s, train_loss=0.0821]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.27it/s, train_loss=0.0821]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.27it/s, train_loss=0.163] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.39it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.39it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.24it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.24it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.25it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.25it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.14it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.14it/s, train_loss=0.0718]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.97it/s, train_loss=0.0718]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.97it/s, train_loss=0.232] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.89it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.89it/s, train_loss=0.0736]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.98it/s, train_loss=0.0736]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.98it/s, train_loss=0.232] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.97it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.97it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.03it/s, train_loss=0.044]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.19it/s, train_loss=0.044]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.19it/s, train_loss=0.00881]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.13it/s, train_loss=0.00881]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.13it/s, train_loss=0.136]  \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.10it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.10it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.98it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.98it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.82it/s, train_loss=0.359]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.82it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.99it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.99it/s, train_loss=0.338] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.11it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.11it/s, train_loss=0.045]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.14it/s, train_loss=0.045]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.14it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.26it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.26it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.18it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.18it/s, train_loss=0.0399]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.13it/s, train_loss=0.0399]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.13it/s, train_loss=0.11]  \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.93it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.93it/s, train_loss=0.0938]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.12it/s, train_loss=0.0938]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.12it/s, train_loss=0.0841]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.47it/s, train_loss=0.0841]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.47it/s, train_loss=0.488] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.41it/s, train_loss=0.488]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.41it/s, train_loss=0.0812]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.33it/s, train_loss=0.0812]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.33it/s, train_loss=0.4]   \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:14,  5.38it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.38it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.22it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.22it/s, train_loss=0.0952]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.20it/s, train_loss=0.0952]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.20it/s, train_loss=0.0528]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.10it/s, train_loss=0.0528]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.10it/s, train_loss=0.0451]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.10it/s, train_loss=0.0451]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.10it/s, train_loss=0.179] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:14,  5.02it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.02it/s, train_loss=0.0245]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.30it/s, train_loss=0.0245]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.30it/s, train_loss=0.431] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.33it/s, train_loss=0.431]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.33it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.39it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.39it/s, train_loss=0.0667]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.46it/s, train_loss=0.0667]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.46it/s, train_loss=0.156] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.34it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.34it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.32it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.32it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:11,  5.37it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:11,  5.37it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.50it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.50it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.42it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.42it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:11,  5.22it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.22it/s, train_loss=0.0238]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.15it/s, train_loss=0.0238]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.15it/s, train_loss=0.0962]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.04it/s, train_loss=0.0962]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.04it/s, train_loss=0.0656]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.01it/s, train_loss=0.0656]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.01it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.19it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.19it/s, train_loss=0.583] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.29it/s, train_loss=0.583]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.29it/s, train_loss=0.934]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.12it/s, train_loss=0.934]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.12it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.04it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.04it/s, train_loss=0.034]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.91it/s, train_loss=0.034]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.91it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.87it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.87it/s, train_loss=0.0254]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  4.96it/s, train_loss=0.0254]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.96it/s, train_loss=0.0768]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.00it/s, train_loss=0.0768]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.00it/s, train_loss=0.154] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.00it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.00it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.93it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.93it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.75it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.75it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  4.92it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.92it/s, train_loss=0.0733]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.99it/s, train_loss=0.0733]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.99it/s, train_loss=0.243] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.98it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.98it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.22it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.22it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.98it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.98it/s, train_loss=0.0326]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.10it/s, train_loss=0.0326]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.10it/s, train_loss=0.243] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.20it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.20it/s, train_loss=0.45] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.33it/s, train_loss=0.45]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.33it/s, train_loss=0.1] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.01it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.01it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.26it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.26it/s, train_loss=0.662]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.26it/s, train_loss=0.662]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.26it/s, train_loss=0.0476]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:16<00:06,  5.15it/s, train_loss=0.0476]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.15it/s, train_loss=0.556] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.03it/s, train_loss=0.556]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.03it/s, train_loss=0.0542]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.81it/s, train_loss=0.0542]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.81it/s, train_loss=0.0987]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.79it/s, train_loss=0.0987]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.79it/s, train_loss=0.164] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.95it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.95it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:17<00:05,  5.23it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.23it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.21it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.21it/s, train_loss=0.0789]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.10it/s, train_loss=0.0789]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.10it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.05it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.05it/s, train_loss=0.162] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.19it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.19it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:18<00:04,  5.06it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.06it/s, train_loss=0.0908]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.88it/s, train_loss=0.0908]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.88it/s, train_loss=0.34]  \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.81it/s, train_loss=0.34]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.81it/s, train_loss=0.0411]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.85it/s, train_loss=0.0411]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.85it/s, train_loss=0.356] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.88it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.88it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.28it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.28it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.13it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.13it/s, train_loss=0.243] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.21it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.21it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.15it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.15it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:20<00:02,  5.28it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.28it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.07it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.07it/s, train_loss=0.226] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.87it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.87it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.83it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.83it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.95it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.95it/s, train_loss=0.463]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:01,  5.05it/s, train_loss=0.463]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.05it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.03it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.03it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.02it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.02it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.98it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.98it/s, train_loss=0.0086]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.20it/s, train_loss=0.0086]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.20it/s, train_loss=0.236] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:22<00:00,  5.04it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.04it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.27it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.27it/s, train_loss=0.646]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.19it/s, train_loss=0.646]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.19it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.12it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.12it/s, train_loss=0.27] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.92it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.92it/s, train_loss=0.0883]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64 average loss: 0.1836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  58%|█████▊    | 64/110 [26:36<18:57, 24.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 64 current AUC: 0.9930 current accuracy: 0.8696 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 65/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:27,  4.34it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:27,  4.34it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.73it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.73it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.81it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.81it/s, train_loss=0.0662]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.87it/s, train_loss=0.0662]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.87it/s, train_loss=0.0738]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.00it/s, train_loss=0.0738]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.00it/s, train_loss=0.278] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.09it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.09it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.00it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.00it/s, train_loss=0.0613]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.91it/s, train_loss=0.0613]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.91it/s, train_loss=0.343] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.10it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  5.10it/s, train_loss=0.0651]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.06it/s, train_loss=0.0651]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.06it/s, train_loss=0.191] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.03it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.03it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.82it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.82it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.87it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.87it/s, train_loss=0.568]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.88it/s, train_loss=0.568]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.88it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.76it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.76it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.05it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.05it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.08it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.08it/s, train_loss=0.0305]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.98it/s, train_loss=0.0305]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.98it/s, train_loss=0.323] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.83it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:21,  4.83it/s, train_loss=0.31] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.93it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.93it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.88it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.88it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.05it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.05it/s, train_loss=0.309] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.00it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.00it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.94it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:19,  4.94it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.70it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.70it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.88it/s, train_loss=0.338]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.88it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.11it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.11it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.93it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.93it/s, train_loss=0.0634]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.10it/s, train_loss=0.0634]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  5.10it/s, train_loss=0.337] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.08it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.08it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.08it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.08it/s, train_loss=0.272] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.01it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.01it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.04it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.04it/s, train_loss=0.0938]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.03it/s, train_loss=0.0938]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  5.03it/s, train_loss=0.129] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.03it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.03it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.02it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.02it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.05it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.05it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.99it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.99it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.94it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:16,  4.94it/s, train_loss=0.0956]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.00it/s, train_loss=0.0956]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.00it/s, train_loss=0.208] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.93it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.93it/s, train_loss=0.0947]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.10it/s, train_loss=0.0947]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.10it/s, train_loss=0.041] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.04it/s, train_loss=0.041]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.04it/s, train_loss=0.0818]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.15it/s, train_loss=0.0818]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  5.15it/s, train_loss=0.196] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.09it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.09it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.04it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.04it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.15it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.15it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.16it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.16it/s, train_loss=0.0057]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.21it/s, train_loss=0.0057]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  5.21it/s, train_loss=0.384] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.10it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.10it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.98it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.98it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.84it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.84it/s, train_loss=0.763]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.83it/s, train_loss=0.763]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.83it/s, train_loss=0.628]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.80it/s, train_loss=0.628]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:14,  4.80it/s, train_loss=0.859]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.80it/s, train_loss=0.859]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.80it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.93it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.93it/s, train_loss=0.0926]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.06it/s, train_loss=0.0926]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.06it/s, train_loss=0.289] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.93it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.93it/s, train_loss=0.0384]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.01it/s, train_loss=0.0384]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  5.01it/s, train_loss=0.329] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.87it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.87it/s, train_loss=0.0742]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.88it/s, train_loss=0.0742]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.88it/s, train_loss=0.0526]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.88it/s, train_loss=0.0526]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.88it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.09it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.09it/s, train_loss=0.231] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.03it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  5.03it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.16it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.16it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.12it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.12it/s, train_loss=0.0738]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=0.0738]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=0.255] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.17it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.17it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.06it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  5.06it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.11it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.11it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.37it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.37it/s, train_loss=0.16]  \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.26it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.26it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.16it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.16it/s, train_loss=0.131] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.12it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  5.12it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.94it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.94it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.99it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.99it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.94it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.94it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.10it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.10it/s, train_loss=0.0689]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.03it/s, train_loss=0.0689]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.03it/s, train_loss=0.0484]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.25it/s, train_loss=0.0484]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.25it/s, train_loss=0.116] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.11it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.11it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.03it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.03it/s, train_loss=0.0961]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.27it/s, train_loss=0.0961]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.27it/s, train_loss=0.173] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.09it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.09it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.04it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.04it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.93it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.93it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.12it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.12it/s, train_loss=0.0442]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.13it/s, train_loss=0.0442]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.13it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.08it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.08it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.95it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.95it/s, train_loss=0.0429]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.91it/s, train_loss=0.0429]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.91it/s, train_loss=0.262] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.87it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.87it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.90it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.90it/s, train_loss=0.772]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.17it/s, train_loss=0.772]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.17it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.28it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.28it/s, train_loss=0.0978]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.38it/s, train_loss=0.0978]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.38it/s, train_loss=0.195] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.38it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.38it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.93it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.93it/s, train_loss=0.0966]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.84it/s, train_loss=0.0966]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.84it/s, train_loss=0.301] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.94it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.94it/s, train_loss=0.059]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.87it/s, train_loss=0.059]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.87it/s, train_loss=0.0972]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.81it/s, train_loss=0.0972]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.81it/s, train_loss=0.115] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.88it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.88it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.84it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.84it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.02it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.02it/s, train_loss=0.239] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.21it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.21it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.12it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.12it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.26it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.26it/s, train_loss=0.285] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.24it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.24it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.99it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.99it/s, train_loss=0.0709]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.98it/s, train_loss=0.0709]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.98it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.95it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.95it/s, train_loss=0.0394]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.06it/s, train_loss=0.0394]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.06it/s, train_loss=0.292] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.04it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.04it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.89it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.89it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.21it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.21it/s, train_loss=0.0948]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.08it/s, train_loss=0.0948]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.08it/s, train_loss=0.0167]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.17it/s, train_loss=0.0167]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.17it/s, train_loss=0.284] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.06it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.06it/s, train_loss=0.053]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.96it/s, train_loss=0.053]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.96it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.82it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.82it/s, train_loss=0.162]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65 average loss: 0.1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  59%|█████▉    | 65/110 [27:01<18:34, 24.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 65 current AUC: 0.9981 current accuracy: 0.9006 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 66/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.67it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.67it/s, train_loss=0.0291]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.97it/s, train_loss=0.0291]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.97it/s, train_loss=0.0973]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.90it/s, train_loss=0.0973]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.90it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.98it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  4.98it/s, train_loss=0.0193]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.93it/s, train_loss=0.0193]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.93it/s, train_loss=0.169] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.79it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.79it/s, train_loss=0.0717]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.0717]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.269] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.20it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:21,  5.20it/s, train_loss=0.0494]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.94it/s, train_loss=0.0494]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.94it/s, train_loss=0.103] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.97it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.97it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.76it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.76it/s, train_loss=0.0732]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.81it/s, train_loss=0.0732]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.81it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.96it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  4.96it/s, train_loss=0.378] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.10it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.10it/s, train_loss=0.0412]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.03it/s, train_loss=0.0412]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.03it/s, train_loss=0.0454]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.08it/s, train_loss=0.0454]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.08it/s, train_loss=0.154] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.98it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.98it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.95it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  4.95it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.00it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.00it/s, train_loss=0.0295]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.09it/s, train_loss=0.0295]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.09it/s, train_loss=0.0803]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.99it/s, train_loss=0.0803]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.99it/s, train_loss=0.0642]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.87it/s, train_loss=0.0642]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.87it/s, train_loss=0.239] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.85it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:20,  4.85it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.72it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.72it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.75it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.75it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  5.00it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  5.00it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.90it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.90it/s, train_loss=0.0982]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.14it/s, train_loss=0.0982]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  5.14it/s, train_loss=0.0813]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.14it/s, train_loss=0.0813]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.14it/s, train_loss=0.411] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.91it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.91it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.82it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.82it/s, train_loss=0.0773]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:19,  4.67it/s, train_loss=0.0773]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:19,  4.67it/s, train_loss=0.174] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.95it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  4.95it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.93it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.93it/s, train_loss=0.039]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.93it/s, train_loss=0.039]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.93it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.13it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.13it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.26it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.26it/s, train_loss=0.0657]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.23it/s, train_loss=0.0657]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:15,  5.23it/s, train_loss=0.00659]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.10it/s, train_loss=0.00659]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.10it/s, train_loss=0.0531] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.00it/s, train_loss=0.0531]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.00it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.0596]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.92it/s, train_loss=0.0596]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.92it/s, train_loss=0.221] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.12it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  5.12it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.35it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.35it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:13,  5.46it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:13,  5.46it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.53it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.53it/s, train_loss=0.0575]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.25it/s, train_loss=0.0575]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.25it/s, train_loss=0.657] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.09it/s, train_loss=0.657]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.09it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.17it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.17it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.29it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.29it/s, train_loss=0.0469]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.37it/s, train_loss=0.0469]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.37it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.15it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.15it/s, train_loss=0.0243]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.14it/s, train_loss=0.0243]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.14it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.05it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.05it/s, train_loss=0.0532]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.91it/s, train_loss=0.0532]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.91it/s, train_loss=0.151] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.93it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.93it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.99it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.99it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.02it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.02it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.13it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.13it/s, train_loss=0.00408]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.28it/s, train_loss=0.00408]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.28it/s, train_loss=0.109]  \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.41it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.41it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.15it/s, train_loss=0.573]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.15it/s, train_loss=0.02] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.25it/s, train_loss=0.02]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.25it/s, train_loss=0.0587]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.18it/s, train_loss=0.0587]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.18it/s, train_loss=0.224] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.99it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.99it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.79it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.79it/s, train_loss=0.0889]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.66it/s, train_loss=0.0889]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.66it/s, train_loss=0.353] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.81it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.81it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.03it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.03it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.79it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.79it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.73it/s, train_loss=0.397]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.73it/s, train_loss=0.0263]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.80it/s, train_loss=0.0263]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.80it/s, train_loss=0.146] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.99it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.99it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.09it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.09it/s, train_loss=0.0879]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.14it/s, train_loss=0.0879]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.14it/s, train_loss=0.336] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.19it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.19it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:07,  5.46it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:07,  5.46it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.20it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.20it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.42it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.42it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.21it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.21it/s, train_loss=0.0441]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.22it/s, train_loss=0.0441]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.22it/s, train_loss=0.402] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.14it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.14it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.05it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.05it/s, train_loss=0.45] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.87it/s, train_loss=0.45]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.87it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.12it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.12it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.05it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.05it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.89it/s, train_loss=0.434]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.89it/s, train_loss=0.0478]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.03it/s, train_loss=0.0478]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.03it/s, train_loss=0.244] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.16it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.16it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.08it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.08it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.10it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.10it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.01it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.01it/s, train_loss=0.278] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.09it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.09it/s, train_loss=0.0342]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.09it/s, train_loss=0.0342]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.09it/s, train_loss=0.0644]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.03it/s, train_loss=0.0644]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.03it/s, train_loss=0.284] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.15it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.15it/s, train_loss=0.0408]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.01it/s, train_loss=0.0408]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.01it/s, train_loss=0.156] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.15it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.15it/s, train_loss=0.0654]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.05it/s, train_loss=0.0654]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.05it/s, train_loss=0.00622]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.07it/s, train_loss=0.00622]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.07it/s, train_loss=0.127]  \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.21it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.21it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.25it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.25it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.14it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.14it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.25it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.25it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.98it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.98it/s, train_loss=0.0315]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.04it/s, train_loss=0.0315]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.04it/s, train_loss=0.0713]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.96it/s, train_loss=0.0713]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.96it/s, train_loss=0.246] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.03it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.03it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.21it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.21it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.12it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.12it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.06it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.06it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.81it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.81it/s, train_loss=0.0959]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.87it/s, train_loss=0.0959]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.87it/s, train_loss=0.183] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.98it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.98it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.04it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.04it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.98it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.98it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.90it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.90it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.13it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.13it/s, train_loss=0.0482]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66 average loss: 0.1584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 66/110 [27:26<18:08, 24.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 66 current AUC: 0.9960 current accuracy: 0.9565 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 67/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.61it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.61it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.30it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.30it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.96it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.96it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.91it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.91it/s, train_loss=0.1]  \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.81it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.81it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.84it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.84it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.97it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.97it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.98it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.98it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.22it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.22it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.04it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.04it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.20it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.20it/s, train_loss=0.0611]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.19it/s, train_loss=0.0611]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.19it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.25it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.25it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:19,  5.55it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:19,  5.55it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.50it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.50it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.31it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.31it/s, train_loss=0.123] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.21it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.21it/s, train_loss=0.0657]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.15it/s, train_loss=0.0657]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.15it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.96it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.96it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.02it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.02it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.04it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.04it/s, train_loss=0.378] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.38it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.38it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.34it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.34it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.33it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.33it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.14it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.14it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.01it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.01it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.35it/s, train_loss=0.381]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.35it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.26it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.26it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.26it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.26it/s, train_loss=0.833]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:05<00:17,  5.32it/s, train_loss=0.833]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.32it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.02it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.02it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.02it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.02it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.89it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.89it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.92it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.92it/s, train_loss=0.0669]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.77it/s, train_loss=0.0669]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.77it/s, train_loss=0.0063]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.86it/s, train_loss=0.0063]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.86it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.97it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.97it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.93it/s, train_loss=0.319]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.93it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.00it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.00it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.99it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.99it/s, train_loss=0.02] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.97it/s, train_loss=0.02]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.97it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.29it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.29it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.20it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.20it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.02it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.02it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.82it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.82it/s, train_loss=0.172] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.91it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.91it/s, train_loss=0.00352]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.04it/s, train_loss=0.00352]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.04it/s, train_loss=0.407]  \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.12it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.12it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.04it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.04it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.05it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.05it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.98it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.98it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.93it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.93it/s, train_loss=0.116] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.94it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.94it/s, train_loss=0.0547]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.01it/s, train_loss=0.0547]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.01it/s, train_loss=0.817] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.88it/s, train_loss=0.817]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.88it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.92it/s, train_loss=0.519]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.92it/s, train_loss=0.662]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.06it/s, train_loss=0.662]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.06it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.92it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.92it/s, train_loss=0.0975]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.94it/s, train_loss=0.0975]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.94it/s, train_loss=0.245] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.72it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.72it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.67it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.67it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.77it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.77it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.93it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.93it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.83it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.83it/s, train_loss=0.159] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.95it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.95it/s, train_loss=0.0835]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.01it/s, train_loss=0.0835]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.01it/s, train_loss=0.393] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.07it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.07it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.96it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.96it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.25it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.25it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.44it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.44it/s, train_loss=0.00926]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:08,  5.60it/s, train_loss=0.00926]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:08,  5.60it/s, train_loss=0.111]  \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:08,  5.51it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:08,  5.51it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:08,  5.37it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:08,  5.37it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.17it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.17it/s, train_loss=0.058]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.26it/s, train_loss=0.058]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.26it/s, train_loss=0.0303]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.18it/s, train_loss=0.0303]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.18it/s, train_loss=0.258] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.10it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.10it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.05it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.05it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.00it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.00it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.95it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.95it/s, train_loss=0.0555]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.06it/s, train_loss=0.0555]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.06it/s, train_loss=0.103] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.19it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.19it/s, train_loss=0.00639]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.37it/s, train_loss=0.00639]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.37it/s, train_loss=0.246]  \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.29it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.29it/s, train_loss=0.0897]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.10it/s, train_loss=0.0897]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.10it/s, train_loss=0.222] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.15it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.15it/s, train_loss=0.059]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.28it/s, train_loss=0.059]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.28it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.15it/s, train_loss=0.623]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.15it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.14it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.14it/s, train_loss=0.0207]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.15it/s, train_loss=0.0207]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.15it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.96it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.96it/s, train_loss=0.244] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.15it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.15it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.20it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.20it/s, train_loss=0.0726]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.11it/s, train_loss=0.0726]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.11it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.90it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.90it/s, train_loss=0.0695]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.0695]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.125] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.98it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.98it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.07it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.07it/s, train_loss=0.0425]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.12it/s, train_loss=0.0425]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.12it/s, train_loss=0.0779]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.96it/s, train_loss=0.0779]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.96it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.93it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.93it/s, train_loss=0.344] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.99it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.99it/s, train_loss=0.0889]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.89it/s, train_loss=0.0889]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.89it/s, train_loss=0.339] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.84it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.84it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.90it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.90it/s, train_loss=0.0965]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  5.00it/s, train_loss=0.0965]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  5.00it/s, train_loss=0.0526]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.92it/s, train_loss=0.0526]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.92it/s, train_loss=0.191] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.10it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.10it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.93it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.93it/s, train_loss=0.719]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.85it/s, train_loss=0.719]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.85it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.39it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.39it/s, train_loss=0.0647]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.10it/s, train_loss=0.0647]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.10it/s, train_loss=0.157] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.07it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.07it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.86it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.86it/s, train_loss=0.02] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.79it/s, train_loss=0.02]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.79it/s, train_loss=0.0303]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.65it/s, train_loss=0.0303]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.65it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.68it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.68it/s, train_loss=0.119] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.68it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.68it/s, train_loss=0.0827]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67 average loss: 0.1674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  61%|██████    | 67/110 [27:51<17:42, 24.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 67 current AUC: 0.9973 current accuracy: 0.9317 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 68/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.00517]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  5.78it/s, train_loss=0.00517]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  5.78it/s, train_loss=0.0339] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.09it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.09it/s, train_loss=0.167] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.95it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.95it/s, train_loss=0.12] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.06it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.06it/s, train_loss=0.0524]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.02it/s, train_loss=0.0524]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.02it/s, train_loss=0.437] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.91it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.91it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.92it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.92it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.72it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:24,  4.72it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.91it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.91it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.07it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.07it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.99it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.99it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.96it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.96it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.95it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  4.95it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.91it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.91it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.94it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.94it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.10it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.10it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.10it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.10it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.98it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  4.98it/s, train_loss=0.0665]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.85it/s, train_loss=0.0665]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.85it/s, train_loss=0.0356]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.96it/s, train_loss=0.0356]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.96it/s, train_loss=0.133] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.02it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.02it/s, train_loss=0.00893]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.24it/s, train_loss=0.00893]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.24it/s, train_loss=0.0614] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.25it/s, train_loss=0.0614]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.25it/s, train_loss=0.195] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.11it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.11it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.15it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.15it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.10it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.10it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.22it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.22it/s, train_loss=0.00897]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.20it/s, train_loss=0.00897]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.20it/s, train_loss=0.0717] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.29it/s, train_loss=0.0717]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.29it/s, train_loss=0.189] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:16,  5.45it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:16,  5.45it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.03it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.03it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.29it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.29it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.14it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.14it/s, train_loss=0.0964]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.98it/s, train_loss=0.0964]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.98it/s, train_loss=0.231] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.20it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.20it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.13it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.13it/s, train_loss=0.0444]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.98it/s, train_loss=0.0444]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.98it/s, train_loss=0.0746]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.91it/s, train_loss=0.0746]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.91it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.05it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.05it/s, train_loss=0.0657]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.21it/s, train_loss=0.0657]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.21it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.24it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.24it/s, train_loss=0.611] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.33it/s, train_loss=0.611]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.33it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.23it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.23it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.05it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.05it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.99it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.99it/s, train_loss=0.0942]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.96it/s, train_loss=0.0942]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.96it/s, train_loss=0.0344]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.98it/s, train_loss=0.0344]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.98it/s, train_loss=0.0968]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.00it/s, train_loss=0.0968]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.00it/s, train_loss=0.154] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.98it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.98it/s, train_loss=0.0353]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.10it/s, train_loss=0.0353]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.10it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.12it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.12it/s, train_loss=0.0329]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.09it/s, train_loss=0.0329]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.09it/s, train_loss=0.173] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.05it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.05it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.18it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.18it/s, train_loss=0.0353]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.30it/s, train_loss=0.0353]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.30it/s, train_loss=0.0781]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.04it/s, train_loss=0.0781]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.04it/s, train_loss=0.0551]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.08it/s, train_loss=0.0551]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.08it/s, train_loss=0.248] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.91it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.91it/s, train_loss=0.0594]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:13,  4.74it/s, train_loss=0.0594]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:13,  4.74it/s, train_loss=0.723] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.00it/s, train_loss=0.723]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.00it/s, train_loss=0.0181]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.19it/s, train_loss=0.0181]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.19it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.27it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.27it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.30it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.30it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.16it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.16it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.02it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.02it/s, train_loss=0.07]  \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.90it/s, train_loss=0.07]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.90it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.95it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.95it/s, train_loss=0.0452]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.89it/s, train_loss=0.0452]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.89it/s, train_loss=0.0962]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.87it/s, train_loss=0.0962]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.87it/s, train_loss=0.1]   \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.90it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.90it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.81it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.81it/s, train_loss=0.284] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.78it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.78it/s, train_loss=0.0812]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.80it/s, train_loss=0.0812]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.80it/s, train_loss=0.11]  \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.98it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.98it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.89it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.89it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.67it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.67it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.69it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.69it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.74it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.74it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.83it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.83it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.78it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.78it/s, train_loss=0.142] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.80it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.80it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.86it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.86it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.93it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.93it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.04it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.04it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.09it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.09it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.25it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.25it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.07it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.07it/s, train_loss=0.182] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.96it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.96it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.94it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.94it/s, train_loss=0.0872]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.02it/s, train_loss=0.0872]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.02it/s, train_loss=0.0883]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.08it/s, train_loss=0.0883]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.08it/s, train_loss=0.509] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.92it/s, train_loss=0.509]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.92it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.96it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.96it/s, train_loss=0.0706]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.99it/s, train_loss=0.0706]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.99it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.121] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.12it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.12it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.86it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.86it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.97it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.97it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.93it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.93it/s, train_loss=0.0993]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.87it/s, train_loss=0.0993]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.87it/s, train_loss=0.264] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.15it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.15it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.13it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.13it/s, train_loss=0.134] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.06it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.06it/s, train_loss=0.00711]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.07it/s, train_loss=0.00711]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.07it/s, train_loss=0.0501] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.05it/s, train_loss=0.0501]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.05it/s, train_loss=0.348] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.07it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.07it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.14it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.14it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.98it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.98it/s, train_loss=0.0547]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.11it/s, train_loss=0.0547]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.11it/s, train_loss=0.102] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.33it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.33it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.19it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.19it/s, train_loss=0.0991]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.86it/s, train_loss=0.0991]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.86it/s, train_loss=0.183] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.90it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.90it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.89it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.89it/s, train_loss=0.087]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.91it/s, train_loss=0.087]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.91it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.88it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.88it/s, train_loss=0.0855]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.02it/s, train_loss=0.0855]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.02it/s, train_loss=0.114] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.93it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.93it/s, train_loss=0.53] \n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.81it/s, train_loss=0.53]\n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68 average loss: 0.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  62%|██████▏   | 68/110 [28:16<17:19, 24.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 68 current AUC: 0.9938 current accuracy: 0.9255 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 69/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.97it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.97it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.69it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.69it/s, train_loss=0.0975]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.96it/s, train_loss=0.0975]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.96it/s, train_loss=0.121] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.77it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.77it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.94it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.94it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.0513]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.09it/s, train_loss=0.0513]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.09it/s, train_loss=0.109] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.23it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.23it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.11it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  5.11it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.99it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.99it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.09it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.09it/s, train_loss=0.053] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.12it/s, train_loss=0.053]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.12it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.10it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.10it/s, train_loss=0.0641]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=0.0641]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=0.0851]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.01it/s, train_loss=0.0851]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.01it/s, train_loss=0.0609]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.22it/s, train_loss=0.0609]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.22it/s, train_loss=0.00755]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.13it/s, train_loss=0.00755]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.13it/s, train_loss=0.0794] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.08it/s, train_loss=0.0794]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.08it/s, train_loss=0.253] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.94it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.94it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.08it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.08it/s, train_loss=0.38]  \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.88it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.88it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.91it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.91it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.02it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.02it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.99it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.99it/s, train_loss=0.189] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.89it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.89it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.91it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.91it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.92it/s, train_loss=0.196] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.78it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.78it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.95it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.95it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.10it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.10it/s, train_loss=0.652] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.09it/s, train_loss=0.652]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.09it/s, train_loss=0.0999]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.31it/s, train_loss=0.0999]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.31it/s, train_loss=0.102] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.20it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.20it/s, train_loss=0.0311]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.26it/s, train_loss=0.0311]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.26it/s, train_loss=0.0794]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.35it/s, train_loss=0.0794]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.35it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.16it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.16it/s, train_loss=0.539] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.06it/s, train_loss=0.539]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.06it/s, train_loss=0.0681]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.98it/s, train_loss=0.0681]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.98it/s, train_loss=0.216] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.04it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.04it/s, train_loss=0.541]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.17it/s, train_loss=0.541]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.17it/s, train_loss=0.35] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.20it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.20it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.97it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.97it/s, train_loss=0.0537]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.0537]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.104] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.06it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.06it/s, train_loss=0.0611]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.08it/s, train_loss=0.0611]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.08it/s, train_loss=0.0847]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.16it/s, train_loss=0.0847]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.16it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.18it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.18it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.15it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.15it/s, train_loss=0.0881]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.41it/s, train_loss=0.0881]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.41it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:12,  5.71it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:12,  5.71it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:12,  5.52it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:12,  5.52it/s, train_loss=0.196] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.30it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.30it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.26it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.26it/s, train_loss=0.094]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.96it/s, train_loss=0.094]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.96it/s, train_loss=0.0407]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.00it/s, train_loss=0.0407]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.00it/s, train_loss=0.00427]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.89it/s, train_loss=0.00427]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.89it/s, train_loss=0.0611] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.93it/s, train_loss=0.0611]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.93it/s, train_loss=0.326] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.94it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.94it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.05it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.05it/s, train_loss=0.0603]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.21it/s, train_loss=0.0603]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.21it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.22it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.22it/s, train_loss=0.0502]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.14it/s, train_loss=0.0502]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.14it/s, train_loss=0.083] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.25it/s, train_loss=0.083]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.25it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.09it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.09it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  5.06it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.06it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.12it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.12it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.14it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.14it/s, train_loss=0.0384]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:09,  5.38it/s, train_loss=0.0384]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:09,  5.38it/s, train_loss=0.202] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.09it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.09it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  5.06it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.06it/s, train_loss=0.339] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.08it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.08it/s, train_loss=0.0225]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.02it/s, train_loss=0.0225]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.02it/s, train_loss=0.12]  \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.84it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.84it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.95it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.95it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  4.86it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.86it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.20it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.20it/s, train_loss=0.334] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.35it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.35it/s, train_loss=0.0813]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:07,  5.50it/s, train_loss=0.0813]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:07,  5.50it/s, train_loss=0.262] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.22it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.22it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.11it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.11it/s, train_loss=0.17] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.91it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.91it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.20it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.20it/s, train_loss=0.222] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.25it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.25it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.83it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.83it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  4.87it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.87it/s, train_loss=0.51] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.79it/s, train_loss=0.51]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.79it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.71it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.71it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.72it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.72it/s, train_loss=0.0256]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.83it/s, train_loss=0.0256]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.83it/s, train_loss=0.449] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.88it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.88it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.90it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.90it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.95it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.95it/s, train_loss=0.167] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.02it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.22it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.22it/s, train_loss=0.0719]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.35it/s, train_loss=0.0719]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.35it/s, train_loss=0.0419]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.34it/s, train_loss=0.0419]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.34it/s, train_loss=0.00486]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.22it/s, train_loss=0.00486]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.22it/s, train_loss=0.399]  \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.06it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.06it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.87it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.87it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.10it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.10it/s, train_loss=0.742]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.26it/s, train_loss=0.742]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.26it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.28it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.28it/s, train_loss=0.045]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.24it/s, train_loss=0.045]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.24it/s, train_loss=0.03] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.15it/s, train_loss=0.03]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.15it/s, train_loss=0.0906]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.07it/s, train_loss=0.0906]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.07it/s, train_loss=0.182] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.05it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.05it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.02it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.02it/s, train_loss=0.0981]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.26it/s, train_loss=0.0981]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.26it/s, train_loss=0.188] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.16it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.16it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.33it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.33it/s, train_loss=0.0782]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.03it/s, train_loss=0.0782]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.03it/s, train_loss=0.0706]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.17it/s, train_loss=0.0706]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.17it/s, train_loss=0.224] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.23it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.23it/s, train_loss=0.00968]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.01it/s, train_loss=0.00968]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.01it/s, train_loss=0.0784] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.25it/s, train_loss=0.0784]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.25it/s, train_loss=0.0498]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.0498]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.405] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.85it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.85it/s, train_loss=0.0755]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.79it/s, train_loss=0.0755]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.79it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.85it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.85it/s, train_loss=0.18]  \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.01it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.01it/s, train_loss=1.47]\n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69 average loss: 0.1635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  63%|██████▎   | 69/110 [28:40<16:52, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 69 current AUC: 0.9867 current accuracy: 0.8571 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 70/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  5.82it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  5.82it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.20it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.20it/s, train_loss=0.0592]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.76it/s, train_loss=0.0592]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.76it/s, train_loss=0.0671]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.75it/s, train_loss=0.0671]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.75it/s, train_loss=0.186] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.03it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.03it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.84it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.84it/s, train_loss=0.314] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.98it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.98it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.17it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.17it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.21it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.21it/s, train_loss=0.0376]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.17it/s, train_loss=0.0376]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.17it/s, train_loss=0.032] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.37it/s, train_loss=0.032]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.37it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.30it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.30it/s, train_loss=0.02]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.97it/s, train_loss=0.02]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.97it/s, train_loss=0.0356]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.04it/s, train_loss=0.0356]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.04it/s, train_loss=0.0838]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.01it/s, train_loss=0.0838]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.01it/s, train_loss=0.073] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.95it/s, train_loss=0.073]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.95it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.92it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.92it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.05it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.05it/s, train_loss=0.0403]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.01it/s, train_loss=0.0403]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.01it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.89it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.89it/s, train_loss=0.216] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.90it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.90it/s, train_loss=0.0768]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.97it/s, train_loss=0.0768]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.97it/s, train_loss=0.585] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.85it/s, train_loss=0.585]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.85it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.03it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.03it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.88it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.88it/s, train_loss=0.068]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.93it/s, train_loss=0.068]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.93it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.96it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.96it/s, train_loss=0.53] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.09it/s, train_loss=0.53]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.09it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.13it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.13it/s, train_loss=0.0254]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.08it/s, train_loss=0.0254]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.08it/s, train_loss=0.0149]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.86it/s, train_loss=0.0149]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.86it/s, train_loss=0.172] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.17it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.17it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.08it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.08it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.83it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.83it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.92it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.92it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.99it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.99it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.92it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.92it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.01it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.01it/s, train_loss=0.0996]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.98it/s, train_loss=0.0996]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.98it/s, train_loss=0.301] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.15it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.15it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.20it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.20it/s, train_loss=0.0558]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.26it/s, train_loss=0.0558]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.26it/s, train_loss=0.119] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.38it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.38it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.33it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.33it/s, train_loss=0.0444]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.22it/s, train_loss=0.0444]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.22it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.08it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.08it/s, train_loss=0.18]  \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.94it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.94it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.95it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.95it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.03it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.03it/s, train_loss=0.00851]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.08it/s, train_loss=0.00851]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.08it/s, train_loss=0.24]   \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.29it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.29it/s, train_loss=0.0531]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.18it/s, train_loss=0.0531]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.18it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.26it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.26it/s, train_loss=0.116] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.08it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.08it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.06it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.06it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.92it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.92it/s, train_loss=0.0941]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.86it/s, train_loss=0.0941]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.86it/s, train_loss=0.0784]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.89it/s, train_loss=0.0784]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.89it/s, train_loss=0.0577]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.01it/s, train_loss=0.0577]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.01it/s, train_loss=0.158] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.05it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.05it/s, train_loss=0.53] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.15it/s, train_loss=0.53]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.15it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.24it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.24it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.28it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.28it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.22it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.22it/s, train_loss=0.038]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.97it/s, train_loss=0.038]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.97it/s, train_loss=0.0694]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.23it/s, train_loss=0.0694]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.23it/s, train_loss=0.166] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.04it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.04it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.30it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.30it/s, train_loss=0.114] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:09,  5.46it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:09,  5.46it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.15it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.15it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.29it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.29it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.14it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.14it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.11it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.11it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.01it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.01it/s, train_loss=0.043]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.99it/s, train_loss=0.043]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.99it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.94it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.94it/s, train_loss=0.109] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.01it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.01it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.17it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.17it/s, train_loss=0.0366]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.13it/s, train_loss=0.0366]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.13it/s, train_loss=0.132] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.29it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.29it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.11it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.11it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.06it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.06it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.88it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.88it/s, train_loss=0.201] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.93it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.93it/s, train_loss=0.0556]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.88it/s, train_loss=0.0556]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.88it/s, train_loss=0.248] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.91it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.91it/s, train_loss=0.0402]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.92it/s, train_loss=0.0402]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.92it/s, train_loss=0.239] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.00it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.00it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.13it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.13it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.08it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.08it/s, train_loss=0.177] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.91it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.91it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.0382]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.87it/s, train_loss=0.0382]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.87it/s, train_loss=0.3]   \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.97it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.97it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.02it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.02it/s, train_loss=0.116] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.0762]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.91it/s, train_loss=0.0762]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.91it/s, train_loss=0.309] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.03it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.03it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.93it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.93it/s, train_loss=0.0892]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.06it/s, train_loss=0.0892]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.06it/s, train_loss=0.0864]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.00it/s, train_loss=0.0864]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.00it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.91it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.91it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.93it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.93it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.93it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.93it/s, train_loss=0.0329]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.99it/s, train_loss=0.0329]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.99it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.75it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.75it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.94it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.94it/s, train_loss=0.0996]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.97it/s, train_loss=0.0996]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.97it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.00it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.00it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.90it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.90it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.86it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.86it/s, train_loss=0.0451]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.02it/s, train_loss=0.0451]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.02it/s, train_loss=0.354] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.98it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.98it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.93it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.93it/s, train_loss=0.00701]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.02it/s, train_loss=0.00701]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.02it/s, train_loss=0.216]  \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.34it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.34it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.13it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.13it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.02it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.02it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.18it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.18it/s, train_loss=0.522]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70 average loss: 0.1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  64%|██████▎   | 70/110 [29:05<16:27, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 70 current AUC: 0.9974 current accuracy: 0.9255 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 71/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0199]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.87it/s, train_loss=0.0199]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.87it/s, train_loss=0.077] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.80it/s, train_loss=0.077]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.80it/s, train_loss=0.0607]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.19it/s, train_loss=0.0607]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.19it/s, train_loss=0.167] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.08it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.08it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.11it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.11it/s, train_loss=0.341] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.18] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.95it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.95it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.90it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.90it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.88it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.88it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.99it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.99it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.13it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.13it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.18it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.18it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.17it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.17it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.11it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.11it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  4.94it/s, train_loss=0.603]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.94it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.76it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.76it/s, train_loss=0.0459]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.88it/s, train_loss=0.0459]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.88it/s, train_loss=0.0756]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.95it/s, train_loss=0.0756]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.95it/s, train_loss=0.0334]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.94it/s, train_loss=0.0334]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  4.94it/s, train_loss=0.351] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.84it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.84it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.87it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.87it/s, train_loss=0.016] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.0358]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.04it/s, train_loss=0.0358]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.04it/s, train_loss=0.109] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.04it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:19,  5.04it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.89it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.89it/s, train_loss=0.77] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.07it/s, train_loss=0.77]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.07it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.00it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  5.00it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.97it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.97it/s, train_loss=0.0583]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.92it/s, train_loss=0.0583]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.92it/s, train_loss=0.0441]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.87it/s, train_loss=0.0441]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.87it/s, train_loss=0.0992]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.92it/s, train_loss=0.0992]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.92it/s, train_loss=0.0999]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.97it/s, train_loss=0.0999]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  4.97it/s, train_loss=0.286] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.87it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.87it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.87it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.87it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.04it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.04it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.18it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.18it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.09it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.09it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.27it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.27it/s, train_loss=0.124] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.32it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.32it/s, train_loss=0.072]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.18it/s, train_loss=0.072]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.18it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.15it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.15it/s, train_loss=0.208] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.87it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.87it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.97it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.97it/s, train_loss=0.307] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.21it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.21it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.11it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.11it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.13it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.13it/s, train_loss=0.0977]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.86it/s, train_loss=0.0977]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:15,  4.86it/s, train_loss=0.307] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.78it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.78it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.87it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.87it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.92it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.92it/s, train_loss=0.0927]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.09it/s, train_loss=0.0927]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.09it/s, train_loss=0.18]  \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.22it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.22it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.42it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.42it/s, train_loss=0.054]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.13it/s, train_loss=0.054]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.13it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.27it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.27it/s, train_loss=0.468]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.33it/s, train_loss=0.468]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.33it/s, train_loss=0.0509]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.31it/s, train_loss=0.0509]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.31it/s, train_loss=0.0741]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.49it/s, train_loss=0.0741]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.49it/s, train_loss=0.181] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.34it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.34it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.30it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.30it/s, train_loss=0.029] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.49it/s, train_loss=0.029]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.49it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.56it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.56it/s, train_loss=0.0819]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:09,  5.76it/s, train_loss=0.0819]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:09,  5.76it/s, train_loss=0.26]  \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.32it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.32it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  5.00it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  5.00it/s, train_loss=0.0604]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.31it/s, train_loss=0.0604]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.31it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.15it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.15it/s, train_loss=0.454] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.15it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.15it/s, train_loss=0.0689]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.20it/s, train_loss=0.0689]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.20it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.15it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.15it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.29it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.29it/s, train_loss=0.234] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.19it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.19it/s, train_loss=0.0687]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.97it/s, train_loss=0.0687]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.97it/s, train_loss=0.0332]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  4.92it/s, train_loss=0.0332]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.92it/s, train_loss=0.0429]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.88it/s, train_loss=0.0429]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.88it/s, train_loss=0.0863]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.84it/s, train_loss=0.0863]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.84it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.75it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.75it/s, train_loss=0.197] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.94it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.94it/s, train_loss=0.0071]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.94it/s, train_loss=0.0071]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.94it/s, train_loss=0.377] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.09it/s, train_loss=0.377]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.09it/s, train_loss=0.0461]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.26it/s, train_loss=0.0461]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.26it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.38it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.38it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.49it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.49it/s, train_loss=0.0392]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.19it/s, train_loss=0.0392]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.19it/s, train_loss=0.119] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.26it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.26it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.36it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.36it/s, train_loss=0.292] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.45it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.45it/s, train_loss=0.17] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.11it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.11it/s, train_loss=0.03]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.10it/s, train_loss=0.03]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.10it/s, train_loss=0.00692]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.18it/s, train_loss=0.00692]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.18it/s, train_loss=0.0119] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.19it/s, train_loss=0.0119]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.19it/s, train_loss=0.395] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.11it/s, train_loss=0.395]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.11it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.04it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.04it/s, train_loss=0.0752]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.05it/s, train_loss=0.0752]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.05it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.90it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.90it/s, train_loss=0.102] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.98it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.98it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.84it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.84it/s, train_loss=0.0821]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.88it/s, train_loss=0.0821]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.88it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.98it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.98it/s, train_loss=0.144] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.18it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.18it/s, train_loss=0.00748]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.35it/s, train_loss=0.00748]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.35it/s, train_loss=0.0278] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.22it/s, train_loss=0.0278]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.22it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.03it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.03it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.94it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.94it/s, train_loss=0.0154]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.00it/s, train_loss=0.0154]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.00it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.82it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.82it/s, train_loss=0.0347]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.92it/s, train_loss=0.0347]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.92it/s, train_loss=0.0346]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.95it/s, train_loss=0.0346]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.95it/s, train_loss=0.213] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.85it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.85it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.14it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.14it/s, train_loss=0.156] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.93it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.93it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.95it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.95it/s, train_loss=0.544]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.95it/s, train_loss=0.544]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.95it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.91it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.91it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.24it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.24it/s, train_loss=0.0448]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.21it/s, train_loss=0.0448]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.21it/s, train_loss=0.0447]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.18it/s, train_loss=0.0447]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.18it/s, train_loss=0.107] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.12it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.12it/s, train_loss=0.0762]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:23<00:00,  5.97it/s, train_loss=0.0762]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71 average loss: 0.1372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  65%|██████▍   | 71/110 [29:29<16:01, 24.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 71 current AUC: 0.9965 current accuracy: 0.8882 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 72/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  5.01it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  5.01it/s, train_loss=0.0834]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.87it/s, train_loss=0.0834]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.87it/s, train_loss=0.2]   \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.02it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.02it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.12it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  5.12it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.93it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.93it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.12it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.12it/s, train_loss=0.0502]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.97it/s, train_loss=0.0502]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.97it/s, train_loss=0.186] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.16it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.16it/s, train_loss=0.0318]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.18it/s, train_loss=0.0318]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.18it/s, train_loss=0.125] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.07it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.07it/s, train_loss=0.0605]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.00it/s, train_loss=0.0605]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.00it/s, train_loss=0.104] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.09it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.09it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.10it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.10it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.03it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.03it/s, train_loss=0.0977]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  4.88it/s, train_loss=0.0977]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.88it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.97it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.97it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.82it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.82it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.81it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.81it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.03it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.03it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.17it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.17it/s, train_loss=0.00968]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.13it/s, train_loss=0.00968]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.13it/s, train_loss=0.335]  \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.06it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.06it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.06it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.06it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.12it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.12it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.06it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.06it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.86it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.86it/s, train_loss=0.0378]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.95it/s, train_loss=0.0378]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.95it/s, train_loss=0.0538]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.83it/s, train_loss=0.0538]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.83it/s, train_loss=0.0468]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.12it/s, train_loss=0.0468]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.12it/s, train_loss=0.267] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.12it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.12it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.11it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.11it/s, train_loss=0.0283]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.97it/s, train_loss=0.0283]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.97it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.83it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.83it/s, train_loss=0.0893]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.93it/s, train_loss=0.0893]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.93it/s, train_loss=0.0759]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.12it/s, train_loss=0.0759]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.12it/s, train_loss=0.0402]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.07it/s, train_loss=0.0402]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.07it/s, train_loss=0.174] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=0.0399]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.93it/s, train_loss=0.0399]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.93it/s, train_loss=0.0574]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.0574]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.18]  \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.19it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.19it/s, train_loss=0.0679]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.19it/s, train_loss=0.0679]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.19it/s, train_loss=0.102] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.87it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.87it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.04it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.04it/s, train_loss=0.858] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.22it/s, train_loss=0.858]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.22it/s, train_loss=0.0091]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.25it/s, train_loss=0.0091]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.25it/s, train_loss=0.0516]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.20it/s, train_loss=0.0516]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.20it/s, train_loss=0.107] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.19it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.19it/s, train_loss=0.0533]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.21it/s, train_loss=0.0533]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.21it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.24it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.24it/s, train_loss=0.0722]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.13it/s, train_loss=0.0722]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.13it/s, train_loss=0.109] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.30it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.30it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.29it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.29it/s, train_loss=0.104] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.38it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.38it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.22it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.22it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.13it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.13it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.13it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.13it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.20it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.20it/s, train_loss=0.0493]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.0493]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.25it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.25it/s, train_loss=0.0834]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.21it/s, train_loss=0.0834]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.21it/s, train_loss=0.217] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.14it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.14it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.18it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.18it/s, train_loss=0.2]  \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.05it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.05it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.10it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.10it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.04it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.04it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.00it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.00it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.84it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.84it/s, train_loss=0.244] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.86it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.86it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.89it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.89it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:11,  4.71it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:11,  4.71it/s, train_loss=0.0702]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.92it/s, train_loss=0.0702]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.92it/s, train_loss=0.123] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.94it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.94it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.20it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.20it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.04it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.04it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.05it/s, train_loss=0.364]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.05it/s, train_loss=0.12] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.08it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.08it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.20it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.20it/s, train_loss=0.784] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.99it/s, train_loss=0.784]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.99it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.08it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.08it/s, train_loss=0.0321]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.23it/s, train_loss=0.0321]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.23it/s, train_loss=0.163] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.06it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.06it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  5.00it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  5.00it/s, train_loss=0.0804]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.78it/s, train_loss=0.0804]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.78it/s, train_loss=0.249] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.89it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.89it/s, train_loss=0.0116]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.87it/s, train_loss=0.0116]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.87it/s, train_loss=0.0739]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.99it/s, train_loss=0.0739]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.99it/s, train_loss=0.0632]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.15it/s, train_loss=0.0632]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.15it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.24it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.24it/s, train_loss=0.0116]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.30it/s, train_loss=0.0116]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.30it/s, train_loss=0.107] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.06it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.06it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.09it/s, train_loss=0.533]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.09it/s, train_loss=0.0738]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.23it/s, train_loss=0.0738]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.23it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.98it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.98it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.94it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.94it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.11it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.11it/s, train_loss=0.12]  \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.97it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.97it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.91it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.91it/s, train_loss=0.0793]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.79it/s, train_loss=0.0793]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.79it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.08it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.08it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.97it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.97it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.31it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.31it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.30it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.30it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.24it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.24it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.20it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.20it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.89it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.89it/s, train_loss=0.0735]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.78it/s, train_loss=0.0735]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.78it/s, train_loss=0.219] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.93it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.93it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.03it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.03it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.23it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.23it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.13it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.13it/s, train_loss=0.253] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.06it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.06it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.17it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.17it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.22it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.22it/s, train_loss=0.0789]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.18it/s, train_loss=0.0789]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.18it/s, train_loss=0.42]  \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.83it/s, train_loss=0.42]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.83it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.94it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.94it/s, train_loss=0.169] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.08it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.08it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.94it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.94it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.08it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.08it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.00it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.00it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.18it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.18it/s, train_loss=0.063] \n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72 average loss: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  65%|██████▌   | 72/110 [29:54<15:36, 24.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 72 current AUC: 0.9967 current accuracy: 0.8944 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 73/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0614]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.51it/s, train_loss=0.0614]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.51it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.63it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.63it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.08it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.08it/s, train_loss=0.0334]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.92it/s, train_loss=0.0334]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.92it/s, train_loss=0.00586]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.11it/s, train_loss=0.00586]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.11it/s, train_loss=0.0915] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.0915]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.124] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.99it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.99it/s, train_loss=0.0719]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.23it/s, train_loss=0.0719]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.23it/s, train_loss=0.327] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.13it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.13it/s, train_loss=0.0343]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.24it/s, train_loss=0.0343]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.24it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.14it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.14it/s, train_loss=0.169] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.79it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.79it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.88it/s, train_loss=0.279]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.88it/s, train_loss=0.0994]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.03it/s, train_loss=0.0994]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.03it/s, train_loss=0.00365]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.24it/s, train_loss=0.00365]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.24it/s, train_loss=0.0575] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.44it/s, train_loss=0.0575]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.44it/s, train_loss=0.125] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.30it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.30it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.36it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.36it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.17it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.17it/s, train_loss=0.35] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.04it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.04it/s, train_loss=0.0742]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.93it/s, train_loss=0.0742]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.93it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.19it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.19it/s, train_loss=0.398] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.26it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.26it/s, train_loss=0.0988]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.12it/s, train_loss=0.0988]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.12it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.08it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.08it/s, train_loss=0.108] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.92it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.92it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.80it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.80it/s, train_loss=0.0124]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.76it/s, train_loss=0.0124]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.76it/s, train_loss=0.275] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.68it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.68it/s, train_loss=0.0279]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:19,  4.61it/s, train_loss=0.0279]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:19,  4.61it/s, train_loss=0.207] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.88it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.88it/s, train_loss=0.1]  \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.06it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.06it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.99it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.99it/s, train_loss=0.162] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.19it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.19it/s, train_loss=0.0139]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.31it/s, train_loss=0.0139]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.31it/s, train_loss=0.494] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.31it/s, train_loss=0.494]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.31it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.17it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.17it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.15it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.15it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.27]  \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.22it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.22it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.92it/s, train_loss=0.288]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.92it/s, train_loss=0.0678]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.93it/s, train_loss=0.0678]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.93it/s, train_loss=0.0466]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.93it/s, train_loss=0.0466]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.93it/s, train_loss=0.418] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.83it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.83it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:16,  4.76it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.76it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.82it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.82it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.84it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.84it/s, train_loss=0.0831]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.96it/s, train_loss=0.0831]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.96it/s, train_loss=0.229] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.98it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.98it/s, train_loss=0.0664]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.99it/s, train_loss=0.0664]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.99it/s, train_loss=0.11]  \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.77it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.77it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.06it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.06it/s, train_loss=0.112] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.06it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.06it/s, train_loss=0.0477]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.01it/s, train_loss=0.0477]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.01it/s, train_loss=0.0627]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.95it/s, train_loss=0.0627]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.95it/s, train_loss=0.46]  \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.06it/s, train_loss=0.46]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.06it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.09it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.09it/s, train_loss=0.0963]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.88it/s, train_loss=0.0963]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.88it/s, train_loss=0.374] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.01it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.01it/s, train_loss=0.0704]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.20it/s, train_loss=0.0704]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.20it/s, train_loss=0.0522]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.30it/s, train_loss=0.0522]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.30it/s, train_loss=0.0969]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.15it/s, train_loss=0.0969]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.15it/s, train_loss=0.432] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.24it/s, train_loss=0.432]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.24it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.12it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.12it/s, train_loss=0.145] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.85it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.85it/s, train_loss=0.057]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.78it/s, train_loss=0.057]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.78it/s, train_loss=0.0835]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.90it/s, train_loss=0.0835]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.90it/s, train_loss=0.112] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.00it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.00it/s, train_loss=0.038]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.89it/s, train_loss=0.038]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.89it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:11,  4.68it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:11,  4.68it/s, train_loss=0.2]  \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.75it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.75it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.95it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.95it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.03it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.03it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.13it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.13it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.08it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.08it/s, train_loss=0.137] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.93it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.93it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.84it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.84it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.90it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.90it/s, train_loss=0.153] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.03it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.03it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.18it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.18it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.11it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.11it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.93it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.93it/s, train_loss=0.0305]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.0305]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.0576]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.06it/s, train_loss=0.0576]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.06it/s, train_loss=0.0823]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.97it/s, train_loss=0.0823]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.97it/s, train_loss=0.391] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.85it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.85it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.08it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.08it/s, train_loss=0.0828]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.34it/s, train_loss=0.0828]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.34it/s, train_loss=0.0747]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.23it/s, train_loss=0.0747]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.23it/s, train_loss=0.5]   \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.39it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:05,  5.39it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.40it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.40it/s, train_loss=0.44] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.33it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.33it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.07it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.07it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.03it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.03it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.03it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.03it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.15it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.15it/s, train_loss=0.0395]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.07it/s, train_loss=0.0395]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.07it/s, train_loss=0.117] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.11it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.11it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.86it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.86it/s, train_loss=0.0134]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.89it/s, train_loss=0.0134]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.89it/s, train_loss=0.173] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.15it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.15it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.02it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.02it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.10it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.10it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.19it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.19it/s, train_loss=0.0188]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.02it/s, train_loss=0.0188]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.02it/s, train_loss=0.153] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.94it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.94it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.01it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.01it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.12it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.12it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.27it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.27it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.37it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.37it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.29it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.29it/s, train_loss=0.15]  \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.21it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.21it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.16it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.16it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.07it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.07it/s, train_loss=0.0193]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.93it/s, train_loss=0.0193]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.93it/s, train_loss=0.0877]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.80it/s, train_loss=0.0877]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.80it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.86it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.86it/s, train_loss=0.0064]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.95it/s, train_loss=0.0064]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.95it/s, train_loss=0.216] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.33it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.33it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.07it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.07it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.02it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.02it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.89it/s, train_loss=0.134]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73 average loss: 0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  66%|██████▋   | 73/110 [30:19<15:12, 24.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 73 current AUC: 0.9937 current accuracy: 0.8944 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 74/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.80it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.80it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.688]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.07it/s, train_loss=0.688]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.07it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.21it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.21it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.04it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.04it/s, train_loss=0.0867]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.85it/s, train_loss=0.0867]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.85it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.90it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.90it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.15it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.15it/s, train_loss=0.0669]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.0669]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.087] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  4.98it/s, train_loss=0.087]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.98it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.94it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.94it/s, train_loss=0.0383]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.89it/s, train_loss=0.0383]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.89it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.98it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.98it/s, train_loss=0.0625]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.08it/s, train_loss=0.0625]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.08it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.08it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.08it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.05it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.05it/s, train_loss=0.132] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.19it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.19it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.20it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.20it/s, train_loss=0.0663]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.0663]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.108] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.14it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.14it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.02it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.02it/s, train_loss=0.021] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.15it/s, train_loss=0.021]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.15it/s, train_loss=0.0869]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.15it/s, train_loss=0.0869]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.15it/s, train_loss=0.146] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.19it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.19it/s, train_loss=0.0608]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.17it/s, train_loss=0.0608]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.17it/s, train_loss=0.178] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.13it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.13it/s, train_loss=0.0491]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.94it/s, train_loss=0.0491]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.94it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.86it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.86it/s, train_loss=0.0425]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.12it/s, train_loss=0.0425]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.12it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.98it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.98it/s, train_loss=0.193] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.10it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.10it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.09it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.09it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.08it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.08it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.00it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.00it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.00it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.00it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.97it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.97it/s, train_loss=0.19]  \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.11it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.11it/s, train_loss=0.00573]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.06it/s, train_loss=0.00573]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.06it/s, train_loss=0.0848] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.07it/s, train_loss=0.0848]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.07it/s, train_loss=0.00346]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.90it/s, train_loss=0.00346]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.90it/s, train_loss=0.154]  \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.83it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.83it/s, train_loss=0.0557]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.87it/s, train_loss=0.0557]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.87it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.89it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.89it/s, train_loss=0.0154]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.91it/s, train_loss=0.0154]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.91it/s, train_loss=0.0796]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.15it/s, train_loss=0.0796]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.15it/s, train_loss=0.31]  \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.86it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.86it/s, train_loss=0.01]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.92it/s, train_loss=0.01]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.92it/s, train_loss=0.0262]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.84it/s, train_loss=0.0262]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.84it/s, train_loss=0.189] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.81it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.81it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.88it/s, train_loss=0.407]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.88it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.03it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.03it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.85it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.85it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.10it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.10it/s, train_loss=0.604] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.05it/s, train_loss=0.604]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.05it/s, train_loss=0.0794]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.16it/s, train_loss=0.0794]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.16it/s, train_loss=0.231] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.17it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.17it/s, train_loss=0.0378]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.35it/s, train_loss=0.0378]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.35it/s, train_loss=0.0996]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.28it/s, train_loss=0.0996]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.28it/s, train_loss=0.195] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.47it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.47it/s, train_loss=0.0627]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.58it/s, train_loss=0.0627]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.58it/s, train_loss=0.0774]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:10,  5.64it/s, train_loss=0.0774]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:10,  5.64it/s, train_loss=0.264] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.17it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.17it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.94it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.94it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.89it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.89it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.95it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.95it/s, train_loss=0.182] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.07it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.07it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.05it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.05it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.79it/s, train_loss=0.363]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.79it/s, train_loss=0.0993]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.83it/s, train_loss=0.0993]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.83it/s, train_loss=0.188] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.79it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.79it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.76it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.76it/s, train_loss=0.00492]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.56it/s, train_loss=0.00492]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.56it/s, train_loss=0.0982] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.57it/s, train_loss=0.0982]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.57it/s, train_loss=0.0578]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.75it/s, train_loss=0.0578]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.75it/s, train_loss=0.222] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.73it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.73it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.85it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.85it/s, train_loss=0.153] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.0595]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.93it/s, train_loss=0.0595]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.93it/s, train_loss=0.0777]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.09it/s, train_loss=0.0777]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.09it/s, train_loss=0.182] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.02it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.02it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.15it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.15it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.00it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.00it/s, train_loss=0.24] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.12it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.12it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.13it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.13it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.02it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.02it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.95it/s, train_loss=0.642]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.95it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.99it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.99it/s, train_loss=0.0247]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.0247]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.03it/s, train_loss=0.019] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.32it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.32it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.44it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.44it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.22it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.22it/s, train_loss=0.0559]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.92it/s, train_loss=0.0559]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.92it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.88it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.88it/s, train_loss=0.214] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.90it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.90it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.81it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.81it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.90it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.90it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.97it/s, train_loss=0.328]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.97it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.04it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.04it/s, train_loss=0.213] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.99it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.99it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.03it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.03it/s, train_loss=0.193] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.24it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.24it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.10it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.10it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.06it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.06it/s, train_loss=0.211] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.82it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.82it/s, train_loss=0.0891]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.91it/s, train_loss=0.0891]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.91it/s, train_loss=0.254] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.71it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.71it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.96it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.96it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.11it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.11it/s, train_loss=0.345] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.03it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.03it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.88it/s, train_loss=0.565]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.88it/s, train_loss=0.0787]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.00it/s, train_loss=0.0787]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.00it/s, train_loss=0.24]  \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.01it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.01it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.92it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.92it/s, train_loss=0.0289]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.90it/s, train_loss=0.0289]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.90it/s, train_loss=0.127] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.86it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.86it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.75it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.75it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.92it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.92it/s, train_loss=0.0287]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.09it/s, train_loss=0.0287]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.09it/s, train_loss=0.223] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.06it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.06it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.33it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.33it/s, train_loss=0.102] \n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74 average loss: 0.1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  67%|██████▋   | 74/110 [30:43<14:49, 24.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 74 current AUC: 0.9926 current accuracy: 0.9130 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 75/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.00807]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.17it/s, train_loss=0.00807]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.17it/s, train_loss=0.132]  \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.10it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.10it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.12it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.12it/s, train_loss=0.235] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.95it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.95it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.15it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.15it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.88it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.88it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.83it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.83it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.80it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.80it/s, train_loss=0.0846]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.86it/s, train_loss=0.0846]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.86it/s, train_loss=0.202] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.97it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.97it/s, train_loss=0.0946]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.97it/s, train_loss=0.0946]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.97it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.07it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.07it/s, train_loss=0.144] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.06it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.06it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.12it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.12it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.09it/s, train_loss=0.271]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.09it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.94it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.94it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.83it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.83it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.89it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.89it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.83it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:21,  4.83it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.77it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.77it/s, train_loss=0.022] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.76it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.76it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.84it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.84it/s, train_loss=0.0608]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.98it/s, train_loss=0.0608]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.98it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.95it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:19,  4.95it/s, train_loss=0.345] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.06it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.06it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.16it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.16it/s, train_loss=0.0415]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.09it/s, train_loss=0.0415]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.09it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.01it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.01it/s, train_loss=0.0147]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.22it/s, train_loss=0.0147]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:17,  5.22it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.18it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.18it/s, train_loss=0.0533]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.27it/s, train_loss=0.0533]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.27it/s, train_loss=0.00824]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.98it/s, train_loss=0.00824]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.98it/s, train_loss=0.0121] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.13it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.13it/s, train_loss=0.0795]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.05it/s, train_loss=0.0795]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.05it/s, train_loss=0.196] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.35it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.35it/s, train_loss=0.0757]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.14it/s, train_loss=0.0757]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.14it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.55it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.55it/s, train_loss=0.139] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.41it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.41it/s, train_loss=0.0425]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.10it/s, train_loss=0.0425]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.10it/s, train_loss=0.181] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.90it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.90it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.89it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.89it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.08it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.08it/s, train_loss=0.0589]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.88it/s, train_loss=0.0589]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.88it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.12it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.12it/s, train_loss=0.162] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.93it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.93it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:16,  4.70it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:16,  4.70it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.90it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.90it/s, train_loss=0.0154]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.04it/s, train_loss=0.0154]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.04it/s, train_loss=0.246] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.83it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.83it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.88it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.88it/s, train_loss=0.034] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.75it/s, train_loss=0.034]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.75it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.77it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.77it/s, train_loss=0.0705]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.80it/s, train_loss=0.0705]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.80it/s, train_loss=0.202] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.98it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.98it/s, train_loss=0.00478]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.15it/s, train_loss=0.00478]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.15it/s, train_loss=0.0659] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.07it/s, train_loss=0.0659]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.07it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.04it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.04it/s, train_loss=0.233] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.12it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.12it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.06it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  5.06it/s, train_loss=0.0206]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.97it/s, train_loss=0.0206]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.97it/s, train_loss=0.149] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.79it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.79it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.85it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.85it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.05it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  5.05it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.87it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.87it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.05it/s, train_loss=0.454]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.05it/s, train_loss=0.605]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.05it/s, train_loss=0.605]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.05it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.90it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.90it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.79it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:11,  4.79it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.09it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.09it/s, train_loss=0.188] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.26it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.26it/s, train_loss=0.0658]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.45it/s, train_loss=0.0658]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.45it/s, train_loss=0.027] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.09it/s, train_loss=0.027]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.09it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.07it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.07it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.10it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.10it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.04it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.04it/s, train_loss=0.00724]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.23it/s, train_loss=0.00724]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.23it/s, train_loss=0.957]  \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.15it/s, train_loss=0.957]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.15it/s, train_loss=0.0699]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.18it/s, train_loss=0.0699]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.18it/s, train_loss=0.349] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.11it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.11it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.13it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.13it/s, train_loss=0.492] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.13it/s, train_loss=0.492]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.13it/s, train_loss=0.0329]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.05it/s, train_loss=0.0329]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.05it/s, train_loss=0.156] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.91it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.91it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.15it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.15it/s, train_loss=0.185] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.01it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.01it/s, train_loss=0.614]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.22it/s, train_loss=0.614]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.22it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.08it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.08it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.08it/s, train_loss=0.382]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.08it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.07it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.07it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.17it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.17it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.17it/s, train_loss=0.315]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.17it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.38it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.38it/s, train_loss=0.048]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.37it/s, train_loss=0.048]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.37it/s, train_loss=0.0867]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.23it/s, train_loss=0.0867]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.23it/s, train_loss=0.0595]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.0595]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.218] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.0226]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.76it/s, train_loss=0.0226]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.76it/s, train_loss=0.0421]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.72it/s, train_loss=0.0421]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.72it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.00it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.00it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.95it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.89it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.89it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.88it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.88it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.85it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.85it/s, train_loss=0.0822]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.01it/s, train_loss=0.0822]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.01it/s, train_loss=0.118] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.16it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.16it/s, train_loss=0.0471]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.88it/s, train_loss=0.0471]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.88it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.97it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.97it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.98it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.98it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.85it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.85it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.81it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.81it/s, train_loss=0.21] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.89it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.89it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.85it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.85it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.82it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.82it/s, train_loss=0.0855]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.84it/s, train_loss=0.0855]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.84it/s, train_loss=0.243] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.98it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.98it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.20it/s, train_loss=0.702]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.20it/s, train_loss=0.086]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.21it/s, train_loss=0.086]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.21it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.00it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.00it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.21it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.21it/s, train_loss=0.0299]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75 average loss: 0.1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  68%|██████▊   | 75/110 [31:08<14:25, 24.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 75 current AUC: 0.9954 current accuracy: 0.9130 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 76/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.14it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.14it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.11it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.11it/s, train_loss=0.0623]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.26it/s, train_loss=0.0623]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.26it/s, train_loss=0.0895]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.90it/s, train_loss=0.0895]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.90it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.93it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.93it/s, train_loss=0.697] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.07it/s, train_loss=0.697]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.07it/s, train_loss=0.0411]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.97it/s, train_loss=0.0411]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.97it/s, train_loss=0.828] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.88it/s, train_loss=0.828]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.88it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.06it/s, train_loss=0.413]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.06it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.27it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.27it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.00it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.00it/s, train_loss=0.11]  \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.82it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.82it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.96it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.96it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.83it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.83it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.78it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.78it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.09it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.09it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.08it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.08it/s, train_loss=0.28] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.01it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.01it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.99it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  4.99it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.96it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.96it/s, train_loss=0.211] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.10it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.10it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.16it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.16it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.28it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.28it/s, train_loss=0.0253]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.22it/s, train_loss=0.0253]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.22it/s, train_loss=0.333] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.95it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.95it/s, train_loss=0.0383]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.09it/s, train_loss=0.0383]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.09it/s, train_loss=0.197] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.97it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.97it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.05it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.05it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.06it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.06it/s, train_loss=0.741] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.94it/s, train_loss=0.741]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.94it/s, train_loss=0.511]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.92it/s, train_loss=0.511]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.92it/s, train_loss=0.0289]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.93it/s, train_loss=0.0289]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.93it/s, train_loss=0.0238]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.18it/s, train_loss=0.0238]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.18it/s, train_loss=0.148] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.21it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.21it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.21it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.21it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.97it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.97it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.90it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.90it/s, train_loss=0.0675]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.87it/s, train_loss=0.0675]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.87it/s, train_loss=0.12]  \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:17,  4.79it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.79it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.95it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.95it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.91it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.91it/s, train_loss=0.215] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.13it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.13it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.98it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.98it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.89it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.89it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.88it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.88it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.77it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.77it/s, train_loss=0.193] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.12it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.12it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.28it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.28it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.32it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.32it/s, train_loss=0.072] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.09it/s, train_loss=0.072]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.09it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.02it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.02it/s, train_loss=0.0657]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.01it/s, train_loss=0.0657]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.01it/s, train_loss=0.347] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.06it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.06it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.17it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.17it/s, train_loss=0.0565]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.99it/s, train_loss=0.0565]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.99it/s, train_loss=0.225] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.19it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.19it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.89it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.89it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.05it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.05it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.17it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.17it/s, train_loss=0.0644]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.13it/s, train_loss=0.0644]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.13it/s, train_loss=0.0514]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.25it/s, train_loss=0.0514]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.25it/s, train_loss=0.353] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.25it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.25it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.16it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.16it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.18it/s, train_loss=0.353]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.18it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.94it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.94it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.11it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.11it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.98it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.98it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.71it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.71it/s, train_loss=0.00811]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.90it/s, train_loss=0.00811]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.90it/s, train_loss=0.4]    \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.91it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.91it/s, train_loss=0.0529]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.66it/s, train_loss=0.0529]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.66it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.74it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.74it/s, train_loss=0.0268]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.97it/s, train_loss=0.0268]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.97it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.80it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.80it/s, train_loss=0.0495]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.90it/s, train_loss=0.0495]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.90it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.80it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.80it/s, train_loss=0.0689]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.74it/s, train_loss=0.0689]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.74it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.69it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.69it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.05it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.05it/s, train_loss=0.0365]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.26it/s, train_loss=0.0365]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.26it/s, train_loss=0.0978]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.24it/s, train_loss=0.0978]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.24it/s, train_loss=0.199] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.01it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.01it/s, train_loss=0.0591]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.00it/s, train_loss=0.0591]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.00it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.08it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.08it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.09it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.09it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.33it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.33it/s, train_loss=0.282] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.06it/s, train_loss=0.282]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.06it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.11it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.11it/s, train_loss=0.0222]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.87it/s, train_loss=0.0222]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.87it/s, train_loss=0.97]  \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.95it/s, train_loss=0.97]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.95it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.02it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.02it/s, train_loss=0.371] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.02it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.02it/s, train_loss=0.0899]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.84it/s, train_loss=0.0899]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.84it/s, train_loss=0.268] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.05it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.05it/s, train_loss=0.0375]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.95it/s, train_loss=0.0375]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.95it/s, train_loss=0.517] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.03it/s, train_loss=0.517]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.03it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.98it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.98it/s, train_loss=0.00865]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.88it/s, train_loss=0.00865]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.88it/s, train_loss=0.0782] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.82it/s, train_loss=0.0782]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.82it/s, train_loss=0.0841]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.86it/s, train_loss=0.0841]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.86it/s, train_loss=0.215] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.77it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.77it/s, train_loss=0.091]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.95it/s, train_loss=0.091]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.95it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.86it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  4.86it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.75it/s, train_loss=0.448]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.75it/s, train_loss=0.18] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.91it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.91it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.92it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.92it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.94it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.94it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.84it/s, train_loss=0.223]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  4.84it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.01it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.01it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.99it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.99it/s, train_loss=0.0865]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.68it/s, train_loss=0.0865]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.68it/s, train_loss=0.125] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.74it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.74it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.70it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.70it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.84it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.84it/s, train_loss=0.204] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.93it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.93it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.18it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.18it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.17it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.17it/s, train_loss=0.0538]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.26it/s, train_loss=0.0538]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  5.26it/s, train_loss=0.495] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.27it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.27it/s, train_loss=0.023]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.50it/s, train_loss=0.023]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.50it/s, train_loss=0.341]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76 average loss: 0.1674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  69%|██████▉   | 76/110 [31:33<14:02, 24.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 76 current AUC: 0.9956 current accuracy: 0.8882 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 77/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:27,  4.39it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:27,  4.39it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.68it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:25,  4.68it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.73it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.73it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.69it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.69it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.87it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.87it/s, train_loss=0.057] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.91it/s, train_loss=0.057]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.91it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.89it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.89it/s, train_loss=0.0403]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.11it/s, train_loss=0.0403]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  5.11it/s, train_loss=0.061] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.96it/s, train_loss=0.061]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.96it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.08it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.08it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.98it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.98it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.07it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.07it/s, train_loss=0.0501]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.86it/s, train_loss=0.0501]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.86it/s, train_loss=0.221] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.77it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.77it/s, train_loss=0.095]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.01it/s, train_loss=0.095]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.01it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.94it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.94it/s, train_loss=0.0355]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.22it/s, train_loss=0.0355]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.22it/s, train_loss=0.521] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.15it/s, train_loss=0.521]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  5.15it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.01it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.01it/s, train_loss=0.0521]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.01it/s, train_loss=0.0521]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.01it/s, train_loss=0.0102]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.97it/s, train_loss=0.0102]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.97it/s, train_loss=0.0727]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.01it/s, train_loss=0.0727]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.01it/s, train_loss=0.0456]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.22it/s, train_loss=0.0456]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.22it/s, train_loss=0.192] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.31it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.31it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.17it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.17it/s, train_loss=0.081]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.18it/s, train_loss=0.081]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.18it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.14it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.14it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.08it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  5.08it/s, train_loss=0.00831]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.95it/s, train_loss=0.00831]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.95it/s, train_loss=0.105]  \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.07it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.07it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.97it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.97it/s, train_loss=0.32] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.02it/s, train_loss=0.32]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.02it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.04it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  5.04it/s, train_loss=0.0449]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.96it/s, train_loss=0.0449]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.96it/s, train_loss=0.173] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.00it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.00it/s, train_loss=0.0333]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  5.00it/s, train_loss=0.0333]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  5.00it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.95it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.95it/s, train_loss=0.394] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.82it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:17,  4.82it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.70it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.70it/s, train_loss=0.00292]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:17,  4.67it/s, train_loss=0.00292]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:17,  4.67it/s, train_loss=0.141]  \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:17,  4.68it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:17,  4.68it/s, train_loss=0.074]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.82it/s, train_loss=0.074]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.82it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.76it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:16,  4.76it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.10it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.10it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.03it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.03it/s, train_loss=0.0513]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.92it/s, train_loss=0.0513]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.92it/s, train_loss=0.104] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.85it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.85it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.97it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  4.97it/s, train_loss=0.0652]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.12it/s, train_loss=0.0652]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.12it/s, train_loss=0.0537]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.25it/s, train_loss=0.0537]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.25it/s, train_loss=0.0538]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.29it/s, train_loss=0.0538]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.29it/s, train_loss=0.176] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.25it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.25it/s, train_loss=0.051]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.16it/s, train_loss=0.051]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  5.16it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.10it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.10it/s, train_loss=0.0522]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.06it/s, train_loss=0.0522]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.06it/s, train_loss=0.0215]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.95it/s, train_loss=0.0215]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.95it/s, train_loss=0.00305]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.12it/s, train_loss=0.00305]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.12it/s, train_loss=0.0452] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.96it/s, train_loss=0.0452]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  4.96it/s, train_loss=0.158] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.80it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.80it/s, train_loss=0.0597]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.95it/s, train_loss=0.0597]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.95it/s, train_loss=0.0487]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.96it/s, train_loss=0.0487]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.96it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.84it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.84it/s, train_loss=0.281] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.95it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  4.95it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.07it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.07it/s, train_loss=0.0789]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.03it/s, train_loss=0.0789]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.03it/s, train_loss=0.0207]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.02it/s, train_loss=0.0207]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.02it/s, train_loss=0.209] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.16it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.16it/s, train_loss=0.743]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.87it/s, train_loss=0.743]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  4.87it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.96it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.96it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.93it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.93it/s, train_loss=0.0321]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.97it/s, train_loss=0.0321]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.97it/s, train_loss=0.332] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.02it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.02it/s, train_loss=0.0414]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.23it/s, train_loss=0.0414]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  5.23it/s, train_loss=0.131] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:08,  5.28it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:08,  5.28it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.47it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.47it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.39it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.39it/s, train_loss=0.0332]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.25it/s, train_loss=0.0332]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.25it/s, train_loss=0.149] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.22it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.22it/s, train_loss=0.0137]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.11it/s, train_loss=0.0137]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.11it/s, train_loss=0.251] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.18it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.18it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.23it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.23it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.09it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.09it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.04it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.04it/s, train_loss=0.0452]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.93it/s, train_loss=0.0452]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.93it/s, train_loss=0.0559]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.07it/s, train_loss=0.0559]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.07it/s, train_loss=0.45]  \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.02it/s, train_loss=0.45]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.02it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.09it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.09it/s, train_loss=0.0972]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.89it/s, train_loss=0.0972]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.89it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.12it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.12it/s, train_loss=0.269] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.28it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.28it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.96it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.96it/s, train_loss=0.39] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.86it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.86it/s, train_loss=0.0774]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.05it/s, train_loss=0.0774]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.05it/s, train_loss=0.152] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.32it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.32it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.01it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.01it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.21it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.21it/s, train_loss=0.108] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.11it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.11it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.27it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.27it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.26it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.26it/s, train_loss=0.208] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.18it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.18it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.12it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.12it/s, train_loss=0.125] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.26it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.26it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.29it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.29it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.16it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.16it/s, train_loss=0.0961]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.12it/s, train_loss=0.0961]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.12it/s, train_loss=0.175] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.25it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.25it/s, train_loss=0.071]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.16it/s, train_loss=0.071]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.16it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.21it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.21it/s, train_loss=0.019] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.20it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.20it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.29it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.29it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.07it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.07it/s, train_loss=0.0481]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.30it/s, train_loss=0.0481]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.30it/s, train_loss=0.186] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.18it/s, train_loss=0.324]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.18it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.09it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.09it/s, train_loss=0.139] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.22it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.22it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.19it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.19it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.22it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.22it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.12it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.12it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.98it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.98it/s, train_loss=0.766]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77 average loss: 0.1359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  70%|███████   | 77/110 [31:58<13:36, 24.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 77 current AUC: 0.9924 current accuracy: 0.8758 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 78/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.10it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.10it/s, train_loss=0.0602]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.0602]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.0507]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.22it/s, train_loss=0.0507]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.22it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.26it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.26it/s, train_loss=0.0781]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:21,  5.46it/s, train_loss=0.0781]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:21,  5.46it/s, train_loss=0.00955]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.35it/s, train_loss=0.00955]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.35it/s, train_loss=0.0632] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.0632]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.02it/s, train_loss=0.298] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.94it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.94it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.95it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.95it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  4.99it/s, train_loss=0.507]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.99it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.96it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.96it/s, train_loss=0.0756]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.03it/s, train_loss=0.0756]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.03it/s, train_loss=0.0821]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.15it/s, train_loss=0.0821]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.15it/s, train_loss=0.0727]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.15it/s, train_loss=0.0727]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.15it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.03it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.03it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.04it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.04it/s, train_loss=0.274] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.13it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.13it/s, train_loss=0.0696]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.21it/s, train_loss=0.0696]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.21it/s, train_loss=0.259] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.28it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.28it/s, train_loss=0.0907]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.17it/s, train_loss=0.0907]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.17it/s, train_loss=0.196] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.14it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.14it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.14it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.14it/s, train_loss=0.0656]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.38it/s, train_loss=0.0656]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.38it/s, train_loss=0.0735]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.37it/s, train_loss=0.0735]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.37it/s, train_loss=0.447] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.99it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.99it/s, train_loss=0.082]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.00it/s, train_loss=0.082]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.00it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.03it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.03it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.19it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.19it/s, train_loss=0.217] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.09it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.09it/s, train_loss=0.0512]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.18it/s, train_loss=0.0512]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.18it/s, train_loss=0.0613]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.16it/s, train_loss=0.0613]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.16it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.0829]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.30it/s, train_loss=0.0829]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.30it/s, train_loss=0.149] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.95it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.95it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.04it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.04it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.14it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.14it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.18it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.18it/s, train_loss=0.0188]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.24it/s, train_loss=0.0188]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.24it/s, train_loss=0.152] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.15it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.15it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.40it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.40it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:07<00:15,  5.21it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.21it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.15it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.15it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.08it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.08it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.12it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.12it/s, train_loss=0.149] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.01it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.01it/s, train_loss=0.0781]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:15,  4.99it/s, train_loss=0.0781]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.99it/s, train_loss=0.123] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.00it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.00it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.01it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.01it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.10it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.10it/s, train_loss=0.43]  \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.01it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.01it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.35it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.35it/s, train_loss=0.082] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.36it/s, train_loss=0.082]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.36it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.17it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.17it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.17it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.17it/s, train_loss=0.0256]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:13,  4.80it/s, train_loss=0.0256]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.80it/s, train_loss=0.326] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.95it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.95it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.83it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.83it/s, train_loss=0.00584]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.83it/s, train_loss=0.00584]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.83it/s, train_loss=0.0431] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.95it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.95it/s, train_loss=0.217] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  4.88it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.88it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.99it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.99it/s, train_loss=0.0778]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.82it/s, train_loss=0.0778]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.82it/s, train_loss=0.0723]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:12,  4.74it/s, train_loss=0.0723]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:12,  4.74it/s, train_loss=0.283] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  4.90it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.90it/s, train_loss=0.00641]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.02it/s, train_loss=0.00641]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.02it/s, train_loss=0.119]  \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.30it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.30it/s, train_loss=0.0253]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.08it/s, train_loss=0.0253]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.08it/s, train_loss=0.0604]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.96it/s, train_loss=0.0604]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.96it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.14it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.14it/s, train_loss=0.12]  \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.88it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.88it/s, train_loss=0.0755]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.93it/s, train_loss=0.0755]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.93it/s, train_loss=0.0466]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.91it/s, train_loss=0.0466]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.91it/s, train_loss=0.166] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.87it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.87it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  5.00it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.00it/s, train_loss=0.418] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.97it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.97it/s, train_loss=0.0879]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.99it/s, train_loss=0.0879]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.99it/s, train_loss=0.0557]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.99it/s, train_loss=0.0557]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.99it/s, train_loss=0.394] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.98it/s, train_loss=0.394]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.98it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.01it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.01it/s, train_loss=0.112] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.11it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.11it/s, train_loss=0.0415]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.93it/s, train_loss=0.0415]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.93it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.85it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.85it/s, train_loss=0.175] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.00it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.00it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  4.99it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.99it/s, train_loss=0.131] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.99it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.99it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.87it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.87it/s, train_loss=0.114] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.97it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.97it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.18it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.18it/s, train_loss=0.176] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.21it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.21it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.10it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.10it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.23it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.23it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.26it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.26it/s, train_loss=0.118] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.19it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.19it/s, train_loss=0.00808]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.31it/s, train_loss=0.00808]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.31it/s, train_loss=0.0265] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.13it/s, train_loss=0.0265]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.13it/s, train_loss=0.0966]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.90it/s, train_loss=0.0966]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.90it/s, train_loss=0.414] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.19it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.19it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.86it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.86it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.85it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.85it/s, train_loss=0.0199]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.84it/s, train_loss=0.0199]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.84it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:04,  4.73it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:04,  4.73it/s, train_loss=0.203] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.81it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.81it/s, train_loss=0.0727]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.10it/s, train_loss=0.0727]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.10it/s, train_loss=0.0575]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.07it/s, train_loss=0.0575]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.07it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.03it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.03it/s, train_loss=0.00678]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.21it/s, train_loss=0.00678]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.21it/s, train_loss=0.231]  \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.17it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.17it/s, train_loss=0.0258]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.08it/s, train_loss=0.0258]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.08it/s, train_loss=0.0278]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.10it/s, train_loss=0.0278]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.10it/s, train_loss=0.233] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.09it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.09it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.00it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.00it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.00it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.00it/s, train_loss=0.00841]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.07it/s, train_loss=0.00841]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.07it/s, train_loss=0.0124] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.99it/s, train_loss=0.0124]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.99it/s, train_loss=0.123] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.07it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.07it/s, train_loss=0.192] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.91it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.91it/s, train_loss=0.463]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.89it/s, train_loss=0.463]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.89it/s, train_loss=0.597]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78 average loss: 0.1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  71%|███████   | 78/110 [32:22<13:10, 24.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 78 current AUC: 0.9942 current accuracy: 0.9006 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 79/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0516]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.54it/s, train_loss=0.0516]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.54it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.20it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.20it/s, train_loss=0.047]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.34it/s, train_loss=0.047]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.34it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.37it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.37it/s, train_loss=0.197] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:21,  5.39it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:21,  5.39it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.45it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.45it/s, train_loss=0.0513]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.47it/s, train_loss=0.0513]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.47it/s, train_loss=0.0793]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.37it/s, train_loss=0.0793]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.37it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.31it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.31it/s, train_loss=0.0407]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.26it/s, train_loss=0.0407]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.26it/s, train_loss=0.126] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.20it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.20it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.13it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.13it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.01it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.01it/s, train_loss=0.0556]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.91it/s, train_loss=0.0556]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.91it/s, train_loss=0.371] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:22,  4.85it/s, train_loss=0.371]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.85it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.77it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.77it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.82it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.82it/s, train_loss=0.00421]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.07it/s, train_loss=0.00421]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.07it/s, train_loss=0.021]  \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.92it/s, train_loss=0.021]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.92it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.17it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.17it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.09it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.09it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.27it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.27it/s, train_loss=0.036] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.06it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.06it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.10it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.10it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.00it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.00it/s, train_loss=0.0958]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.05it/s, train_loss=0.0958]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.05it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.12it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.12it/s, train_loss=0.095] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.83it/s, train_loss=0.095]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.83it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.93it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.93it/s, train_loss=0.014] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.85it/s, train_loss=0.014]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.85it/s, train_loss=0.38] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.82it/s, train_loss=0.38]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.82it/s, train_loss=0.0641]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.0641]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.11it/s, train_loss=0.714] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.82it/s, train_loss=0.714]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.82it/s, train_loss=0.0439]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.97it/s, train_loss=0.0439]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.97it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.00it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.00it/s, train_loss=0.036] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.98it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.98it/s, train_loss=0.0337]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.86it/s, train_loss=0.0337]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.86it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.81it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.81it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.96it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.96it/s, train_loss=0.0485]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.00it/s, train_loss=0.0485]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.00it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.96it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.96it/s, train_loss=0.0788]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.07it/s, train_loss=0.0788]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.07it/s, train_loss=0.225] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.23it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.23it/s, train_loss=0.0226]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.18it/s, train_loss=0.0226]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.18it/s, train_loss=0.148] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.15it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.15it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.97it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.97it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.95it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.95it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.01it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.01it/s, train_loss=0.188] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.19it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.19it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.98it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.98it/s, train_loss=0.0149]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.88it/s, train_loss=0.0149]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.88it/s, train_loss=0.185] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.03it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.03it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.12it/s, train_loss=0.438]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.12it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.21it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.21it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.27it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.27it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.10it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.10it/s, train_loss=0.0486]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.19it/s, train_loss=0.0486]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.19it/s, train_loss=0.258] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.08it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.08it/s, train_loss=0.32] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.03it/s, train_loss=0.32]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.03it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.98it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.98it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.97it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.97it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.99it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.99it/s, train_loss=0.043] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.06it/s, train_loss=0.043]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.06it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.03it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.03it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.26it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.26it/s, train_loss=0.0667]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.20it/s, train_loss=0.0667]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.20it/s, train_loss=0.0615]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.94it/s, train_loss=0.0615]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.94it/s, train_loss=0.114] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.96it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.96it/s, train_loss=0.08] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.00it/s, train_loss=0.08]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.00it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.84it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.84it/s, train_loss=0.163] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.92it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.92it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.90it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.90it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.07it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.07it/s, train_loss=0.201] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.85it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.85it/s, train_loss=0.0504]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.87it/s, train_loss=0.0504]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.87it/s, train_loss=0.834] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.99it/s, train_loss=0.834]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.99it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.95it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.95it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.88it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.88it/s, train_loss=0.0454]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.93it/s, train_loss=0.0454]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.93it/s, train_loss=0.03]  \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.82it/s, train_loss=0.03]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.82it/s, train_loss=0.0546]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.97it/s, train_loss=0.0546]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.97it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.14it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.14it/s, train_loss=0.396] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.04] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.07it/s, train_loss=0.04]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.07it/s, train_loss=0.00804]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.87it/s, train_loss=0.00804]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.87it/s, train_loss=0.0288] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.87it/s, train_loss=0.0288]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.87it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.77it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.77it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.67it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.67it/s, train_loss=0.0372]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:07,  4.49it/s, train_loss=0.0372]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:07,  4.49it/s, train_loss=0.123] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.88it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.88it/s, train_loss=0.0882]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.01it/s, train_loss=0.0882]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.01it/s, train_loss=0.436] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.13it/s, train_loss=0.436]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.13it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.28it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.28it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.32it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.32it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.24it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.24it/s, train_loss=0.0447]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.08it/s, train_loss=0.0447]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.08it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.94it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.94it/s, train_loss=0.264] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.73it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.73it/s, train_loss=0.0355]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.63it/s, train_loss=0.0355]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.63it/s, train_loss=0.0224]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.52it/s, train_loss=0.0224]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.52it/s, train_loss=0.0448]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.70it/s, train_loss=0.0448]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.70it/s, train_loss=0.106] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.60it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.60it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:04,  4.72it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:04,  4.72it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.65it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  4.65it/s, train_loss=0.00783]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.57it/s, train_loss=0.00783]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.57it/s, train_loss=0.0934] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.78it/s, train_loss=0.0934]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.78it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.0241]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.86it/s, train_loss=0.0241]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.86it/s, train_loss=0.0966]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.91it/s, train_loss=0.0966]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  4.91it/s, train_loss=0.022] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.94it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.94it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.80it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.80it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.90it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.90it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.95it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.95it/s, train_loss=0.437] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.79it/s, train_loss=0.437]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.79it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.86it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.86it/s, train_loss=0.0367]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.96it/s, train_loss=0.0367]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.96it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.84it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.84it/s, train_loss=0.367] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.76it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.76it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.67it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.67it/s, train_loss=0.0585]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.66it/s, train_loss=0.0585]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.66it/s, train_loss=0.106] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.91it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.91it/s, train_loss=0.0176]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79 average loss: 0.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  72%|███████▏  | 79/110 [32:47<12:49, 24.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 79 current AUC: 0.9886 current accuracy: 0.8509 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 80/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0622]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.51it/s, train_loss=0.0622]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.51it/s, train_loss=0.0896]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.27it/s, train_loss=0.0896]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.27it/s, train_loss=0.0585]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:20,  5.72it/s, train_loss=0.0585]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:20,  5.72it/s, train_loss=0.124] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.48it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.48it/s, train_loss=0.0275]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:21,  5.53it/s, train_loss=0.0275]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:21,  5.53it/s, train_loss=0.212] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.18it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.18it/s, train_loss=0.00868]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.30it/s, train_loss=0.00868]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.30it/s, train_loss=0.169]  \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  4.97it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  4.97it/s, train_loss=0.0196]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.04it/s, train_loss=0.0196]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.04it/s, train_loss=0.374] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.00it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.00it/s, train_loss=0.3]  \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.13it/s, train_loss=0.3]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.13it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.03it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.03it/s, train_loss=0.0655]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.07it/s, train_loss=0.0655]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.07it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.07it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.07it/s, train_loss=0.0102]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.05it/s, train_loss=0.0102]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.05it/s, train_loss=0.0629]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.03it/s, train_loss=0.0629]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.03it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.03it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.03it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.87it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.87it/s, train_loss=0.0922]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.81it/s, train_loss=0.0922]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.81it/s, train_loss=0.00952]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:21,  4.80it/s, train_loss=0.00952]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.80it/s, train_loss=0.122]  \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.84it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.84it/s, train_loss=0.0888]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.65it/s, train_loss=0.0888]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.65it/s, train_loss=0.0856]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.83it/s, train_loss=0.0856]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.83it/s, train_loss=0.152] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.85it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.85it/s, train_loss=0.0778]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.98it/s, train_loss=0.0778]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.98it/s, train_loss=0.052] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.09it/s, train_loss=0.052]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.09it/s, train_loss=0.0418]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.11it/s, train_loss=0.0418]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.11it/s, train_loss=0.113] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.93it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.93it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.98it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.98it/s, train_loss=0.0561]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.86it/s, train_loss=0.0561]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.86it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.84it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.84it/s, train_loss=0.247] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.94it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.94it/s, train_loss=0.0647]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.87it/s, train_loss=0.0647]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.87it/s, train_loss=0.00543]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.95it/s, train_loss=0.00543]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  4.95it/s, train_loss=0.139]  \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.84it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.84it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.98it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.98it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.85it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.85it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.79it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:17,  4.79it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.96it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.96it/s, train_loss=0.245] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.00it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.00it/s, train_loss=0.22] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.95it/s, train_loss=0.22]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.95it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.01it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.01it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.03it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  5.03it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.09it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.09it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.19it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.19it/s, train_loss=0.104] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.22it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.22it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.00it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.00it/s, train_loss=0.00613]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.87it/s, train_loss=0.00613]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  4.87it/s, train_loss=0.0942] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.90it/s, train_loss=0.0942]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.90it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.01it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.01it/s, train_loss=0.0613]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.13it/s, train_loss=0.0613]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.13it/s, train_loss=0.0147]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.98it/s, train_loss=0.0147]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.98it/s, train_loss=0.291] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.92it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  4.92it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.86it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.86it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.88it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.88it/s, train_loss=0.0729]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.81it/s, train_loss=0.0729]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.81it/s, train_loss=0.152] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  4.98it/s, train_loss=0.00714]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.83it/s, train_loss=0.00714]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.83it/s, train_loss=0.258]  \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.89it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.89it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.92it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.92it/s, train_loss=0.0225]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.89it/s, train_loss=0.0225]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.89it/s, train_loss=0.0761]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.83it/s, train_loss=0.0761]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  4.83it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:12,  4.71it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:12,  4.71it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:12,  4.65it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:12,  4.65it/s, train_loss=0.399] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.64it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.64it/s, train_loss=0.00555]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.66it/s, train_loss=0.00555]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.66it/s, train_loss=0.0708] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.96it/s, train_loss=0.0708]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  4.96it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.22it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.22it/s, train_loss=0.404] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.13it/s, train_loss=0.404]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.13it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.22it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.22it/s, train_loss=0.0334]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.99it/s, train_loss=0.0334]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.99it/s, train_loss=0.019] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.96it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  4.96it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.99it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.99it/s, train_loss=0.00286]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.02it/s, train_loss=0.00286]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.02it/s, train_loss=0.0268] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.94it/s, train_loss=0.0268]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.94it/s, train_loss=0.151] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.97it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.97it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.00it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:08,  5.00it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.98it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.98it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.07it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.07it/s, train_loss=0.0231]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.01it/s, train_loss=0.0231]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.01it/s, train_loss=0.119] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.17it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.17it/s, train_loss=0.0949]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.26it/s, train_loss=0.0949]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  5.26it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.88it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.88it/s, train_loss=0.00685]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.03it/s, train_loss=0.00685]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.03it/s, train_loss=0.772]  \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.95it/s, train_loss=0.772]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.95it/s, train_loss=0.0485]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.01it/s, train_loss=0.0485]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.01it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.08it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  5.08it/s, train_loss=0.113] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.99it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.99it/s, train_loss=0.756]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.07it/s, train_loss=0.756]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.07it/s, train_loss=0.36] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.27it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.27it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.16it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  5.16it/s, train_loss=0.0628]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.35it/s, train_loss=0.0628]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.35it/s, train_loss=0.0462]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.37it/s, train_loss=0.0462]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.37it/s, train_loss=0.0241]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.68it/s, train_loss=0.0241]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.68it/s, train_loss=0.181] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.66it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.66it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.35it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.35it/s, train_loss=0.0493]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.48it/s, train_loss=0.0493]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.48it/s, train_loss=0.134] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.45it/s, train_loss=0.134]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.45it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.60it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.60it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.47it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.47it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.48it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.48it/s, train_loss=0.0283]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.33it/s, train_loss=0.0283]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.33it/s, train_loss=0.0729]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:02,  5.38it/s, train_loss=0.0729]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:02,  5.38it/s, train_loss=0.0893]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.15it/s, train_loss=0.0893]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.15it/s, train_loss=0.0848]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.30it/s, train_loss=0.0848]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.30it/s, train_loss=0.0455]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.06it/s, train_loss=0.0455]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.06it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.22it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.22it/s, train_loss=0.229] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.28it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.28it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.32it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.32it/s, train_loss=0.172] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.17it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.17it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.06it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.06it/s, train_loss=0.145] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.04it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.04it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.11it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.11it/s, train_loss=0.126] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.82it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.82it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.76it/s, train_loss=0.444]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.76it/s, train_loss=0.0348]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.78it/s, train_loss=0.0348]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.78it/s, train_loss=0.27]  \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.85it/s, train_loss=0.27]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.85it/s, train_loss=0.0287]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.01it/s, train_loss=0.0287]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.01it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.87it/s, train_loss=0.0213]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80 average loss: 0.1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  73%|███████▎  | 80/110 [33:12<12:23, 24.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 80 current AUC: 0.9929 current accuracy: 0.8882 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 81/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.54it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.54it/s, train_loss=0.0372]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.23it/s, train_loss=0.0372]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.23it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.35it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.35it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.42it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:21,  5.42it/s, train_loss=0.0509]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:21,  5.38it/s, train_loss=0.0509]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:21,  5.38it/s, train_loss=0.393] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.07it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.07it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.20it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.20it/s, train_loss=0.0173]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.07it/s, train_loss=0.0173]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.07it/s, train_loss=0.203] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.05it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.05it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.12it/s, train_loss=0.0517]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.12it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.22it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.22it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.31it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.31it/s, train_loss=0.032]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.31it/s, train_loss=0.032]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.31it/s, train_loss=0.0444]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.18it/s, train_loss=0.0444]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.18it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:19,  5.38it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:19,  5.38it/s, train_loss=0.0856]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.29it/s, train_loss=0.0856]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.29it/s, train_loss=0.215] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.12it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.12it/s, train_loss=0.00451]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.03it/s, train_loss=0.00451]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.03it/s, train_loss=0.0423] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.15it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.15it/s, train_loss=0.183] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.21it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.21it/s, train_loss=0.0627]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.28it/s, train_loss=0.0627]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.28it/s, train_loss=0.208] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.0958]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.90it/s, train_loss=0.0958]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.90it/s, train_loss=0.327] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.07it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.07it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.01it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.01it/s, train_loss=0.038]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.14it/s, train_loss=0.038]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.14it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.15it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.15it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.39it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.39it/s, train_loss=0.0779]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.21it/s, train_loss=0.0779]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.21it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.26it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.26it/s, train_loss=0.247] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:05<00:17,  5.26it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.26it/s, train_loss=0.0997]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  5.00it/s, train_loss=0.0997]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  5.00it/s, train_loss=0.0646]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.95it/s, train_loss=0.0646]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.95it/s, train_loss=0.246] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.09it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.09it/s, train_loss=0.0513]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.89it/s, train_loss=0.0513]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.89it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.68it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:18,  4.68it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.77it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.77it/s, train_loss=0.0888]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.10it/s, train_loss=0.0888]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.10it/s, train_loss=0.019] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.04it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.04it/s, train_loss=0.00841]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.11it/s, train_loss=0.00841]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.11it/s, train_loss=0.0832] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:07<00:15,  5.20it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.20it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:14,  5.41it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:14,  5.41it/s, train_loss=0.0207]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.48it/s, train_loss=0.0207]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:14,  5.48it/s, train_loss=0.178] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.43it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.43it/s, train_loss=0.0592]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.35it/s, train_loss=0.0592]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.35it/s, train_loss=0.755] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:14,  5.17it/s, train_loss=0.755]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.17it/s, train_loss=0.0951]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.22it/s, train_loss=0.0951]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.22it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.27it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.27it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.26it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.26it/s, train_loss=0.0456]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.21it/s, train_loss=0.0456]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.21it/s, train_loss=0.203] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.15it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.15it/s, train_loss=0.0741]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.10it/s, train_loss=0.0741]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.10it/s, train_loss=0.0178]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.92it/s, train_loss=0.0178]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.92it/s, train_loss=0.013] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.28it/s, train_loss=0.013]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.28it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.16it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.16it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.09it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.09it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.97it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.97it/s, train_loss=0.00376]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.84it/s, train_loss=0.00376]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.84it/s, train_loss=0.0294] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.07it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.07it/s, train_loss=0.459] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.83it/s, train_loss=0.459]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.83it/s, train_loss=0.0257]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  4.78it/s, train_loss=0.0257]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.78it/s, train_loss=0.028] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.96it/s, train_loss=0.028]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.96it/s, train_loss=0.0323]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.12it/s, train_loss=0.0323]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.12it/s, train_loss=0.0447]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.07it/s, train_loss=0.0447]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.07it/s, train_loss=0.0343]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.22it/s, train_loss=0.0343]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.22it/s, train_loss=0.11]  \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.11it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.11it/s, train_loss=0.0342]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.97it/s, train_loss=0.0342]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.97it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.83it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.83it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.72it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.72it/s, train_loss=0.0537]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:11,  4.61it/s, train_loss=0.0537]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:11,  4.61it/s, train_loss=0.192] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  4.75it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.75it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.72it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.72it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.63it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.63it/s, train_loss=0.0419]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.69it/s, train_loss=0.0419]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.69it/s, train_loss=0.12]  \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:10,  4.60it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:10,  4.60it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.80it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.80it/s, train_loss=0.0326]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.93it/s, train_loss=0.0326]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.93it/s, train_loss=0.188] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.90it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.90it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.84it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.84it/s, train_loss=0.283] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.92it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.92it/s, train_loss=0.0429]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.05it/s, train_loss=0.0429]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.09it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.09it/s, train_loss=0.188] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.85it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.85it/s, train_loss=0.0257]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.06it/s, train_loss=0.0257]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.06it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.99it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.99it/s, train_loss=0.0447]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.91it/s, train_loss=0.0447]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.91it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  5.00it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  5.00it/s, train_loss=0.0291]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.04it/s, train_loss=0.0291]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.04it/s, train_loss=0.0511]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.76it/s, train_loss=0.0511]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.76it/s, train_loss=0.00818]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.90it/s, train_loss=0.00818]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.90it/s, train_loss=0.0922] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.84it/s, train_loss=0.0922]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.84it/s, train_loss=0.129] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.79it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.79it/s, train_loss=0.00948]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.81it/s, train_loss=0.00948]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.81it/s, train_loss=0.0436] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.76it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.76it/s, train_loss=0.07]  \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.97it/s, train_loss=0.07]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.97it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.03it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.03it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.07]  \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.16it/s, train_loss=0.07]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.16it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.06it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.06it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.87it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.87it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.02it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.02it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.90it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.90it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.86it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.86it/s, train_loss=0.157] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.89it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.89it/s, train_loss=0.0782]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.87it/s, train_loss=0.0782]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.87it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.86it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.86it/s, train_loss=0.335] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.81it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.81it/s, train_loss=0.0325]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.81it/s, train_loss=0.0325]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.81it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.76it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.76it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.72it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.72it/s, train_loss=0.0945]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.69it/s, train_loss=0.0945]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.69it/s, train_loss=0.285] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.73it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.73it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.80it/s, train_loss=0.495]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.80it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.80it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.80it/s, train_loss=0.325] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.76it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.76it/s, train_loss=0.0343]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.76it/s, train_loss=0.0343]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.76it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.79it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.79it/s, train_loss=0.0418]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.00it/s, train_loss=0.0418]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.00it/s, train_loss=0.0673]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.07it/s, train_loss=0.0673]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.07it/s, train_loss=0.15]  \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.18it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.18it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.32it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.32it/s, train_loss=0.239]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81 average loss: 0.1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  74%|███████▎  | 81/110 [33:37<11:59, 24.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 81 current AUC: 0.9977 current accuracy: 0.8820 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 82/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.66it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.66it/s, train_loss=0.308] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.63it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.63it/s, train_loss=0.0748]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.80it/s, train_loss=0.0748]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.80it/s, train_loss=0.163] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.75it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.75it/s, train_loss=0.0967]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.04it/s, train_loss=0.0967]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.04it/s, train_loss=0.322] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.75it/s, train_loss=0.322]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.75it/s, train_loss=0.0675]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.82it/s, train_loss=0.0675]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.82it/s, train_loss=0.0684]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.84it/s, train_loss=0.0684]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.84it/s, train_loss=0.0915]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.83it/s, train_loss=0.0915]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.83it/s, train_loss=0.287] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.84it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.84it/s, train_loss=0.0196]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.96it/s, train_loss=0.0196]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.96it/s, train_loss=0.154] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.85it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.85it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.78it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.78it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:23,  4.69it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:23,  4.69it/s, train_loss=0.059] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.81it/s, train_loss=0.059]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.81it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.96it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.96it/s, train_loss=0.0602]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.11it/s, train_loss=0.0602]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.11it/s, train_loss=0.14]  \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.91it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.91it/s, train_loss=0.00784]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.98it/s, train_loss=0.00784]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  4.98it/s, train_loss=0.128]  \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.84it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.84it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.81it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.81it/s, train_loss=0.00451]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.81it/s, train_loss=0.00451]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.81it/s, train_loss=0.0456] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.08it/s, train_loss=0.0456]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.08it/s, train_loss=0.229] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.86it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:20,  4.86it/s, train_loss=0.0977]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.15it/s, train_loss=0.0977]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.15it/s, train_loss=0.221] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.05it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.05it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.26it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.26it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.48it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.48it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.22it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:17,  5.22it/s, train_loss=0.66] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.14it/s, train_loss=0.66]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.14it/s, train_loss=0.0469]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.34it/s, train_loss=0.0469]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.34it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.50it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.50it/s, train_loss=0.117] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.40it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.40it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.11it/s, train_loss=0.301]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  5.11it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.05it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.05it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.15it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.15it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.20it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.20it/s, train_loss=0.075] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.16it/s, train_loss=0.075]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.16it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.18it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.18it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.15it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.15it/s, train_loss=0.00963]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.06it/s, train_loss=0.00963]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.06it/s, train_loss=0.0284] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.18it/s, train_loss=0.0284]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.18it/s, train_loss=0.0655]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.0655]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.025] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.99it/s, train_loss=0.025]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.99it/s, train_loss=0.0314]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.94it/s, train_loss=0.0314]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.94it/s, train_loss=0.181] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.94it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.94it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.84it/s, train_loss=0.501]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.84it/s, train_loss=0.725]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.86it/s, train_loss=0.725]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.86it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.73it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:15,  4.73it/s, train_loss=0.00668]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.78it/s, train_loss=0.00668]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.78it/s, train_loss=0.361]  \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.77it/s, train_loss=0.361]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.77it/s, train_loss=0.0164]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.87it/s, train_loss=0.0164]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.87it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.67it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.67it/s, train_loss=0.281] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.85it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:14,  4.85it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.83it/s, train_loss=0.405]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.83it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.79it/s, train_loss=0.393]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.79it/s, train_loss=0.0638]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.94it/s, train_loss=0.0638]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.94it/s, train_loss=0.107] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.94it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.94it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.79it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:13,  4.79it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.90it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.90it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.92it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.92it/s, train_loss=0.112] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.87it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.87it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.87it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.87it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.93it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  4.93it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.87it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.87it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.95it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.95it/s, train_loss=0.0836]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.74it/s, train_loss=0.0836]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.74it/s, train_loss=0.459] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.80it/s, train_loss=0.459]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.80it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.12it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  5.12it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.20it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.20it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.07it/s, train_loss=0.262]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.07it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.28it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.28it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.28it/s, train_loss=0.396]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.28it/s, train_loss=0.0488]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.23it/s, train_loss=0.0488]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  5.23it/s, train_loss=0.106] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:08,  5.47it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:08,  5.47it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.38it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.38it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.25it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.25it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.21it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.21it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.32it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.32it/s, train_loss=0.0372]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.20it/s, train_loss=0.0372]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.20it/s, train_loss=0.035] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.13it/s, train_loss=0.035]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.13it/s, train_loss=0.0059]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.25it/s, train_loss=0.0059]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.25it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.43it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.43it/s, train_loss=0.291] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.29it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.29it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.41it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:06,  5.41it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.37it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.37it/s, train_loss=0.0775]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.26it/s, train_loss=0.0775]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.26it/s, train_loss=0.104] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.18it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.18it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.09it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.09it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.34it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:05,  5.34it/s, train_loss=0.239] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.35it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.35it/s, train_loss=0.0337]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.15it/s, train_loss=0.0337]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.15it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.88it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.88it/s, train_loss=0.101] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.96it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.96it/s, train_loss=0.0829]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.85it/s, train_loss=0.0829]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.85it/s, train_loss=0.00956]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.90it/s, train_loss=0.00956]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.90it/s, train_loss=0.0494] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.08it/s, train_loss=0.0494]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.08it/s, train_loss=0.00618]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.06it/s, train_loss=0.00618]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.06it/s, train_loss=0.19]   \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.99it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.99it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.91it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.91it/s, train_loss=0.0642]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.88it/s, train_loss=0.0642]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.88it/s, train_loss=0.0221]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.02it/s, train_loss=0.0221]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.02it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.0403]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.92it/s, train_loss=0.0403]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.92it/s, train_loss=0.0475]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.24it/s, train_loss=0.0475]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.24it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.93it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.93it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.91it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.91it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.05it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.05it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.84it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.84it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.86it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.86it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.81it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.81it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.94it/s, train_loss=0.391]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.94it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.82it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.82it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.95it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.95it/s, train_loss=0.479] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.99it/s, train_loss=0.479]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.99it/s, train_loss=0.00899]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.97it/s, train_loss=0.00899]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.97it/s, train_loss=0.00936]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.00936]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.0757] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.93it/s, train_loss=0.0757]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.93it/s, train_loss=0.0797]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.68it/s, train_loss=0.0797]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.68it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.78it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.78it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.83it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.83it/s, train_loss=0.0356]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82 average loss: 0.1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  75%|███████▍  | 82/110 [34:02<11:35, 24.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 82 current AUC: 0.9963 current accuracy: 0.9379 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 83/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:27,  4.48it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:27,  4.48it/s, train_loss=0.0764]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.05it/s, train_loss=0.0764]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.05it/s, train_loss=0.268] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.20it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.20it/s, train_loss=0.0949]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.90it/s, train_loss=0.0949]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.90it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.00it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.00it/s, train_loss=0.0556]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.24it/s, train_loss=0.0556]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.24it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.41it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.41it/s, train_loss=0.0548]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.39it/s, train_loss=0.0548]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:21,  5.39it/s, train_loss=0.0465]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.35it/s, train_loss=0.0465]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.35it/s, train_loss=0.0356]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.21it/s, train_loss=0.0356]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.21it/s, train_loss=0.0255]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.22it/s, train_loss=0.0255]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.22it/s, train_loss=0.0879]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.01it/s, train_loss=0.0879]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.01it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.98it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.98it/s, train_loss=0.157] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.83it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.83it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.02it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.02it/s, train_loss=0.1]   \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.15it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.15it/s, train_loss=0.0501]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.34it/s, train_loss=0.0501]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.34it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.26it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.26it/s, train_loss=0.0365]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.30it/s, train_loss=0.0365]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.30it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.19it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.19it/s, train_loss=0.263] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.19it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.19it/s, train_loss=0.0192]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.0192]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.24it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.24it/s, train_loss=0.1]   \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.97it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.97it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.92it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.92it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.69it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.69it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.78it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.78it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:20,  4.62it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:20,  4.62it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.73it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.73it/s, train_loss=0.221] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:19,  4.64it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:19,  4.64it/s, train_loss=0.00895]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.93it/s, train_loss=0.00895]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.93it/s, train_loss=0.161]  \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.81it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.81it/s, train_loss=0.0864]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.87it/s, train_loss=0.0864]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.87it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.83it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:18,  4.83it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.74it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.74it/s, train_loss=0.00596]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.87it/s, train_loss=0.00596]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.87it/s, train_loss=0.0261] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.79it/s, train_loss=0.0261]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.79it/s, train_loss=0.219] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.84it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.84it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.01it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.01it/s, train_loss=0.24] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.15it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.15it/s, train_loss=0.0221]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.03it/s, train_loss=0.0221]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.03it/s, train_loss=0.00568]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.00568]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.149]  \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.93it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.93it/s, train_loss=0.0974]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.91it/s, train_loss=0.0974]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  4.91it/s, train_loss=0.0621]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.74it/s, train_loss=0.0621]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.74it/s, train_loss=0.0139]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:16,  4.71it/s, train_loss=0.0139]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:16,  4.71it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.83it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.83it/s, train_loss=0.289] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.88it/s, train_loss=0.289]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.88it/s, train_loss=0.0468]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.00it/s, train_loss=0.0468]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  5.00it/s, train_loss=0.046] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.21it/s, train_loss=0.046]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.21it/s, train_loss=0.0571]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.15it/s, train_loss=0.0571]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.15it/s, train_loss=0.0816]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.08it/s, train_loss=0.0816]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.08it/s, train_loss=0.23]  \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.14it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.23it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.23it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.10it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.10it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.92it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.92it/s, train_loss=0.0171]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.14it/s, train_loss=0.0171]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.14it/s, train_loss=0.0178]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.0178]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.0476]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.11it/s, train_loss=0.0476]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.11it/s, train_loss=0.0828]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.02it/s, train_loss=0.0828]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.02it/s, train_loss=0.029] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.01it/s, train_loss=0.029]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.01it/s, train_loss=0.051]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.14it/s, train_loss=0.051]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.14it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.15it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.15it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.78it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:12,  4.78it/s, train_loss=0.292] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.94it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.94it/s, train_loss=0.0333]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.02it/s, train_loss=0.0333]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.02it/s, train_loss=0.0888]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.97it/s, train_loss=0.0888]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.97it/s, train_loss=0.313] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.02it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.02it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.00it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.00it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.04it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.04it/s, train_loss=0.00932]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.14it/s, train_loss=0.00932]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.14it/s, train_loss=0.0534] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.88it/s, train_loss=0.0534]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.88it/s, train_loss=0.0947]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.93it/s, train_loss=0.0947]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.93it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.95it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  4.95it/s, train_loss=0.115] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.02it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.02it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.20it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.20it/s, train_loss=0.214] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.16it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.16it/s, train_loss=0.0798]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.13it/s, train_loss=0.0798]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.13it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.05it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.05it/s, train_loss=0.252] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.13it/s, train_loss=0.252]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.13it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.00it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.00it/s, train_loss=0.0124]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.98it/s, train_loss=0.0124]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.98it/s, train_loss=0.0346]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.05it/s, train_loss=0.0346]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.05it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.04it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.04it/s, train_loss=0.146] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.99it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.99it/s, train_loss=0.0472]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.02it/s, train_loss=0.0472]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.02it/s, train_loss=0.0164]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.97it/s, train_loss=0.0164]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.97it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.23it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.23it/s, train_loss=0.032] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.98it/s, train_loss=0.032]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.98it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.84it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.84it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.86it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.86it/s, train_loss=0.42] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.79it/s, train_loss=0.42]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.79it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.78it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.78it/s, train_loss=0.447] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.86it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.86it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.90it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.90it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.03it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.03it/s, train_loss=0.0427]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.22it/s, train_loss=0.0427]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.22it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.96it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.96it/s, train_loss=0.0958]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.08it/s, train_loss=0.0958]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.08it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.12it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.12it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.23it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.23it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.14it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.14it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.88it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.88it/s, train_loss=0.186] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.90it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.90it/s, train_loss=0.0266]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.05it/s, train_loss=0.0266]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.05it/s, train_loss=0.102] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.04it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.04it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.22it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.22it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.15it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.15it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.24it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.24it/s, train_loss=0.107] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.07it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.07it/s, train_loss=0.00829]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.15it/s, train_loss=0.00829]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.15it/s, train_loss=0.292]  \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.93it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.93it/s, train_loss=0.12] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.26it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.26it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.10it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.10it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.03it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.03it/s, train_loss=0.00806]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.85it/s, train_loss=0.00806]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.85it/s, train_loss=0.0106] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.71it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.71it/s, train_loss=0.173] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.81it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.81it/s, train_loss=0.0563]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.12it/s, train_loss=0.0563]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.12it/s, train_loss=0.0989]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.04it/s, train_loss=0.0989]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.04it/s, train_loss=0.00537]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=0.00537]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.08it/s, train_loss=0.119]  \n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83 average loss: 0.0873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  75%|███████▌  | 83/110 [34:27<11:10, 24.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 83 current AUC: 0.9905 current accuracy: 0.8758 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 84/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0144]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  5.02it/s, train_loss=0.0144]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  5.02it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.91it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.91it/s, train_loss=0.026] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.85it/s, train_loss=0.026]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.85it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.17it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:22,  5.17it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.85it/s, train_loss=0.244] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.86it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.86it/s, train_loss=0.0887]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.06it/s, train_loss=0.0887]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.06it/s, train_loss=0.016] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.01it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.01it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.06it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.06it/s, train_loss=0.04] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.08it/s, train_loss=0.04]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.08it/s, train_loss=0.0301]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.91it/s, train_loss=0.0301]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.91it/s, train_loss=0.0521]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.83it/s, train_loss=0.0521]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.83it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.02it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.02it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.90it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.90it/s, train_loss=0.342] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.95it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.95it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.85it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.85it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.86it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.86it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.87it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.87it/s, train_loss=0.0204]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.98it/s, train_loss=0.0204]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  4.98it/s, train_loss=0.166] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.24it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.24it/s, train_loss=0.029]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.17it/s, train_loss=0.029]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.17it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.02it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.02it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.20it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.20it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.10it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:19,  5.10it/s, train_loss=0.149] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.02it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.02it/s, train_loss=0.0603]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.87it/s, train_loss=0.0603]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.87it/s, train_loss=0.0499]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.94it/s, train_loss=0.0499]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.94it/s, train_loss=0.0914]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.02it/s, train_loss=0.0914]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.02it/s, train_loss=0.199] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.95it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  4.95it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.98it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.98it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.94it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.94it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.99it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.99it/s, train_loss=0.0375]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.84it/s, train_loss=0.0375]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.84it/s, train_loss=0.0284]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.77it/s, train_loss=0.0284]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:18,  4.77it/s, train_loss=0.0409]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.90it/s, train_loss=0.0409]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.90it/s, train_loss=0.1]   \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.86it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.86it/s, train_loss=0.0316]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.07it/s, train_loss=0.0316]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.07it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.09it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.09it/s, train_loss=0.228] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.32it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:15,  5.32it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.21it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.21it/s, train_loss=0.0198]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.15it/s, train_loss=0.0198]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.15it/s, train_loss=0.0877]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.98it/s, train_loss=0.0877]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.98it/s, train_loss=0.303] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.11it/s, train_loss=0.303]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.11it/s, train_loss=0.0637]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.35it/s, train_loss=0.0637]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.35it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.45it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.45it/s, train_loss=0.126] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.19it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.19it/s, train_loss=0.086]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.21it/s, train_loss=0.086]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.21it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.07it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.07it/s, train_loss=0.162] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.11it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.11it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.01it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.01it/s, train_loss=0.133] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.95it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.95it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.88it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.88it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.91it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.91it/s, train_loss=0.0967]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.05it/s, train_loss=0.0967]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.05it/s, train_loss=0.00759]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.03it/s, train_loss=0.00759]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.03it/s, train_loss=0.0447] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.02it/s, train_loss=0.0447]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.02it/s, train_loss=0.108] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.92it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.92it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.02it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.02it/s, train_loss=0.043] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.03it/s, train_loss=0.043]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.03it/s, train_loss=0.0763]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.24it/s, train_loss=0.0763]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.24it/s, train_loss=0.0935]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.15it/s, train_loss=0.0935]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.15it/s, train_loss=0.00389]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.96it/s, train_loss=0.00389]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.96it/s, train_loss=0.0781] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.09it/s, train_loss=0.0781]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.09it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.24it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.24it/s, train_loss=0.0571]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.08it/s, train_loss=0.0571]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.08it/s, train_loss=0.104] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.94it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.94it/s, train_loss=0.0047]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  5.00it/s, train_loss=0.0047]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  5.00it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.85it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.85it/s, train_loss=0.00477]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.76it/s, train_loss=0.00477]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.76it/s, train_loss=0.089]  \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.88it/s, train_loss=0.089]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.88it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.96it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.96it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.02it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.02it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.20it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.20it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.11it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.11it/s, train_loss=0.0529]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.01it/s, train_loss=0.0529]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.01it/s, train_loss=0.0158]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.34it/s, train_loss=0.0158]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.34it/s, train_loss=0.0728]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.36it/s, train_loss=0.0728]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.36it/s, train_loss=0.136] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.16it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.16it/s, train_loss=0.00922]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.00922]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.512]  \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.12it/s, train_loss=0.512]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.12it/s, train_loss=0.0547]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.21it/s, train_loss=0.0547]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.21it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.15it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.15it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.98it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.98it/s, train_loss=0.0614]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.09it/s, train_loss=0.0614]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.09it/s, train_loss=0.00351]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.82it/s, train_loss=0.00351]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.82it/s, train_loss=0.13]   \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.08it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.08it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.93it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.93it/s, train_loss=0.00422]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.69it/s, train_loss=0.00422]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.69it/s, train_loss=0.477]  \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.74it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.74it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.92it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.92it/s, train_loss=0.036] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.84it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.84it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.02it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.02it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.85it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.85it/s, train_loss=0.0907]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.96it/s, train_loss=0.0907]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.96it/s, train_loss=0.427] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.94it/s, train_loss=0.427]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.94it/s, train_loss=0.00452]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.10it/s, train_loss=0.00452]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.10it/s, train_loss=0.0975] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.16it/s, train_loss=0.0975]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.16it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.97it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.97it/s, train_loss=0.149] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.22it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.22it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.13it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.13it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.27it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.27it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.30it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.30it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.21it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.21it/s, train_loss=0.164] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.89it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.89it/s, train_loss=0.00624]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.00it/s, train_loss=0.00624]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.00it/s, train_loss=0.0538] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.16it/s, train_loss=0.0538]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.16it/s, train_loss=0.0694]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.16it/s, train_loss=0.0694]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.16it/s, train_loss=0.133] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.09it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.09it/s, train_loss=0.0908]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.83it/s, train_loss=0.0908]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.83it/s, train_loss=0.352] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.05it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.05it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.24it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.24it/s, train_loss=0.0759]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.13it/s, train_loss=0.0759]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.13it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.04it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.04it/s, train_loss=0.0687]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.0687]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.0955]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.02it/s, train_loss=0.0955]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.02it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.97it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.97it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.82it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.82it/s, train_loss=0.016] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.97it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.97it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.12it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.12it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.20it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.20it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.07it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.07it/s, train_loss=0.0699]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.86it/s, train_loss=0.0699]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84 average loss: 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  76%|███████▋  | 84/110 [34:52<10:45, 24.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 84 current AUC: 0.9950 current accuracy: 0.9130 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 85/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0243]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.29it/s, train_loss=0.0243]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.29it/s, train_loss=0.0862]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.0862]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.0038]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.88it/s, train_loss=0.0038]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.88it/s, train_loss=0.227] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.87it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.87it/s, train_loss=0.088]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.81it/s, train_loss=0.088]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.81it/s, train_loss=0.0157]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.83it/s, train_loss=0.0157]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.83it/s, train_loss=0.0926]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.04it/s, train_loss=0.0926]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.04it/s, train_loss=0.11]  \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.86it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.86it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.82it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.82it/s, train_loss=0.00495]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.05it/s, train_loss=0.00495]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.05it/s, train_loss=0.0289] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.83it/s, train_loss=0.0289]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.83it/s, train_loss=0.0509]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.82it/s, train_loss=0.0509]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.82it/s, train_loss=0.199] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.15it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.15it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.20it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.20it/s, train_loss=0.036] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.20it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.20it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.18it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.18it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.08it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.08it/s, train_loss=0.0737]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.20it/s, train_loss=0.0737]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.20it/s, train_loss=0.112] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.24it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.24it/s, train_loss=0.0445]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.16it/s, train_loss=0.0445]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.16it/s, train_loss=0.0815]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.01it/s, train_loss=0.0815]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.01it/s, train_loss=0.349] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.05it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.05it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.08it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.08it/s, train_loss=0.016] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.97it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.97it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.88it/s, train_loss=0.0873]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.88it/s, train_loss=0.0476]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.79it/s, train_loss=0.0476]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.79it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.04it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.04it/s, train_loss=0.115] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.19it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.19it/s, train_loss=0.00703]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.16it/s, train_loss=0.00703]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.16it/s, train_loss=0.0667] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.09it/s, train_loss=0.0667]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.09it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.05it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.05it/s, train_loss=0.126] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.04it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.04it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.08it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.08it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.08it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.08it/s, train_loss=0.123] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.91it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.91it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.96it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.96it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.12it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.12it/s, train_loss=0.0937]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.15it/s, train_loss=0.0937]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.15it/s, train_loss=0.283] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.18it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.18it/s, train_loss=0.343] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.38it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.38it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:14,  5.38it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:14,  5.38it/s, train_loss=0.234] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.20it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.20it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.08it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.08it/s, train_loss=0.164] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.04it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.04it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.08it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.08it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.17it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.17it/s, train_loss=0.00301]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.17it/s, train_loss=0.00301]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.17it/s, train_loss=0.2]    \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.14it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.14it/s, train_loss=0.0524]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.06it/s, train_loss=0.0524]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.06it/s, train_loss=0.0751]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.15it/s, train_loss=0.0751]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.15it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.03it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.03it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.20it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.20it/s, train_loss=0.161] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.06it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.06it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.05it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.05it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.02it/s, train_loss=0.537]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.02it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.06it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.06it/s, train_loss=0.0944]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.04it/s, train_loss=0.0944]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.04it/s, train_loss=0.0856]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.0856]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.00654]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.02it/s, train_loss=0.00654]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.02it/s, train_loss=0.141]  \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.04it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.04it/s, train_loss=0.0353]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.10it/s, train_loss=0.0353]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.10it/s, train_loss=0.0756]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.23it/s, train_loss=0.0756]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.23it/s, train_loss=0.465] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.09it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.09it/s, train_loss=0.048]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.14it/s, train_loss=0.048]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.14it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.97it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.97it/s, train_loss=0.145] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.84it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.84it/s, train_loss=0.00899]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.86it/s, train_loss=0.00899]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.86it/s, train_loss=0.0526] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.01it/s, train_loss=0.0526]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.01it/s, train_loss=0.11]  \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.10it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.10it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.03it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.03it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.24it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.24it/s, train_loss=0.0922]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.10it/s, train_loss=0.0922]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.10it/s, train_loss=0.0542]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.19it/s, train_loss=0.0542]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.19it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.42it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.42it/s, train_loss=0.0593]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.39it/s, train_loss=0.0593]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.39it/s, train_loss=0.235] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.50it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.50it/s, train_loss=0.047]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.26it/s, train_loss=0.047]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.26it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.16it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.16it/s, train_loss=0.0977]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.06it/s, train_loss=0.0977]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.06it/s, train_loss=0.0411]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.01it/s, train_loss=0.0411]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.01it/s, train_loss=0.0916]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.11it/s, train_loss=0.0916]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.11it/s, train_loss=0.229] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.10it/s, train_loss=0.229]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.10it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.01it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.01it/s, train_loss=0.634]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.93it/s, train_loss=0.634]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.93it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  4.70it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.70it/s, train_loss=0.0495]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.78it/s, train_loss=0.0495]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.78it/s, train_loss=0.0807]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.91it/s, train_loss=0.0807]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.91it/s, train_loss=0.0964]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.94it/s, train_loss=0.0964]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.94it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.07it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.07it/s, train_loss=0.273] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.22it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.22it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.92it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.92it/s, train_loss=0.024]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.86it/s, train_loss=0.024]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.86it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.86it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.86it/s, train_loss=0.00642]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.83it/s, train_loss=0.00642]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.83it/s, train_loss=0.0436] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.76it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.76it/s, train_loss=0.00637]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.98it/s, train_loss=0.00637]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.98it/s, train_loss=0.0633] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.0633]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.0268]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.29it/s, train_loss=0.0268]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.29it/s, train_loss=0.0258]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.20it/s, train_loss=0.0258]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.20it/s, train_loss=0.313] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.03it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.03it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.99it/s, train_loss=0.529]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.99it/s, train_loss=0.0442]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.94it/s, train_loss=0.0442]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.94it/s, train_loss=0.0776]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.96it/s, train_loss=0.0776]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.96it/s, train_loss=0.0659]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.92it/s, train_loss=0.0659]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.92it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.80it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.80it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.79it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.79it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.94it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.94it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.78it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.78it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.80it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.80it/s, train_loss=0.0978]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.88it/s, train_loss=0.0978]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.88it/s, train_loss=0.0608]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.66it/s, train_loss=0.0608]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.66it/s, train_loss=0.0846]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.81it/s, train_loss=0.0846]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.81it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.05it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.05it/s, train_loss=0.48]  \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.01it/s, train_loss=0.48]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.01it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.01it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.01it/s, train_loss=0.212] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.96it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.96it/s, train_loss=0.0945]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.17it/s, train_loss=0.0945]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.17it/s, train_loss=0.0521]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.26it/s, train_loss=0.0521]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.26it/s, train_loss=0.00489]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.13it/s, train_loss=0.00489]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.13it/s, train_loss=0.0181] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.15it/s, train_loss=0.0181]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.15it/s, train_loss=0.339] \n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85 average loss: 0.1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  77%|███████▋  | 85/110 [35:16<10:19, 24.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 85 current AUC: 0.9884 current accuracy: 0.8447 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 86/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.90it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.90it/s, train_loss=0.00421]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.97it/s, train_loss=0.00421]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.97it/s, train_loss=0.238]  \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.06it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.06it/s, train_loss=0.0253]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.22it/s, train_loss=0.0253]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.22it/s, train_loss=0.0732]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.15it/s, train_loss=0.0732]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.15it/s, train_loss=0.0941]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.96it/s, train_loss=0.0941]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.96it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.82it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.82it/s, train_loss=0.34]  \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.93it/s, train_loss=0.34]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.93it/s, train_loss=0.0307]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.91it/s, train_loss=0.0307]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.91it/s, train_loss=0.677] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.67it/s, train_loss=0.677]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.67it/s, train_loss=0.0163]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.77it/s, train_loss=0.0163]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:23,  4.77it/s, train_loss=0.0319]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.67it/s, train_loss=0.0319]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.67it/s, train_loss=0.0105]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.87it/s, train_loss=0.0105]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.87it/s, train_loss=0.033] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.03it/s, train_loss=0.033]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  5.03it/s, train_loss=0.0703]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.10it/s, train_loss=0.0703]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.10it/s, train_loss=0.0963]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.94it/s, train_loss=0.0963]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.94it/s, train_loss=0.125] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.09it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.09it/s, train_loss=0.0337]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.22it/s, train_loss=0.0337]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.22it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.15it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.15it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.20it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.20it/s, train_loss=0.064] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.04it/s, train_loss=0.064]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.04it/s, train_loss=0.0327]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.21it/s, train_loss=0.0327]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.21it/s, train_loss=0.0607]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.33it/s, train_loss=0.0607]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.33it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.29it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.29it/s, train_loss=0.00892]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.29it/s, train_loss=0.00892]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.29it/s, train_loss=0.468]  \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.22it/s, train_loss=0.468]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.22it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.30it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.30it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.05it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.05it/s, train_loss=0.011] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.94it/s, train_loss=0.011]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.94it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.05it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.05it/s, train_loss=0.039] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.84it/s, train_loss=0.039]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.84it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.99it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.99it/s, train_loss=0.14] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.93it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.93it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.23it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.23it/s, train_loss=0.358] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.93it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.93it/s, train_loss=0.00971]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.89it/s, train_loss=0.00971]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.89it/s, train_loss=0.0275] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.08it/s, train_loss=0.0275]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.08it/s, train_loss=0.0453]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.07it/s, train_loss=0.0453]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.07it/s, train_loss=0.369] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.14it/s, train_loss=0.369]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.14it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.25it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.25it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.23it/s, train_loss=0.446]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.23it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.04it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.04it/s, train_loss=0.0775]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.80it/s, train_loss=0.0775]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.80it/s, train_loss=0.124] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.66it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.66it/s, train_loss=0.0524]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.87it/s, train_loss=0.0524]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.87it/s, train_loss=0.072] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.77it/s, train_loss=0.072]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.77it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.85it/s, train_loss=0.398]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.85it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.01it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.01it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.10it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.10it/s, train_loss=0.0793]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:15,  4.79it/s, train_loss=0.0793]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.79it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.83it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.83it/s, train_loss=0.052] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.90it/s, train_loss=0.052]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.90it/s, train_loss=0.0882]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.99it/s, train_loss=0.0882]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.99it/s, train_loss=0.249] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.11it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.11it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.10it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.10it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.14it/s, train_loss=0.293]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.14it/s, train_loss=0.0843]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.89it/s, train_loss=0.0843]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.89it/s, train_loss=0.155] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.12it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.12it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.04it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.04it/s, train_loss=0.24]  \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.93it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.93it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.92it/s, train_loss=0.21]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.92it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.95it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.95it/s, train_loss=0.12] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.16it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.16it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.24it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.24it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.00it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.00it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.05it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.05it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.07it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.07it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.08it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.08it/s, train_loss=0.0656]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.16it/s, train_loss=0.0656]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.16it/s, train_loss=0.0344]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.07it/s, train_loss=0.0344]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.07it/s, train_loss=0.265] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.11it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.11it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.12it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.12it/s, train_loss=0.065]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.24it/s, train_loss=0.065]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.24it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.23it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.23it/s, train_loss=0.327] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.16it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.16it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.25it/s, train_loss=0.267]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.25it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.91it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.91it/s, train_loss=0.0355]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.83it/s, train_loss=0.0355]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.83it/s, train_loss=0.203] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.81it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.81it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.01it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.01it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.05it/s, train_loss=0.079] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.19it/s, train_loss=0.079]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.19it/s, train_loss=0.0807]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.02it/s, train_loss=0.0807]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.02it/s, train_loss=0.0108]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.25it/s, train_loss=0.0108]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.25it/s, train_loss=0.0385]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.40it/s, train_loss=0.0385]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:06,  5.40it/s, train_loss=0.153] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.00it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.00it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.88it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.88it/s, train_loss=0.0473]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.13it/s, train_loss=0.0473]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.13it/s, train_loss=0.126] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.02it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.02it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.15it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.15it/s, train_loss=0.06]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.00it/s, train_loss=0.06]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.00it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.95it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.95it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.92it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.92it/s, train_loss=0.0501]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.76it/s, train_loss=0.0501]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.76it/s, train_loss=0.356] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.83it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.83it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.96it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.96it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.83it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.83it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.77it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.77it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.68it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.68it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.81it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.81it/s, train_loss=0.0498]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.93it/s, train_loss=0.0498]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.93it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.01it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.01it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.28it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.28it/s, train_loss=0.039] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.39it/s, train_loss=0.039]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.39it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.21it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.21it/s, train_loss=0.0894]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.86it/s, train_loss=0.0894]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.86it/s, train_loss=0.058] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.02it/s, train_loss=0.058]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.02it/s, train_loss=0.00869]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.83it/s, train_loss=0.00869]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.83it/s, train_loss=0.112]  \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.73it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.73it/s, train_loss=0.04] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.79it/s, train_loss=0.04]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.79it/s, train_loss=0.0496]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.85it/s, train_loss=0.0496]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.85it/s, train_loss=0.0486]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.0486]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.0445]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=0.0445]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.23it/s, train_loss=0.127] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.16it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.16it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.01it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.01it/s, train_loss=0.311] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.96it/s, train_loss=0.311]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.96it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.66it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.66it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.91it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.91it/s, train_loss=0.043] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.01it/s, train_loss=0.043]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.01it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.21it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.21it/s, train_loss=0.0305]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.18it/s, train_loss=0.0305]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.18it/s, train_loss=0.00649]\n",
      "\u001b[A                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86 average loss: 0.1204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  78%|███████▊  | 86/110 [35:41<09:55, 24.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 86 current AUC: 0.9963 current accuracy: 0.9130 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 87/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.09it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.09it/s, train_loss=0.0662]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.13it/s, train_loss=0.0662]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.13it/s, train_loss=0.077] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.18it/s, train_loss=0.077]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.18it/s, train_loss=0.057]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.33it/s, train_loss=0.057]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.33it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:21,  5.45it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:21,  5.45it/s, train_loss=0.365] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.24it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.24it/s, train_loss=0.0728]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.06it/s, train_loss=0.0728]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.06it/s, train_loss=0.0651]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.0651]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.0245]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.95it/s, train_loss=0.0245]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.95it/s, train_loss=0.203] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:23,  4.85it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.85it/s, train_loss=0.0891]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.04it/s, train_loss=0.0891]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.04it/s, train_loss=0.00798]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=0.00798]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.96it/s, train_loss=0.101]  \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:23,  4.70it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:23,  4.70it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.73it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.73it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.86it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.86it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.90it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.90it/s, train_loss=0.0574]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.19it/s, train_loss=0.0574]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.19it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.20it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.20it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.38it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.38it/s, train_loss=0.269] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.21it/s, train_loss=0.269]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.21it/s, train_loss=0.0321]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.13it/s, train_loss=0.0321]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.13it/s, train_loss=0.198] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.13it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.13it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.06it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.06it/s, train_loss=0.0587]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.04it/s, train_loss=0.0587]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.04it/s, train_loss=0.0787]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.85it/s, train_loss=0.0787]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.85it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.98it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.98it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.08it/s, train_loss=0.346] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.27it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.27it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.20it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.20it/s, train_loss=0.0498]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.99it/s, train_loss=0.0498]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.99it/s, train_loss=0.173] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.89it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.89it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.86it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.86it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.71it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.71it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.93it/s, train_loss=0.374]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.93it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.95it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.95it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.99it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.99it/s, train_loss=0.525] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.05it/s, train_loss=0.525]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.05it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.75it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.75it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.80it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:17,  4.80it/s, train_loss=0.0932]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.80it/s, train_loss=0.0932]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.80it/s, train_loss=0.482] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:17,  4.75it/s, train_loss=0.482]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:17,  4.75it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.91it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.91it/s, train_loss=0.182] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.88it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.88it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.93it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  4.93it/s, train_loss=0.0757]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.00it/s, train_loss=0.0757]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.00it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.95it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.95it/s, train_loss=0.00333]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.96it/s, train_loss=0.00333]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.96it/s, train_loss=0.00633]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.05it/s, train_loss=0.00633]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.05it/s, train_loss=0.12]   \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.03it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  5.03it/s, train_loss=0.0595]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.97it/s, train_loss=0.0595]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.97it/s, train_loss=0.0973]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.89it/s, train_loss=0.0973]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.89it/s, train_loss=0.321] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.83it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.83it/s, train_loss=0.0389]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.90it/s, train_loss=0.0389]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.90it/s, train_loss=0.00746]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.85it/s, train_loss=0.00746]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:14,  4.85it/s, train_loss=0.00655]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.86it/s, train_loss=0.00655]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.86it/s, train_loss=0.039]  \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.80it/s, train_loss=0.039]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.80it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.02it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.02it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.85it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.85it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.87it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  4.87it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.05it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.05it/s, train_loss=0.0455]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.13it/s, train_loss=0.0455]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.13it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.08it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.08it/s, train_loss=0.0483]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.27it/s, train_loss=0.0483]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.27it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.06it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  5.06it/s, train_loss=0.0414]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.13it/s, train_loss=0.0414]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.13it/s, train_loss=0.0635]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.11it/s, train_loss=0.0635]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.11it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.07it/s, train_loss=0.0884]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.07it/s, train_loss=0.0926]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.04it/s, train_loss=0.0926]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.04it/s, train_loss=0.51]  \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.99it/s, train_loss=0.51]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  4.99it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.06it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.06it/s, train_loss=0.00324]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.17it/s, train_loss=0.00324]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.17it/s, train_loss=0.0222] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.15it/s, train_loss=0.0222]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.15it/s, train_loss=0.156] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.91it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.91it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.18it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  5.18it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.92it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.92it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.97it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.97it/s, train_loss=0.0894]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.03it/s, train_loss=0.0894]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.03it/s, train_loss=0.0461]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.08it/s, train_loss=0.0461]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.08it/s, train_loss=0.331] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.43] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.02it/s, train_loss=0.43]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.02it/s, train_loss=0.0738]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.08it/s, train_loss=0.0738]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.08it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.31it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.31it/s, train_loss=0.0563]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.29it/s, train_loss=0.0563]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.29it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.27it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.27it/s, train_loss=0.349] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.25it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.25it/s, train_loss=0.12] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.04it/s, train_loss=0.12]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.04it/s, train_loss=0.0337]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.98it/s, train_loss=0.0337]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.98it/s, train_loss=0.0417]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.08it/s, train_loss=0.0417]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.08it/s, train_loss=0.327] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.91it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.91it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.01it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.01it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.10it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.10it/s, train_loss=0.0366]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.01it/s, train_loss=0.0366]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.01it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.95it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.95it/s, train_loss=0.177] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.03it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.03it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.99it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.99it/s, train_loss=0.0719]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.02it/s, train_loss=0.0719]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.02it/s, train_loss=0.145] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.11it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.11it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.12it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.12it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.04it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.04it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.03it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.03it/s, train_loss=0.515] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.98it/s, train_loss=0.515]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.98it/s, train_loss=0.0134]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.90it/s, train_loss=0.0134]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.90it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.01it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.01it/s, train_loss=0.0301]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.04it/s, train_loss=0.0301]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.04it/s, train_loss=0.195] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.03it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.03it/s, train_loss=0.0368]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.95it/s, train_loss=0.0368]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.95it/s, train_loss=0.0484]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.88it/s, train_loss=0.0484]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.88it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.85it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.85it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.88it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.88it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.01it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.01it/s, train_loss=0.136] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.08it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.08it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.02it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.02it/s, train_loss=0.0081]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.16it/s, train_loss=0.0081]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.16it/s, train_loss=0.112] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.13it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.13it/s, train_loss=0.0623]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.05it/s, train_loss=0.0623]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.05it/s, train_loss=0.28]  \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.05it/s, train_loss=0.28]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.05it/s, train_loss=0.0845]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.13it/s, train_loss=0.0845]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.13it/s, train_loss=0.00821]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=0.00821]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=0.146]  \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.11it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.11it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.09it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.09it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.00it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.00it/s, train_loss=0.0724]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87 average loss: 0.1081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  79%|███████▉  | 87/110 [36:06<09:30, 24.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 87 current AUC: 0.9915 current accuracy: 0.8820 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 88/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0485]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.75it/s, train_loss=0.0485]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.75it/s, train_loss=0.242] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.84it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.84it/s, train_loss=0.00967]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.78it/s, train_loss=0.00967]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.78it/s, train_loss=0.157]  \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.97it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  4.97it/s, train_loss=0.066]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.02it/s, train_loss=0.066]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.02it/s, train_loss=0.0663]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.90it/s, train_loss=0.0663]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.90it/s, train_loss=0.207] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.91it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.91it/s, train_loss=0.0499]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.04it/s, train_loss=0.0499]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.04it/s, train_loss=0.0536]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.88it/s, train_loss=0.0536]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.88it/s, train_loss=0.0144]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.96it/s, train_loss=0.0144]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.96it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.08it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.08it/s, train_loss=0.497] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.04it/s, train_loss=0.497]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.04it/s, train_loss=0.032]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.05it/s, train_loss=0.032]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.05it/s, train_loss=0.00804]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.08it/s, train_loss=0.00804]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  5.08it/s, train_loss=0.088]  \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.08it/s, train_loss=0.088]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.08it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.95it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.95it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.94it/s, train_loss=0.329]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.94it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.96it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.96it/s, train_loss=0.0757]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.00it/s, train_loss=0.0757]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  5.00it/s, train_loss=0.296] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.97it/s, train_loss=0.296]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.97it/s, train_loss=0.0818]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.0818]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.385] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.03it/s, train_loss=0.385]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.03it/s, train_loss=0.026]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.89it/s, train_loss=0.026]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.89it/s, train_loss=0.089]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.89it/s, train_loss=0.089]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:20,  4.89it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.97it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.97it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.84it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.84it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:20,  4.63it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:20,  4.63it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:20,  4.63it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:20,  4.63it/s, train_loss=0.133] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.82it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:19,  4.82it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.01it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.01it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.15it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.15it/s, train_loss=0.0166]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.14it/s, train_loss=0.0166]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.14it/s, train_loss=0.0355]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.03it/s, train_loss=0.0355]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.03it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.97it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  4.97it/s, train_loss=0.0845]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.00it/s, train_loss=0.0845]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.00it/s, train_loss=0.241] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.13it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.13it/s, train_loss=0.0221]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.03it/s, train_loss=0.0221]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.03it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.00it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.00it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.15it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:16,  5.15it/s, train_loss=0.035]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.98it/s, train_loss=0.035]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.98it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.17it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.17it/s, train_loss=0.0529]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.15it/s, train_loss=0.0529]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.15it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.95it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.95it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.03it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  5.03it/s, train_loss=0.0869]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.99it/s, train_loss=0.0869]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.99it/s, train_loss=0.0662]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.92it/s, train_loss=0.0662]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.92it/s, train_loss=0.152] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.72it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.72it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.04it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.04it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.08it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  5.08it/s, train_loss=0.019] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.98it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.98it/s, train_loss=0.0413]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.86it/s, train_loss=0.0413]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.86it/s, train_loss=0.0499]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.81it/s, train_loss=0.0499]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.81it/s, train_loss=0.149] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.84it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.84it/s, train_loss=0.00225]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.02it/s, train_loss=0.00225]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  5.02it/s, train_loss=0.333]  \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.98it/s, train_loss=0.333]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.98it/s, train_loss=0.0883]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.08it/s, train_loss=0.0883]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.08it/s, train_loss=0.0241]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=0.0241]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.20it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.20it/s, train_loss=0.157] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.18it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  5.18it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.24it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.24it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.05it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.05it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.00it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.00it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.24it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.24it/s, train_loss=0.117] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.17it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.17it/s, train_loss=0.0315]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.15it/s, train_loss=0.0315]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.15it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.04it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.04it/s, train_loss=0.18]  \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.03it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.11it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.11it/s, train_loss=0.0611]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.93it/s, train_loss=0.0611]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.93it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.07it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.07it/s, train_loss=0.0994]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.93it/s, train_loss=0.0994]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.93it/s, train_loss=0.131] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.03it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.03it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.04it/s, train_loss=0.247]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.04it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.05it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  5.05it/s, train_loss=0.0606]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.99it/s, train_loss=0.0606]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.99it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.90it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.90it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.13it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.13it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.15it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.15it/s, train_loss=0.041]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.08it/s, train_loss=0.041]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:08,  5.08it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.91it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.91it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.82it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.82it/s, train_loss=0.00992]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.70it/s, train_loss=0.00992]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.70it/s, train_loss=0.336]  \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.73it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.73it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.94it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  4.94it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.18it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.18it/s, train_loss=0.0347]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.05it/s, train_loss=0.0347]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.05it/s, train_loss=0.283] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.11it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.11it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.19it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.19it/s, train_loss=0.452] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.38it/s, train_loss=0.452]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.38it/s, train_loss=0.0926]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.30it/s, train_loss=0.0926]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.30it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.20it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.20it/s, train_loss=0.156] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.25it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.25it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.19it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.19it/s, train_loss=0.25] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.47it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.47it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:04,  5.47it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:04,  5.47it/s, train_loss=0.0204]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.43it/s, train_loss=0.0204]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.43it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.45it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.45it/s, train_loss=0.0677]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.27it/s, train_loss=0.0677]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.27it/s, train_loss=0.0153]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.05it/s, train_loss=0.0153]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.05it/s, train_loss=0.0145]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.00it/s, train_loss=0.0145]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.00it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.05it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.05it/s, train_loss=0.205] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.94it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.94it/s, train_loss=0.07] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.18it/s, train_loss=0.07]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.18it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.12it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.12it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.11it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.11it/s, train_loss=0.0687]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.10it/s, train_loss=0.0687]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.10it/s, train_loss=0.00459]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.05it/s, train_loss=0.00459]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.05it/s, train_loss=0.0947] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.20it/s, train_loss=0.0947]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.20it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.03it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.03it/s, train_loss=0.221] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.67it/s, train_loss=0.221]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.67it/s, train_loss=0.061]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.81it/s, train_loss=0.061]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.81it/s, train_loss=0.0605]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.78it/s, train_loss=0.0605]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.78it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.74it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.74it/s, train_loss=0.0824]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.59it/s, train_loss=0.0824]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.59it/s, train_loss=0.376] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.70it/s, train_loss=0.376]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.70it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.98it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.98it/s, train_loss=0.0418]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.0418]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.024] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.05it/s, train_loss=0.024]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.05it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.95it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.95it/s, train_loss=0.188] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.95it/s, train_loss=0.188]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.95it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.87it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.87it/s, train_loss=0.0479]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88 average loss: 0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 88/110 [36:31<09:05, 24.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 88 current AUC: 0.9962 current accuracy: 0.9317 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 89/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.83it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.83it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.91it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.91it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.93it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.93it/s, train_loss=0.00738]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.75it/s, train_loss=0.00738]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.75it/s, train_loss=0.0161] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.96it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.96it/s, train_loss=0.0268]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.21it/s, train_loss=0.0268]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.21it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.21it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.21it/s, train_loss=0.151] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.95it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.95it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.16it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.16it/s, train_loss=0.181] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.15it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.15it/s, train_loss=0.0149]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.06it/s, train_loss=0.0149]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.06it/s, train_loss=0.0597]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.20it/s, train_loss=0.0597]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.20it/s, train_loss=0.0894]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.18it/s, train_loss=0.0894]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.18it/s, train_loss=0.424] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  4.95it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.95it/s, train_loss=0.00648]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.02it/s, train_loss=0.00648]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.02it/s, train_loss=0.0245] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.96it/s, train_loss=0.0245]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.96it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.95it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.95it/s, train_loss=0.00633]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.04it/s, train_loss=0.00633]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.04it/s, train_loss=0.104]  \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.91it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.91it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.06it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.06it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.27it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.27it/s, train_loss=0.292] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.14it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.14it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.31it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.31it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.13it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.13it/s, train_loss=0.012] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.09it/s, train_loss=0.012]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.09it/s, train_loss=0.0613]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.17it/s, train_loss=0.0613]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.17it/s, train_loss=0.0144]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.04it/s, train_loss=0.0144]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.04it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.96it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.96it/s, train_loss=0.0414]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.13it/s, train_loss=0.0414]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.13it/s, train_loss=0.0298]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.06it/s, train_loss=0.0298]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.06it/s, train_loss=0.0157]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.01it/s, train_loss=0.0157]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.01it/s, train_loss=0.0259]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.84it/s, train_loss=0.0259]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.84it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.98it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.98it/s, train_loss=0.336] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.01it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.01it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.25it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.25it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.14it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.14it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.94it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.94it/s, train_loss=0.15] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.97it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.97it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.88it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.88it/s, train_loss=0.0797]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.85it/s, train_loss=0.0797]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.85it/s, train_loss=0.0523]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.0523]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.02it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.02it/s, train_loss=0.052] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.88it/s, train_loss=0.052]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.88it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.88it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.88it/s, train_loss=0.0489]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.09it/s, train_loss=0.0489]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.09it/s, train_loss=0.149] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.20it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.20it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.09it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.09it/s, train_loss=0.0284]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.16it/s, train_loss=0.0284]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.16it/s, train_loss=0.0614]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.36it/s, train_loss=0.0614]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.36it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.35it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.35it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:12,  5.40it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:12,  5.40it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.13it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.13it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.10it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.10it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.04it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.04it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.95it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.95it/s, train_loss=0.0502]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.83it/s, train_loss=0.0502]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.83it/s, train_loss=0.555] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.73it/s, train_loss=0.555]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.73it/s, train_loss=0.0595]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.74it/s, train_loss=0.0595]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.74it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:13,  4.65it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:13,  4.65it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.79it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.79it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.76it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.76it/s, train_loss=0.00977]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.97it/s, train_loss=0.00977]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.97it/s, train_loss=0.299]  \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.99it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.99it/s, train_loss=0.0708]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.98it/s, train_loss=0.0708]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.98it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.10it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.10it/s, train_loss=0.439]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.16it/s, train_loss=0.439]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.16it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.99it/s, train_loss=0.266]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.99it/s, train_loss=0.013]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.02it/s, train_loss=0.013]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.02it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.75it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.75it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.95it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.95it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.06it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.06it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.05it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.05it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.19it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.19it/s, train_loss=0.0535]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.15it/s, train_loss=0.0535]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.15it/s, train_loss=0.114] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.92it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.92it/s, train_loss=0.0944]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.90it/s, train_loss=0.0944]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.90it/s, train_loss=0.0298]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.75it/s, train_loss=0.0298]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:09,  4.75it/s, train_loss=0.0234]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.85it/s, train_loss=0.0234]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.85it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.06it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.06it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.19it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.19it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.02it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.02it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.06it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.06it/s, train_loss=0.0724]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.09it/s, train_loss=0.0724]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.09it/s, train_loss=0.127] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.88it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.88it/s, train_loss=0.00505]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.00505]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.159]  \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.98it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.98it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.72it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.72it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.91it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.91it/s, train_loss=0.209] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.68it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.68it/s, train_loss=0.00482]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.90it/s, train_loss=0.00482]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.90it/s, train_loss=0.0405] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.91it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.91it/s, train_loss=0.0374]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.72it/s, train_loss=0.0374]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.72it/s, train_loss=0.0413]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.84it/s, train_loss=0.0413]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.84it/s, train_loss=0.307] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.88it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.88it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.067] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.17it/s, train_loss=0.067]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.17it/s, train_loss=0.731]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.05it/s, train_loss=0.731]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.05it/s, train_loss=0.00536]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.00it/s, train_loss=0.00536]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.00it/s, train_loss=0.0211] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.21it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.21it/s, train_loss=0.234] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.38it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.38it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.35it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.35it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.19it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.19it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.20it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.20it/s, train_loss=0.00737]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.98it/s, train_loss=0.00737]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.98it/s, train_loss=0.0906] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.81it/s, train_loss=0.0906]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.81it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=0.0792]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.75it/s, train_loss=0.0792]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  4.75it/s, train_loss=0.0171]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.68it/s, train_loss=0.0171]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.68it/s, train_loss=0.114] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.76it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.76it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.72it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.72it/s, train_loss=0.143] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.99it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.99it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.27it/s, train_loss=0.337]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.27it/s, train_loss=0.0591]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.18it/s, train_loss=0.0591]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.18it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.08it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.08it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.13it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.13it/s, train_loss=0.145] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.95it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.95it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.85it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.85it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.00it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.00it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.11it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.11it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.90it/s, train_loss=0.132]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89 average loss: 0.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  81%|████████  | 89/110 [36:56<08:41, 24.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 89 current AUC: 0.9881 current accuracy: 0.8820 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 90/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.74it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.74it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.33it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.33it/s, train_loss=0.057] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.03it/s, train_loss=0.057]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.03it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.15it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.15it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.20it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.20it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.16it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.16it/s, train_loss=0.171] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.15it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.15it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.00758]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.01it/s, train_loss=0.00758]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.01it/s, train_loss=0.0836] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.16it/s, train_loss=0.0836]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.16it/s, train_loss=0.158] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.15it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.15it/s, train_loss=0.0488]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.32it/s, train_loss=0.0488]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.32it/s, train_loss=0.164] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.30it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.30it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.35it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.35it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:19,  5.38it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:19,  5.38it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.49it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.49it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.36it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.36it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.28it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.28it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.40it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.40it/s, train_loss=0.0352]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.26it/s, train_loss=0.0352]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.26it/s, train_loss=0.0556]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.18it/s, train_loss=0.0556]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.18it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.74it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.74it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.76it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.76it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.84it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.84it/s, train_loss=0.0262]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.85it/s, train_loss=0.0262]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.85it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.76it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.76it/s, train_loss=0.0418]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.76it/s, train_loss=0.0418]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.76it/s, train_loss=0.132] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.08it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.08it/s, train_loss=0.39] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.10it/s, train_loss=0.39]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.10it/s, train_loss=0.055]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.29it/s, train_loss=0.055]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.29it/s, train_loss=0.457]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.18it/s, train_loss=0.457]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.18it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.26it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.26it/s, train_loss=0.127] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.22it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.22it/s, train_loss=0.00646]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.21it/s, train_loss=0.00646]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.21it/s, train_loss=0.0791] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.19it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.19it/s, train_loss=0.013] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.15it/s, train_loss=0.013]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.15it/s, train_loss=0.0137]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.18it/s, train_loss=0.0137]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.18it/s, train_loss=0.0265]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.07it/s, train_loss=0.0265]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.07it/s, train_loss=0.639] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.03it/s, train_loss=0.639]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.03it/s, train_loss=0.00853]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.93it/s, train_loss=0.00853]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.93it/s, train_loss=0.0731] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.89it/s, train_loss=0.0731]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.89it/s, train_loss=0.422] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.85it/s, train_loss=0.422]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.85it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.12it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.12it/s, train_loss=0.017] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.05it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.05it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.24it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.24it/s, train_loss=0.0108]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:14,  5.27it/s, train_loss=0.0108]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.27it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.09it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.09it/s, train_loss=0.015] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.06it/s, train_loss=0.015]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.06it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.23it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.23it/s, train_loss=0.0672]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.03it/s, train_loss=0.0672]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.03it/s, train_loss=0.0163]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:14,  5.05it/s, train_loss=0.0163]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  5.05it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  5.00it/s, train_loss=0.0432]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  5.00it/s, train_loss=0.31]  \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.86it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.86it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.01it/s, train_loss=0.387]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.01it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.85it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.85it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.88it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.88it/s, train_loss=0.00495]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.02it/s, train_loss=0.00495]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.02it/s, train_loss=0.0358] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.15it/s, train_loss=0.0358]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.15it/s, train_loss=0.00674]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.15it/s, train_loss=0.00674]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.15it/s, train_loss=0.0625] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.23it/s, train_loss=0.0625]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.23it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:11,  5.37it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.37it/s, train_loss=0.216] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.25it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.25it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.20it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.20it/s, train_loss=0.285] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.25it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.25it/s, train_loss=0.0956]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.18it/s, train_loss=0.0956]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.18it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.30it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.30it/s, train_loss=0.0495]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.32it/s, train_loss=0.0495]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.32it/s, train_loss=0.0897]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.12it/s, train_loss=0.0897]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.12it/s, train_loss=0.198] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.05it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.05it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.07it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.07it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  5.00it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.00it/s, train_loss=0.0257]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.01it/s, train_loss=0.0257]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.01it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.19it/s, train_loss=0.0133]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.19it/s, train_loss=0.358] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.90it/s, train_loss=0.358]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.90it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.04it/s, train_loss=0.316]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.04it/s, train_loss=0.0516]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  5.06it/s, train_loss=0.0516]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.06it/s, train_loss=0.232] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.29it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.29it/s, train_loss=0.015]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.12it/s, train_loss=0.015]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.12it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.28it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.28it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.08it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.08it/s, train_loss=0.383] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.85it/s, train_loss=0.383]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.85it/s, train_loss=0.0192]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.86it/s, train_loss=0.0192]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.86it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.97it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.97it/s, train_loss=0.16]  \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.12it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.12it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.14it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.14it/s, train_loss=0.123] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.06it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.06it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  5.00it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  5.00it/s, train_loss=0.0296]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.05it/s, train_loss=0.0296]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.05it/s, train_loss=0.034] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.85it/s, train_loss=0.034]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.85it/s, train_loss=0.0655]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.99it/s, train_loss=0.0655]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.99it/s, train_loss=0.0062]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.05it/s, train_loss=0.0062]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.05it/s, train_loss=0.163] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.03it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.03it/s, train_loss=0.0646]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.22it/s, train_loss=0.0646]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.22it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.37it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.37it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.33it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.33it/s, train_loss=0.0394]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:18<00:04,  5.27it/s, train_loss=0.0394]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.27it/s, train_loss=0.334] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.02it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.02it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.0667]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.94it/s, train_loss=0.0667]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.94it/s, train_loss=0.084] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.85it/s, train_loss=0.084]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.85it/s, train_loss=0.0157]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.01it/s, train_loss=0.0157]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.01it/s, train_loss=0.143] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.05it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.05it/s, train_loss=0.062]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.97it/s, train_loss=0.062]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.97it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.98it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.98it/s, train_loss=0.0178]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.06it/s, train_loss=0.0178]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.06it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.12it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.12it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.01it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.01it/s, train_loss=0.0145]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.10it/s, train_loss=0.0145]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.10it/s, train_loss=0.207] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.22it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.22it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.91it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.91it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.88it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.88it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.96it/s, train_loss=0.0917]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.96it/s, train_loss=0.102] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.95it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.95it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.84it/s, train_loss=0.256]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.84it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.93it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.93it/s, train_loss=0.0999]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.88it/s, train_loss=0.0999]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.88it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.99it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.99it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.76it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.76it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.69it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.69it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:23<00:00,  5.46it/s, train_loss=0.254]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90 average loss: 0.1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  82%|████████▏ | 90/110 [37:20<08:15, 24.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 90 current AUC: 0.9911 current accuracy: 0.8820 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 91/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.00671]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  6.03it/s, train_loss=0.00671]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  6.03it/s, train_loss=0.0549] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.46it/s, train_loss=0.0549]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.46it/s, train_loss=0.00702]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.25it/s, train_loss=0.00702]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.25it/s, train_loss=0.415]  \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.08it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.08it/s, train_loss=0.00991]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.10it/s, train_loss=0.00991]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.10it/s, train_loss=0.126]  \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.96it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.96it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.93it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.93it/s, train_loss=0.1]   \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.84it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.84it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.87it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.87it/s, train_loss=0.0614]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  4.93it/s, train_loss=0.0614]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.93it/s, train_loss=0.136] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.90it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.90it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.80it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.80it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.79it/s, train_loss=0.579]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.79it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.83it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.83it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.90it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.90it/s, train_loss=0.392] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.97it/s, train_loss=0.392]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.97it/s, train_loss=0.18] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.98it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.98it/s, train_loss=0.0872]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.94it/s, train_loss=0.0872]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.94it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.82it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:21,  4.82it/s, train_loss=0.154] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.91it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.91it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.09it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.09it/s, train_loss=0.29] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.18it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.18it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.24it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.24it/s, train_loss=0.065]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.03it/s, train_loss=0.065]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.03it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.14it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.14it/s, train_loss=0.206] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.16it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.16it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.98it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.98it/s, train_loss=0.106] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.05it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.05it/s, train_loss=0.0525]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.10it/s, train_loss=0.0525]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.10it/s, train_loss=0.406] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.18it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.18it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.18it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.18it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.31it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.31it/s, train_loss=0.00872]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.11it/s, train_loss=0.00872]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.11it/s, train_loss=0.174]  \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.74it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.74it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  4.90it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.90it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.21it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.21it/s, train_loss=0.0374]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.09it/s, train_loss=0.0374]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.09it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.10it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.10it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.10it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.10it/s, train_loss=0.0412]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.12it/s, train_loss=0.0412]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.12it/s, train_loss=0.0315]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.13it/s, train_loss=0.0315]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.13it/s, train_loss=0.026] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.99it/s, train_loss=0.026]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.99it/s, train_loss=0.0753]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.07it/s, train_loss=0.0753]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.07it/s, train_loss=0.103] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.84it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.84it/s, train_loss=0.0346]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.00it/s, train_loss=0.0346]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.00it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.84it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.84it/s, train_loss=0.118] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.01it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.01it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.95it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.95it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.16it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.16it/s, train_loss=0.2]   \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.10it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.10it/s, train_loss=0.0383]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.11it/s, train_loss=0.0383]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.11it/s, train_loss=0.326] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.28it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.28it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.27it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.27it/s, train_loss=0.14]  \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.28it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.28it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.20it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.20it/s, train_loss=0.0648]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.17it/s, train_loss=0.0648]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.17it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.90it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.90it/s, train_loss=0.0037]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.90it/s, train_loss=0.0037]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.90it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.95it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.95it/s, train_loss=0.0493]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.78it/s, train_loss=0.0493]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.78it/s, train_loss=0.0496]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:13,  4.68it/s, train_loss=0.0496]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:13,  4.68it/s, train_loss=0.0411]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.67it/s, train_loss=0.0411]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.67it/s, train_loss=0.148] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.60it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.60it/s, train_loss=0.0383]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.70it/s, train_loss=0.0383]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:12,  4.70it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.77it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.77it/s, train_loss=0.146] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.73it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.73it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.65it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.65it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.83it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.83it/s, train_loss=0.115] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.89it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  4.89it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.91it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.91it/s, train_loss=0.19]  \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.98it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.98it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.99it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.99it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.92it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.92it/s, train_loss=0.0163]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.10it/s, train_loss=0.0163]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  5.10it/s, train_loss=0.176] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.94it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.94it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.96it/s, train_loss=0.284]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.96it/s, train_loss=0.015]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.98it/s, train_loss=0.015]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.98it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.98it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.98it/s, train_loss=0.0967]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.94it/s, train_loss=0.0967]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:08,  4.94it/s, train_loss=0.336] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.00it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.00it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.00it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.00it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.00it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.00it/s, train_loss=0.0063]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.94it/s, train_loss=0.0063]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.94it/s, train_loss=0.0301]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.86it/s, train_loss=0.0301]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  4.86it/s, train_loss=0.0937]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.78it/s, train_loss=0.0937]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.78it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.11it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.11it/s, train_loss=0.106] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.00it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.00it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.08it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.08it/s, train_loss=0.0305]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.12it/s, train_loss=0.0305]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  5.12it/s, train_loss=0.477] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:05,  5.35it/s, train_loss=0.477]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:05,  5.35it/s, train_loss=0.0206]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.21it/s, train_loss=0.0206]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.21it/s, train_loss=0.0534]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.19it/s, train_loss=0.0534]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.19it/s, train_loss=0.231] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.98it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.98it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.19it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.19it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.14it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.14it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.89it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.89it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.77it/s, train_loss=0.343]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.77it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.05it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.05it/s, train_loss=0.0585]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.06it/s, train_loss=0.0585]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.06it/s, train_loss=0.0564]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.12it/s, train_loss=0.0564]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.12it/s, train_loss=0.556] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.24it/s, train_loss=0.556]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.24it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.01it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.01it/s, train_loss=0.0905]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.84it/s, train_loss=0.0905]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.84it/s, train_loss=0.0254]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.01it/s, train_loss=0.0254]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  5.01it/s, train_loss=0.158] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.93it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.93it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.93it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.93it/s, train_loss=0.0466]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.99it/s, train_loss=0.0466]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.99it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.92it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.92it/s, train_loss=0.0372]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.92it/s, train_loss=0.0372]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  4.92it/s, train_loss=0.234] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.75it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.75it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.86it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.86it/s, train_loss=0.159] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.81it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.81it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.94it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.94it/s, train_loss=0.0275]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.97it/s, train_loss=0.0275]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.97it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.93it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.93it/s, train_loss=0.00975]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.07it/s, train_loss=0.00975]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.07it/s, train_loss=0.24]   \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.05it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.05it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.00it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.00it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.06it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  5.06it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.95it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.95it/s, train_loss=0.0277]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.80it/s, train_loss=0.0277]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.80it/s, train_loss=0.0569]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91 average loss: 0.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  83%|████████▎ | 91/110 [37:45<07:51, 24.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 91 current AUC: 0.9926 current accuracy: 0.8820 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 92/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.00962]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.08it/s, train_loss=0.00962]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.08it/s, train_loss=0.0363] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.187] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.98it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.98it/s, train_loss=0.0247]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.80it/s, train_loss=0.0247]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.80it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.92it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.92it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.94it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.94it/s, train_loss=0.0383]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.08it/s, train_loss=0.0383]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.08it/s, train_loss=0.342] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.06it/s, train_loss=0.342]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.06it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.05it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  5.05it/s, train_loss=0.318] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.96it/s, train_loss=0.318]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.96it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.06it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.06it/s, train_loss=0.0781]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.10it/s, train_loss=0.0781]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.10it/s, train_loss=0.0992]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.20it/s, train_loss=0.0992]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.20it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.10it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.10it/s, train_loss=0.238] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.12it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.12it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.18it/s, train_loss=0.472]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.18it/s, train_loss=0.0633]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.27it/s, train_loss=0.0633]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.27it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.04it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.04it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.21it/s, train_loss=0.411]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.21it/s, train_loss=0.0487]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.15it/s, train_loss=0.0487]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.15it/s, train_loss=0.098] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.93it/s, train_loss=0.098]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.93it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.02it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.02it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.92it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.92it/s, train_loss=0.0412]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:21,  4.63it/s, train_loss=0.0412]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:21,  4.63it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.65it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.65it/s, train_loss=0.039] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.78it/s, train_loss=0.039]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.78it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.02it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.02it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.86it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.86it/s, train_loss=0.064]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.72it/s, train_loss=0.064]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:19,  4.72it/s, train_loss=0.00817]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.89it/s, train_loss=0.00817]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.89it/s, train_loss=0.0178] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.91it/s, train_loss=0.0178]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.91it/s, train_loss=0.0524]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.88it/s, train_loss=0.0524]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.88it/s, train_loss=0.255] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.98it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.98it/s, train_loss=0.0825]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.90it/s, train_loss=0.0825]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  4.90it/s, train_loss=0.0907]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.07it/s, train_loss=0.0907]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.07it/s, train_loss=0.0367]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.00it/s, train_loss=0.0367]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.00it/s, train_loss=0.013] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.25it/s, train_loss=0.013]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.25it/s, train_loss=0.0894]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.21it/s, train_loss=0.0894]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.21it/s, train_loss=0.292] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.40it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.40it/s, train_loss=0.091]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.40it/s, train_loss=0.091]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.40it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.15it/s, train_loss=0.481]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.15it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.13it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.13it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.97it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.97it/s, train_loss=0.095]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.16it/s, train_loss=0.095]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.16it/s, train_loss=0.24] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.23it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.23it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.11it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.11it/s, train_loss=0.0732]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.26it/s, train_loss=0.0732]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.26it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.22it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.22it/s, train_loss=0.175] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.15it/s, train_loss=0.175]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.15it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.11it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.11it/s, train_loss=0.0522]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.20it/s, train_loss=0.0522]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.20it/s, train_loss=0.024] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.31it/s, train_loss=0.024]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.31it/s, train_loss=0.0803]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.16it/s, train_loss=0.0803]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.16it/s, train_loss=0.0262]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.11it/s, train_loss=0.0262]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.11it/s, train_loss=0.216] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.06it/s, train_loss=0.216]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.06it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.07it/s, train_loss=0.0692]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.07it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.95it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.95it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.95it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.95it/s, train_loss=0.166] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.89it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.89it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.29it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.29it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.07it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.07it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.89it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.89it/s, train_loss=0.0532]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.79it/s, train_loss=0.0532]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.79it/s, train_loss=0.00791]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.87it/s, train_loss=0.00791]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.87it/s, train_loss=0.0992] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:12,  4.75it/s, train_loss=0.0992]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:12,  4.75it/s, train_loss=0.00492]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.95it/s, train_loss=0.00492]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.95it/s, train_loss=0.25]   \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.25]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.06it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.06it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.10it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.10it/s, train_loss=0.192] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.91it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.91it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.70it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.70it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.92it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.92it/s, train_loss=0.0219]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.99it/s, train_loss=0.0219]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.99it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.75it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:10,  4.75it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.74it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.74it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.67it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.67it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.79it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.79it/s, train_loss=0.0757]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.13it/s, train_loss=0.0757]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.13it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.27it/s, train_loss=0.0832]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.27it/s, train_loss=0.0971]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.29it/s, train_loss=0.0971]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:07,  5.29it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.42it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.42it/s, train_loss=0.153] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.38it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.38it/s, train_loss=0.00846]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.00846]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.0255] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.12it/s, train_loss=0.0255]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.12it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.08it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.08it/s, train_loss=0.299] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.97it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.97it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.04it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.04it/s, train_loss=0.0477]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.09it/s, train_loss=0.0477]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.09it/s, train_loss=0.0991]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.11it/s, train_loss=0.0991]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.11it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.12it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.12it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.86it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.86it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.13it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.13it/s, train_loss=0.03]  \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.19it/s, train_loss=0.03]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.19it/s, train_loss=0.0325]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.12it/s, train_loss=0.0325]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.12it/s, train_loss=0.0312]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.79it/s, train_loss=0.0312]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.79it/s, train_loss=0.085] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.91it/s, train_loss=0.085]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.91it/s, train_loss=0.027]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.95it/s, train_loss=0.027]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.95it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.99it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.99it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.90it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.90it/s, train_loss=0.401] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.14it/s, train_loss=0.401]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.14it/s, train_loss=0.0417]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.82it/s, train_loss=0.0417]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.82it/s, train_loss=0.041] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.70it/s, train_loss=0.041]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.70it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.77it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.77it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.72it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.72it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.76it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.76it/s, train_loss=0.02]  \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.79it/s, train_loss=0.02]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.79it/s, train_loss=0.0395]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.0395]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.90it/s, train_loss=0.0368]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.10it/s, train_loss=0.0368]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.10it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.20it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.20it/s, train_loss=0.0164]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.10it/s, train_loss=0.0164]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.10it/s, train_loss=0.218] \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.08it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.08it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.34it/s, train_loss=0.0294]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.34it/s, train_loss=0.106] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.16it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.16it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.22it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.22it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.11it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.11it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.16it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.16it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.93it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.93it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.89it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.89it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.03it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.03it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.74it/s, train_loss=0.0175]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.74it/s, train_loss=0.0346]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.66it/s, train_loss=0.0346]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.66it/s, train_loss=0.274] \n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92 average loss: 0.0952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  84%|████████▎ | 92/110 [38:10<07:27, 24.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 92 current AUC: 0.9960 current accuracy: 0.9006 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 93/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0137]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.08it/s, train_loss=0.0137]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.08it/s, train_loss=0.00494]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.35it/s, train_loss=0.00494]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.35it/s, train_loss=0.143]  \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.99it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.99it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.10it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.10it/s, train_loss=0.0673]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.27it/s, train_loss=0.0673]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.27it/s, train_loss=0.195] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.32it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.32it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.46it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:21,  5.46it/s, train_loss=0.268] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.14it/s, train_loss=0.268]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.14it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.18it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.18it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  4.97it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.97it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.99it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.99it/s, train_loss=0.0865]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.74it/s, train_loss=0.0865]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:23,  4.74it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.85it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.85it/s, train_loss=0.169] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.78it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.78it/s, train_loss=0.0556]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  4.99it/s, train_loss=0.0556]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.99it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.09it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.09it/s, train_loss=0.0574]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.92it/s, train_loss=0.0574]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.92it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.90it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.90it/s, train_loss=0.101] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.16it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.16it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.31it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.31it/s, train_loss=0.021] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.29it/s, train_loss=0.021]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.29it/s, train_loss=0.0257]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.27it/s, train_loss=0.0257]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.27it/s, train_loss=0.132] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.23it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.23it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.20it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.20it/s, train_loss=0.372] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.04it/s, train_loss=0.372]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.04it/s, train_loss=0.0037]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.00it/s, train_loss=0.0037]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.00it/s, train_loss=0.0782]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.04it/s, train_loss=0.0782]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.04it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.00it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.00it/s, train_loss=0.0665]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.02it/s, train_loss=0.0665]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.02it/s, train_loss=0.0811]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.11it/s, train_loss=0.0811]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.11it/s, train_loss=0.00612]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.29it/s, train_loss=0.00612]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.29it/s, train_loss=0.0149] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.31it/s, train_loss=0.0149]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.31it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.36it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.36it/s, train_loss=0.204] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.32it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.32it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.43it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.43it/s, train_loss=0.0558]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.28it/s, train_loss=0.0558]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.28it/s, train_loss=0.0459]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.17it/s, train_loss=0.0459]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.17it/s, train_loss=0.159] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.01it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.01it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.04it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.04it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.05it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.05it/s, train_loss=0.241] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.90it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.90it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.93it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.93it/s, train_loss=0.052] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.11it/s, train_loss=0.052]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.11it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.10it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.10it/s, train_loss=0.174] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.86it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.86it/s, train_loss=0.072]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.92it/s, train_loss=0.072]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.92it/s, train_loss=0.0344]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=0.0344]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.10it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.95it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.95it/s, train_loss=0.00544]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.01it/s, train_loss=0.00544]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.01it/s, train_loss=0.0479] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.88it/s, train_loss=0.0479]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.88it/s, train_loss=0.092] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.95it/s, train_loss=0.092]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.95it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.98it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.98it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.79it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.79it/s, train_loss=0.202] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.74it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.74it/s, train_loss=0.0538]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.07it/s, train_loss=0.0538]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.07it/s, train_loss=0.0854]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.90it/s, train_loss=0.0854]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.90it/s, train_loss=0.00341]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.14it/s, train_loss=0.00341]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.14it/s, train_loss=0.0104] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.21it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.21it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.21it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.21it/s, train_loss=0.351] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.11it/s, train_loss=0.351]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.11it/s, train_loss=0.014]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.15it/s, train_loss=0.014]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.15it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.13it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.13it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.13it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.13it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.99it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.99it/s, train_loss=0.178] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.09it/s, train_loss=0.178]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.09it/s, train_loss=0.0479]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.13it/s, train_loss=0.0479]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.13it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.17it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.17it/s, train_loss=0.00984]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.92it/s, train_loss=0.00984]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  4.92it/s, train_loss=0.0422] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.90it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.90it/s, train_loss=0.0763]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.09it/s, train_loss=0.0763]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.09it/s, train_loss=0.0981]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  5.08it/s, train_loss=0.0981]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.08it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.00632]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.08it/s, train_loss=0.00632]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.08it/s, train_loss=0.211]  \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.15it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.15it/s, train_loss=0.0703]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.15it/s, train_loss=0.0703]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.15it/s, train_loss=0.00312]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.21it/s, train_loss=0.00312]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.21it/s, train_loss=0.00414]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.27it/s, train_loss=0.00414]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.27it/s, train_loss=0.0212] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.33it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.33it/s, train_loss=0.0644]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.10it/s, train_loss=0.0644]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.10it/s, train_loss=0.0497]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.12it/s, train_loss=0.0497]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.12it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.98it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.98it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.02it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.02it/s, train_loss=0.0415]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.94it/s, train_loss=0.0415]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.94it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.82it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.82it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.68it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.68it/s, train_loss=0.103] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.74it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.74it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.75it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.75it/s, train_loss=0.41]  \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.84it/s, train_loss=0.41]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.84it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.83it/s, train_loss=0.163]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.83it/s, train_loss=0.014]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.99it/s, train_loss=0.014]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.99it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.14it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.14it/s, train_loss=0.022] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.32it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.32it/s, train_loss=0.096]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.36it/s, train_loss=0.096]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.36it/s, train_loss=0.0443]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.21it/s, train_loss=0.0443]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.21it/s, train_loss=0.006] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.16it/s, train_loss=0.006]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.16it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.24it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.24it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.18it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.18it/s, train_loss=0.037] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.34it/s, train_loss=0.037]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.34it/s, train_loss=0.0086]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.35it/s, train_loss=0.0086]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.35it/s, train_loss=0.367] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.36it/s, train_loss=0.367]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.36it/s, train_loss=0.00727]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.36it/s, train_loss=0.00727]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.36it/s, train_loss=0.00761]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.00761]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.06it/s, train_loss=0.0722] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.96it/s, train_loss=0.0722]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.96it/s, train_loss=0.0623]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.02it/s, train_loss=0.0623]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.02it/s, train_loss=0.00581]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.32it/s, train_loss=0.00581]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.32it/s, train_loss=0.0363] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.14it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.14it/s, train_loss=0.465] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.94it/s, train_loss=0.465]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.94it/s, train_loss=0.00908]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.04it/s, train_loss=0.00908]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.04it/s, train_loss=0.107]  \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.87it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.87it/s, train_loss=0.0602]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.90it/s, train_loss=0.0602]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.90it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.94it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.94it/s, train_loss=0.00172]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.80it/s, train_loss=0.00172]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.80it/s, train_loss=0.155]  \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.77it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.77it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.82it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.82it/s, train_loss=0.0342]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.84it/s, train_loss=0.0342]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.84it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.95it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.95it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.96it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.96it/s, train_loss=0.0239]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.75it/s, train_loss=0.0239]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.75it/s, train_loss=0.0428]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.80it/s, train_loss=0.0428]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.80it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.57it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.57it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.70it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.70it/s, train_loss=0.0559]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 average loss: 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  85%|████████▍ | 93/110 [38:35<07:02, 24.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 93 current AUC: 0.9975 current accuracy: 0.9317 best AUC: 0.9990 at epoch: 45\n",
      "----------\n",
      "epoch 94/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.70it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.70it/s, train_loss=0.263] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.06it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.06it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.93it/s, train_loss=0.285]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.93it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.88it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.88it/s, train_loss=0.0051]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.03it/s, train_loss=0.0051]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.03it/s, train_loss=0.0167]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.95it/s, train_loss=0.0167]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.95it/s, train_loss=0.0206]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.86it/s, train_loss=0.0206]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.86it/s, train_loss=0.0512]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.84it/s, train_loss=0.0512]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.84it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.02it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  5.02it/s, train_loss=0.0286]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.00it/s, train_loss=0.0286]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.00it/s, train_loss=0.0866]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.12it/s, train_loss=0.0866]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.12it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.10it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.10it/s, train_loss=0.0934]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.18it/s, train_loss=0.0934]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.18it/s, train_loss=0.227] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.35it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.35it/s, train_loss=0.00569]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:19,  5.46it/s, train_loss=0.00569]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:19,  5.46it/s, train_loss=0.326]  \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.26it/s, train_loss=0.326]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.26it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.04it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.04it/s, train_loss=0.0454]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.88it/s, train_loss=0.0454]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.88it/s, train_loss=0.0909]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.10it/s, train_loss=0.0909]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.10it/s, train_loss=0.0269]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.02it/s, train_loss=0.0269]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.02it/s, train_loss=0.257] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.12it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.12it/s, train_loss=0.0289]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.19it/s, train_loss=0.0289]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.19it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.99it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.99it/s, train_loss=0.0588]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.13it/s, train_loss=0.0588]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.13it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.28it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.28it/s, train_loss=0.0811]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.55it/s, train_loss=0.0811]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:17,  5.55it/s, train_loss=0.144] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.50it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.50it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.35it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.35it/s, train_loss=0.349] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.23it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.23it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.35it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.35it/s, train_loss=0.348] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.20it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.20it/s, train_loss=0.00753]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.34it/s, train_loss=0.00753]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:16,  5.34it/s, train_loss=0.0839] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.33it/s, train_loss=0.0839]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.33it/s, train_loss=0.00994]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.29it/s, train_loss=0.00994]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.29it/s, train_loss=0.0279] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.07it/s, train_loss=0.0279]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.07it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.99it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.99it/s, train_loss=0.173] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.09it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.09it/s, train_loss=0.0196]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.0196]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.197] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.91it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.91it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.86it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.86it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.86it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.86it/s, train_loss=0.033] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.033]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.89it/s, train_loss=0.00483]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.74it/s, train_loss=0.00483]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.74it/s, train_loss=0.00338]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.99it/s, train_loss=0.00338]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.99it/s, train_loss=0.0125] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.96it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.96it/s, train_loss=0.03]  \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.90it/s, train_loss=0.03]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.90it/s, train_loss=0.00481]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.01it/s, train_loss=0.00481]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.01it/s, train_loss=0.0418] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.0418]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.113] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.12it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.12it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.97it/s, train_loss=0.341]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.97it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.94it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.94it/s, train_loss=0.0287]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.95it/s, train_loss=0.0287]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.95it/s, train_loss=0.0302]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.87it/s, train_loss=0.0302]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.87it/s, train_loss=0.0291]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.99it/s, train_loss=0.0291]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.99it/s, train_loss=0.0258]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.91it/s, train_loss=0.0258]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.91it/s, train_loss=0.00667]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.01it/s, train_loss=0.00667]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.01it/s, train_loss=0.0529] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.12it/s, train_loss=0.0529]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.12it/s, train_loss=0.0511]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.06it/s, train_loss=0.0511]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.06it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.0241]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.83it/s, train_loss=0.0241]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.83it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:13,  4.68it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:13,  4.68it/s, train_loss=0.31]  \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.84it/s, train_loss=0.31]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.84it/s, train_loss=0.0487]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.91it/s, train_loss=0.0487]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.91it/s, train_loss=0.09]  \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.15it/s, train_loss=0.09]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.15it/s, train_loss=0.00316]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.17it/s, train_loss=0.00316]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.17it/s, train_loss=0.0401] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.96it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.96it/s, train_loss=0.0258]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.04it/s, train_loss=0.0258]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.04it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:09,  5.45it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:09,  5.45it/s, train_loss=0.0616]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:09,  5.35it/s, train_loss=0.0616]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:09,  5.35it/s, train_loss=0.0536]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.28it/s, train_loss=0.0536]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.28it/s, train_loss=0.0242]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.30it/s, train_loss=0.0242]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.30it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.18it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.18it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.21it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.21it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.17it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.17it/s, train_loss=0.0591]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.23it/s, train_loss=0.0591]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.23it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.20it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.20it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.10it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.10it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.08it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.08it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.13it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.13it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.02it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.02it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.90it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.90it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.79it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.79it/s, train_loss=0.00405]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.89it/s, train_loss=0.00405]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.89it/s, train_loss=0.0161] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.97it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.97it/s, train_loss=0.0476]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  4.88it/s, train_loss=0.0476]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.88it/s, train_loss=0.0623]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.05it/s, train_loss=0.0623]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.05it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.96it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.96it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.01it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.01it/s, train_loss=0.0102]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.17it/s, train_loss=0.0102]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.17it/s, train_loss=0.0139]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.20it/s, train_loss=0.0139]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.20it/s, train_loss=0.00973]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.15it/s, train_loss=0.00973]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.15it/s, train_loss=0.0312] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.00it/s, train_loss=0.0312]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.00it/s, train_loss=0.0195]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.94it/s, train_loss=0.0195]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.94it/s, train_loss=0.0147]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.84it/s, train_loss=0.0147]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.84it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.08it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.08it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.93it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.93it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.14it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.14it/s, train_loss=0.0238]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.16it/s, train_loss=0.0238]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.16it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.34it/s, train_loss=0.0618]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.34it/s, train_loss=0.115] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:03,  5.25it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.25it/s, train_loss=0.0912]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.32it/s, train_loss=0.0912]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.32it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.27it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.27it/s, train_loss=0.0671]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.21it/s, train_loss=0.0671]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.21it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.96it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.96it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.90it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.90it/s, train_loss=0.193] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.74it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.74it/s, train_loss=0.00385]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=0.00385]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=0.00963]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.36it/s, train_loss=0.00963]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.36it/s, train_loss=0.0346] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.45it/s, train_loss=0.0346]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.45it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.36it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.36it/s, train_loss=0.0359]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.13it/s, train_loss=0.0359]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.13it/s, train_loss=0.017] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.07it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.07it/s, train_loss=0.0291]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.06it/s, train_loss=0.0291]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.06it/s, train_loss=0.365] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.13it/s, train_loss=0.365]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.13it/s, train_loss=0.029]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.14it/s, train_loss=0.029]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.14it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.89it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.89it/s, train_loss=0.0119]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.14it/s, train_loss=0.0119]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.14it/s, train_loss=0.038] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.35it/s, train_loss=0.038]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.35it/s, train_loss=0.06] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.27it/s, train_loss=0.06]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.27it/s, train_loss=0.00594]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.16it/s, train_loss=0.00594]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.16it/s, train_loss=0.023]  \n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94 average loss: 0.0648\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  85%|████████▌ | 94/110 [39:01<06:41, 25.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 94 current AUC: 0.9991 current accuracy: 0.9441 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 95/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.24it/s, train_loss=0.476]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.24it/s, train_loss=0.00497]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.00it/s, train_loss=0.00497]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.00it/s, train_loss=0.352]  \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.05it/s, train_loss=0.352]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.05it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  4.94it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  4.94it/s, train_loss=0.312] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.97it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.97it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.99it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.13it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.13it/s, train_loss=0.0636]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.10it/s, train_loss=0.0636]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.10it/s, train_loss=0.192] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.94it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.94it/s, train_loss=0.00453]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.00it/s, train_loss=0.00453]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.00it/s, train_loss=0.00918]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.90it/s, train_loss=0.00918]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.90it/s, train_loss=0.0678] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.08it/s, train_loss=0.0678]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.08it/s, train_loss=0.203] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.98it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.98it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=0.406] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.04it/s, train_loss=0.406]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.04it/s, train_loss=0.23] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.95it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.95it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.06it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.06it/s, train_loss=0.0456]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.05it/s, train_loss=0.0456]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.05it/s, train_loss=0.00949]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.18it/s, train_loss=0.00949]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.18it/s, train_loss=0.0128] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.06it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.06it/s, train_loss=0.414] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.414]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  5.03it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.12it/s, train_loss=0.0102]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.41it/s, train_loss=0.0102]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.41it/s, train_loss=0.255] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.13it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.13it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:20,  4.84it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.84it/s, train_loss=0.0798]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.92it/s, train_loss=0.0798]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.92it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.86it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.86it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.76it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.76it/s, train_loss=0.069] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:20,  4.62it/s, train_loss=0.069]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:20,  4.62it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:19,  4.63it/s, train_loss=0.0416]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:19,  4.63it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.00it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.00it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.13it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.13it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.37it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.37it/s, train_loss=0.00751]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.21it/s, train_loss=0.00751]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.21it/s, train_loss=0.0165] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.19it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.19it/s, train_loss=0.00966]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.14it/s, train_loss=0.00966]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.14it/s, train_loss=0.0268] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.14it/s, train_loss=0.0268]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.14it/s, train_loss=0.0494]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.05it/s, train_loss=0.0494]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.05it/s, train_loss=0.125] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.89it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.89it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.87it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.87it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.83it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.83it/s, train_loss=0.215] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.79it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.79it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.84it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.84it/s, train_loss=0.0403]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.88it/s, train_loss=0.0403]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  4.88it/s, train_loss=0.00907]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.96it/s, train_loss=0.00907]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.96it/s, train_loss=0.00743]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.03it/s, train_loss=0.00743]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.03it/s, train_loss=0.0609] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.21it/s, train_loss=0.0609]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.21it/s, train_loss=0.00875]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.19it/s, train_loss=0.00875]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.19it/s, train_loss=0.078]  \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.99it/s, train_loss=0.078]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  4.99it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.79it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.79it/s, train_loss=0.0317]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.88it/s, train_loss=0.0317]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.88it/s, train_loss=0.29]  \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.90it/s, train_loss=0.29]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.90it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.97it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.97it/s, train_loss=0.121] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.01it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  5.01it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.04it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.04it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.01it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.01it/s, train_loss=0.24]  \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.95it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  4.95it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.92it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.92it/s, train_loss=0.00741]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.94it/s, train_loss=0.00741]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.94it/s, train_loss=0.0351] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.06it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.06it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.22it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.22it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.98it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.98it/s, train_loss=0.0787]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.01it/s, train_loss=0.0787]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.01it/s, train_loss=0.038] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.13it/s, train_loss=0.038]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.13it/s, train_loss=0.00509]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.26it/s, train_loss=0.00509]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.26it/s, train_loss=0.206]  \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.20it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.20it/s, train_loss=0.0996]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.11it/s, train_loss=0.0996]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.11it/s, train_loss=0.0865]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.13it/s, train_loss=0.0865]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.13it/s, train_loss=0.00569]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.94it/s, train_loss=0.00569]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.94it/s, train_loss=0.145]  \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.14it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.14it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.19it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.19it/s, train_loss=0.0677]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.12it/s, train_loss=0.0677]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.12it/s, train_loss=0.255] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.03it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.03it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.09it/s, train_loss=0.415]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.09it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.83it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.83it/s, train_loss=0.479]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.82it/s, train_loss=0.479]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.82it/s, train_loss=0.0671]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.87it/s, train_loss=0.0671]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.87it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.85it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.85it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.99it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.99it/s, train_loss=0.142] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.08it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.08it/s, train_loss=0.00527]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.05it/s, train_loss=0.00527]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.05it/s, train_loss=0.103]  \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.84it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.84it/s, train_loss=0.263] \n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.74it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.74it/s, train_loss=0.0487]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.90it/s, train_loss=0.0487]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.90it/s, train_loss=0.144] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.92it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.92it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.83it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  4.83it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.96it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.96it/s, train_loss=0.0831]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.16it/s, train_loss=0.0831]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.16it/s, train_loss=0.0108]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.33it/s, train_loss=0.0108]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.33it/s, train_loss=0.059] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.36it/s, train_loss=0.059]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.36it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.08it/s, train_loss=0.0351]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.08it/s, train_loss=0.0844]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.09it/s, train_loss=0.0844]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.09it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.30it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.30it/s, train_loss=0.0295]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.18it/s, train_loss=0.0295]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.18it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.04it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.04it/s, train_loss=0.0354]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.02it/s, train_loss=0.0354]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.02it/s, train_loss=0.0259]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.04it/s, train_loss=0.0259]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.04it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.09it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.09it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.24it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.24it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.28it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.28it/s, train_loss=0.0806]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.36it/s, train_loss=0.0806]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.36it/s, train_loss=0.399] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.32it/s, train_loss=0.399]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.32it/s, train_loss=0.00941]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:02,  5.47it/s, train_loss=0.00941]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:02,  5.47it/s, train_loss=0.0167] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.35it/s, train_loss=0.0167]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.35it/s, train_loss=0.243] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.28it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.28it/s, train_loss=0.0642]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.29it/s, train_loss=0.0642]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.29it/s, train_loss=0.046] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.11it/s, train_loss=0.046]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.11it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.14it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.14it/s, train_loss=0.0545]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.20it/s, train_loss=0.0545]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.20it/s, train_loss=0.204] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.07it/s, train_loss=0.204]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.07it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.90it/s, train_loss=0.298]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.90it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.84it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.84it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.73it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.73it/s, train_loss=0.075]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.075]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.4]  \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.01it/s, train_loss=0.4]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.01it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.97it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.97it/s, train_loss=0.00967]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.01it/s, train_loss=0.00967]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.01it/s, train_loss=0.308]  \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.99it/s, train_loss=0.308]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.99it/s, train_loss=0.0378]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95 average loss: 0.1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  86%|████████▋ | 95/110 [39:25<06:15, 25.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 95 current AUC: 0.9867 current accuracy: 0.8758 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 96/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.05it/s, train_loss=0.281]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.05it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.25it/s, train_loss=0.0306]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.25it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.24it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.24it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.21it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.21it/s, train_loss=0.00836]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.09it/s, train_loss=0.00836]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.09it/s, train_loss=0.0446] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.08it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.08it/s, train_loss=0.0895]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.04it/s, train_loss=0.0895]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.04it/s, train_loss=0.19]  \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.11it/s, train_loss=0.0412]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.0412]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.09it/s, train_loss=0.019] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.11it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.11it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.15it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.15it/s, train_loss=0.0464]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.14it/s, train_loss=0.0464]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.14it/s, train_loss=0.154] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.26it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.26it/s, train_loss=0.0951]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.23it/s, train_loss=0.0951]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.23it/s, train_loss=0.145] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.27it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.27it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.42it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.42it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.16it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.16it/s, train_loss=0.00891]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.02it/s, train_loss=0.00891]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.02it/s, train_loss=0.0114] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.01it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.01it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.23it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.23it/s, train_loss=0.0396]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.29it/s, train_loss=0.0396]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.29it/s, train_loss=0.236] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.25it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.25it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.08it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.08it/s, train_loss=0.00758]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.91it/s, train_loss=0.00758]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.91it/s, train_loss=0.0898] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.91it/s, train_loss=0.0898]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.91it/s, train_loss=0.00699]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.82it/s, train_loss=0.00699]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.82it/s, train_loss=0.0395] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.90it/s, train_loss=0.0395]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.90it/s, train_loss=0.158] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.97it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.97it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.08it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.08it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.17it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.17it/s, train_loss=0.021] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.05it/s, train_loss=0.021]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.05it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.03it/s, train_loss=0.314]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.03it/s, train_loss=0.0615]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.85it/s, train_loss=0.0615]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.85it/s, train_loss=0.122] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.95it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.95it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.03it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.03it/s, train_loss=0.0461]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.03it/s, train_loss=0.0461]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.03it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.98it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.98it/s, train_loss=0.0893]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.09it/s, train_loss=0.0893]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.09it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.26it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.26it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.18it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.18it/s, train_loss=0.0671]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.93it/s, train_loss=0.0671]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.93it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.90it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.90it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.87it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.87it/s, train_loss=0.232] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.93it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.93it/s, train_loss=0.0806]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:16,  4.80it/s, train_loss=0.0806]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.80it/s, train_loss=0.0195]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.84it/s, train_loss=0.0195]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.84it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.95it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.95it/s, train_loss=0.153] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.87it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.87it/s, train_loss=0.688]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.81it/s, train_loss=0.688]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.81it/s, train_loss=1.47] \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:15,  4.71it/s, train_loss=1.47]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:15,  4.71it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:15,  4.71it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:15,  4.71it/s, train_loss=0.162] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.77it/s, train_loss=0.162]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.77it/s, train_loss=0.00967]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.79it/s, train_loss=0.00967]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.79it/s, train_loss=0.0589] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.95it/s, train_loss=0.0589]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.95it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.82it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.82it/s, train_loss=0.0552]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.99it/s, train_loss=0.0552]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.99it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.90it/s, train_loss=0.0463]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.90it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.83it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:13,  4.83it/s, train_loss=0.01]  \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.67it/s, train_loss=0.01]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:13,  4.67it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:13,  4.69it/s, train_loss=0.424]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:13,  4.69it/s, train_loss=0.0819]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.91it/s, train_loss=0.0819]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.91it/s, train_loss=0.0459]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.89it/s, train_loss=0.0459]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.89it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.88it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.88it/s, train_loss=0.00773]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.01it/s, train_loss=0.00773]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:13<00:11,  5.01it/s, train_loss=0.417]  \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.96it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.96it/s, train_loss=0.00908]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.02it/s, train_loss=0.00908]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.02it/s, train_loss=0.177]  \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.92it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.92it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.00it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.00it/s, train_loss=0.035]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.84it/s, train_loss=0.035]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  4.84it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.00it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.00it/s, train_loss=0.238] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.97it/s, train_loss=0.238]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.97it/s, train_loss=0.011]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.01it/s, train_loss=0.011]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.01it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.99it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.99it/s, train_loss=0.307] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.89it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  4.89it/s, train_loss=0.00478]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.77it/s, train_loss=0.00478]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.77it/s, train_loss=0.631]  \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.91it/s, train_loss=0.631]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.91it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.04it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.04it/s, train_loss=0.0231]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.15it/s, train_loss=0.0231]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.15it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.22it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:08,  5.22it/s, train_loss=0.0407]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.92it/s, train_loss=0.0407]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.92it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.92it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.92it/s, train_loss=0.0833]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.91it/s, train_loss=0.0833]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.91it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.04it/s, train_loss=0.471] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.93it/s, train_loss=0.471]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  4.93it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.80it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.80it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.06it/s, train_loss=0.344]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.06it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.08it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.08it/s, train_loss=0.0724]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.18it/s, train_loss=0.0724]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.18it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.12it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  5.12it/s, train_loss=0.0648]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.05it/s, train_loss=0.0648]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.05it/s, train_loss=0.122] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.98it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.98it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.15it/s, train_loss=0.0458]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.15it/s, train_loss=0.336] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.11it/s, train_loss=0.336]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.11it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.87it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.87it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.89it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.89it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.94it/s, train_loss=0.265]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.94it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.86it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.86it/s, train_loss=0.187] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.00it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.00it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.93it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:20<00:04,  4.93it/s, train_loss=0.177] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.90it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.90it/s, train_loss=0.0829]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.96it/s, train_loss=0.0829]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.96it/s, train_loss=0.00877]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.01it/s, train_loss=0.00877]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.01it/s, train_loss=0.425]  \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.93it/s, train_loss=0.425]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.93it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.90it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  4.90it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.83it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.83it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.84it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.84it/s, train_loss=0.0452]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.83it/s, train_loss=0.0452]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.83it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.97it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.05it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:22<00:02,  5.05it/s, train_loss=0.443] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.93it/s, train_loss=0.443]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.93it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.10it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.10it/s, train_loss=0.00908]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.23it/s, train_loss=0.00908]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.23it/s, train_loss=0.292]  \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.31it/s, train_loss=0.292]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.31it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.99it/s, train_loss=0.462]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.99it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.98it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.98it/s, train_loss=0.00985]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.80it/s, train_loss=0.00985]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.80it/s, train_loss=0.0442] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.0442]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.94it/s, train_loss=0.0455]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.98it/s, train_loss=0.0455]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.98it/s, train_loss=0.35]  \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.92it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.92it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.94it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.94it/s, train_loss=0.236] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.95it/s, train_loss=0.236]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.95it/s, train_loss=0.00965]\n",
      "\u001b[A                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96 average loss: 0.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  87%|████████▋ | 96/110 [39:50<05:49, 24.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 96 current AUC: 0.9974 current accuracy: 0.9130 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 97/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.28it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.28it/s, train_loss=0.015] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.015]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.99it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.40it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.40it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.35it/s, train_loss=0.0544]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.35it/s, train_loss=0.23]  \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.20it/s, train_loss=0.23]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.20it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.06it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.06it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.96it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.96it/s, train_loss=0.0679]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.80it/s, train_loss=0.0679]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.80it/s, train_loss=0.00489]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.98it/s, train_loss=0.00489]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.98it/s, train_loss=0.0233] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:21,  5.20it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:21,  5.20it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.24it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.24it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.28it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:20,  5.28it/s, train_loss=0.0578]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.13it/s, train_loss=0.0578]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.13it/s, train_loss=0.0144]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.25it/s, train_loss=0.0144]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.25it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:19,  5.40it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:19,  5.40it/s, train_loss=0.32]  \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.29it/s, train_loss=0.32]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.29it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.30it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.30it/s, train_loss=0.0588]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.10it/s, train_loss=0.0588]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.10it/s, train_loss=0.03]  \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.15it/s, train_loss=0.03]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.15it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.06it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.06it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.94it/s, train_loss=0.447]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.94it/s, train_loss=0.00952]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.00952]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.07it/s, train_loss=0.0513] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.09it/s, train_loss=0.0513]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.09it/s, train_loss=0.632] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.19it/s, train_loss=0.632]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.19it/s, train_loss=0.1]  \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.37it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.37it/s, train_loss=0.031]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.20it/s, train_loss=0.031]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.20it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.20it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.20it/s, train_loss=0.0705]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.94it/s, train_loss=0.0705]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.94it/s, train_loss=0.44]  \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.15it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.15it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.00it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.00it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.29it/s, train_loss=0.0182]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.29it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.28it/s, train_loss=0.0335]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.28it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.20it/s, train_loss=0.0809]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.20it/s, train_loss=0.0337]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.25it/s, train_loss=0.0337]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.25it/s, train_loss=0.0318]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.01it/s, train_loss=0.0318]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.01it/s, train_loss=0.348] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:06<00:17,  5.05it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.05it/s, train_loss=0.0992]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.28it/s, train_loss=0.0992]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.28it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.40it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.40it/s, train_loss=0.0677]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.47it/s, train_loss=0.0677]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.47it/s, train_loss=0.36]  \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.46it/s, train_loss=0.36]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.46it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:07<00:15,  5.27it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.27it/s, train_loss=0.0573]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.19it/s, train_loss=0.0573]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.19it/s, train_loss=0.119] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.16it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.16it/s, train_loss=0.0134]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.97it/s, train_loss=0.0134]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.97it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.21it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.21it/s, train_loss=0.0459]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:08<00:14,  5.43it/s, train_loss=0.0459]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.43it/s, train_loss=0.0774]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.44it/s, train_loss=0.0774]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:13,  5.44it/s, train_loss=0.146] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.24it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.24it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.22it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.22it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.18it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.18it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:09<00:13,  5.31it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.31it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.06it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.06it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.87it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.87it/s, train_loss=0.0695]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.89it/s, train_loss=0.0695]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.89it/s, train_loss=0.0858]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.01it/s, train_loss=0.0858]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.01it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:13,  5.05it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.05it/s, train_loss=0.19]  \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.04it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.04it/s, train_loss=0.0613]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.02it/s, train_loss=0.0613]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.02it/s, train_loss=0.079] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.06it/s, train_loss=0.079]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.06it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.21it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.21it/s, train_loss=0.0638]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:11,  5.10it/s, train_loss=0.0638]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.10it/s, train_loss=0.0038]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.10it/s, train_loss=0.0038]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.10it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.24it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.24it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.09it/s, train_loss=0.594]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.09it/s, train_loss=0.0365]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.08it/s, train_loss=0.0365]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.08it/s, train_loss=0.0466]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.26it/s, train_loss=0.0466]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:10,  5.26it/s, train_loss=0.0681]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:12<00:10,  5.24it/s, train_loss=0.0681]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.24it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.15it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.15it/s, train_loss=0.126] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.24it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.24it/s, train_loss=0.0523]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.08it/s, train_loss=0.0523]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.08it/s, train_loss=0.052] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  5.07it/s, train_loss=0.052]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:10,  5.07it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:13<00:09,  5.07it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.07it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.95it/s, train_loss=0.0976]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.95it/s, train_loss=0.0154]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.02it/s, train_loss=0.0154]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.02it/s, train_loss=0.0835]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.16it/s, train_loss=0.0835]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.16it/s, train_loss=0.046] \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.30it/s, train_loss=0.046]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.30it/s, train_loss=0.051]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:14<00:08,  5.36it/s, train_loss=0.051]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.36it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.11it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.11it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.10it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.10it/s, train_loss=0.183] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.08it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.08it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.15it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.15it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:15<00:07,  5.05it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.05it/s, train_loss=0.0834]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.15it/s, train_loss=0.0834]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.15it/s, train_loss=0.0464]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.06it/s, train_loss=0.0464]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.06it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.04it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.04it/s, train_loss=0.0471]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.09it/s, train_loss=0.0471]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.09it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:16<00:06,  5.07it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.07it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.90it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.90it/s, train_loss=0.06]  \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.90it/s, train_loss=0.06]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.90it/s, train_loss=0.0199]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.69it/s, train_loss=0.0199]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.69it/s, train_loss=0.196] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.75it/s, train_loss=0.196]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.75it/s, train_loss=0.0616]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:17<00:06,  4.84it/s, train_loss=0.0616]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.84it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.04it/s, train_loss=0.0209]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.04it/s, train_loss=0.0601]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.11it/s, train_loss=0.0601]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.11it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.91it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.91it/s, train_loss=0.0234]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.00it/s, train_loss=0.0234]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.00it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:18<00:05,  4.88it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=0.0314]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.85it/s, train_loss=0.0314]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.85it/s, train_loss=0.118] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.97it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.97it/s, train_loss=0.0222]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.09it/s, train_loss=0.0222]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.09it/s, train_loss=0.112] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.07it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.07it/s, train_loss=0.0409]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:19<00:04,  4.98it/s, train_loss=0.0409]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.98it/s, train_loss=0.00643]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.07it/s, train_loss=0.00643]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.07it/s, train_loss=0.0129] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.11it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.11it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.23it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.23it/s, train_loss=0.00353]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:02,  5.36it/s, train_loss=0.00353]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:02,  5.36it/s, train_loss=0.0827] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:20<00:02,  5.43it/s, train_loss=0.0827]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.43it/s, train_loss=0.0981]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.51it/s, train_loss=0.0981]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.51it/s, train_loss=0.0317]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.35it/s, train_loss=0.0317]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.35it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.46it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.46it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.44it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.44it/s, train_loss=0.0124]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:01,  5.27it/s, train_loss=0.0124]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:21<00:01,  5.27it/s, train_loss=0.347] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:21<00:01,  5.31it/s, train_loss=0.347]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.31it/s, train_loss=0.00837]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.30it/s, train_loss=0.00837]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.30it/s, train_loss=0.0929] \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.22it/s, train_loss=0.0929]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.22it/s, train_loss=0.0909]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.10it/s, train_loss=0.0909]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.10it/s, train_loss=0.0145]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:22<00:00,  5.21it/s, train_loss=0.0145]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:22<00:00,  5.21it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:22<00:00,  5.45it/s, train_loss=0.0132]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.45it/s, train_loss=0.182] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.33it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.33it/s, train_loss=0.0934]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.46it/s, train_loss=0.0934]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.46it/s, train_loss=0.00961]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.62it/s, train_loss=0.00961]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.62it/s, train_loss=0.0457] \n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97 average loss: 0.0915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  88%|████████▊ | 97/110 [40:15<05:21, 24.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 97 current AUC: 0.9955 current accuracy: 0.9130 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 98/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.00573]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  5.82it/s, train_loss=0.00573]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:20,  5.82it/s, train_loss=0.259]  \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.68it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:21,  5.68it/s, train_loss=0.0265]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.64it/s, train_loss=0.0265]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:21,  5.64it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.30it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.30it/s, train_loss=0.00369]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:21,  5.37it/s, train_loss=0.00369]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:21,  5.37it/s, train_loss=0.118]  \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.22it/s, train_loss=0.118]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.22it/s, train_loss=0.053]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.23it/s, train_loss=0.053]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.23it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.04it/s, train_loss=0.166]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.04it/s, train_loss=0.0262]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.05it/s, train_loss=0.0262]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.05it/s, train_loss=0.0042]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.07it/s, train_loss=0.0042]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.07it/s, train_loss=0.161] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.92it/s, train_loss=0.161]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.92it/s, train_loss=0.00464]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.95it/s, train_loss=0.00464]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.95it/s, train_loss=0.0711] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.96it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  4.96it/s, train_loss=0.0475]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.94it/s, train_loss=0.0475]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.94it/s, train_loss=0.0514]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  4.94it/s, train_loss=0.0514]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.94it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.04it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.04it/s, train_loss=0.117] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.09it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.09it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.98it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  4.98it/s, train_loss=0.0524]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.97it/s, train_loss=0.0524]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.97it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:21,  4.84it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.84it/s, train_loss=0.0702]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.88it/s, train_loss=0.0702]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.88it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.97it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.97it/s, train_loss=0.206] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.94it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.94it/s, train_loss=0.845]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.97it/s, train_loss=0.845]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.97it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.97it/s, train_loss=0.0381]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.97it/s, train_loss=0.095] \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.98it/s, train_loss=0.095]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.98it/s, train_loss=0.0374]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.93it/s, train_loss=0.0374]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.93it/s, train_loss=0.0494]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.16it/s, train_loss=0.0494]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.16it/s, train_loss=0.00829]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.92it/s, train_loss=0.00829]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.92it/s, train_loss=0.0446] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.07it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.07it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.93it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.93it/s, train_loss=0.02]  \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.95it/s, train_loss=0.02]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.95it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.08it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.08it/s, train_loss=0.0327]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.12it/s, train_loss=0.0327]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.12it/s, train_loss=0.01]  \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.24it/s, train_loss=0.01]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.24it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.20it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.20it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.25it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.25it/s, train_loss=0.109] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.37it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.37it/s, train_loss=0.0953]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.35it/s, train_loss=0.0953]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.35it/s, train_loss=0.0229]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.38it/s, train_loss=0.0229]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.38it/s, train_loss=0.0704]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.19it/s, train_loss=0.0704]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.19it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.0438]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.03it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.03it/s, train_loss=0.00753]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.05it/s, train_loss=0.00753]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.05it/s, train_loss=0.0331] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.02it/s, train_loss=0.0331]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.02it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.78it/s, train_loss=0.0983]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.78it/s, train_loss=0.142] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.75it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.75it/s, train_loss=0.055]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.02it/s, train_loss=0.055]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.02it/s, train_loss=0.0635]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.06it/s, train_loss=0.0635]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.06it/s, train_loss=0.0413]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.21it/s, train_loss=0.0413]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.21it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.11it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.11it/s, train_loss=0.0771]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.92it/s, train_loss=0.0771]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.92it/s, train_loss=0.119] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.92it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.92it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.15it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.15it/s, train_loss=0.0425]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.10it/s, train_loss=0.0425]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.10it/s, train_loss=0.0386]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.01it/s, train_loss=0.0386]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  5.01it/s, train_loss=0.133] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.05it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.05it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.05it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.05it/s, train_loss=0.1]   \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.13it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.13it/s, train_loss=0.0757]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.01it/s, train_loss=0.0757]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.01it/s, train_loss=0.0822]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.21it/s, train_loss=0.0822]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.21it/s, train_loss=0.0578]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.36it/s, train_loss=0.0578]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.36it/s, train_loss=0.217] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.12it/s, train_loss=0.217]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.12it/s, train_loss=0.00568]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.06it/s, train_loss=0.00568]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.06it/s, train_loss=0.0348] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.95it/s, train_loss=0.0348]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.95it/s, train_loss=0.255] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.87it/s, train_loss=0.255]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.87it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.0733]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.89it/s, train_loss=0.0733]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.89it/s, train_loss=0.0515]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.94it/s, train_loss=0.0515]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.94it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.10it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.10it/s, train_loss=0.0402]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.02it/s, train_loss=0.0402]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.02it/s, train_loss=0.00901]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.04it/s, train_loss=0.00901]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.04it/s, train_loss=0.177]  \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.06it/s, train_loss=0.177]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.06it/s, train_loss=0.0987]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.19it/s, train_loss=0.0987]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.19it/s, train_loss=0.0562]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.25it/s, train_loss=0.0562]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.25it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:08,  5.25it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.25it/s, train_loss=0.00466]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.11it/s, train_loss=0.00466]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.11it/s, train_loss=0.105]  \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.31it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.31it/s, train_loss=0.00646]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.24it/s, train_loss=0.00646]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.24it/s, train_loss=0.00418]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.04it/s, train_loss=0.00418]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.04it/s, train_loss=0.0953] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  5.01it/s, train_loss=0.0953]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.01it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=0.063] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.97it/s, train_loss=0.063]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.97it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.0118]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.98it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.98it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.98it/s, train_loss=0.0145]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  4.85it/s, train_loss=0.0145]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.85it/s, train_loss=0.0147]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.91it/s, train_loss=0.0147]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.91it/s, train_loss=0.131] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.95it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.95it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.09it/s, train_loss=0.283]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.09it/s, train_loss=0.45] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.10it/s, train_loss=0.45]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.10it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  4.90it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.90it/s, train_loss=0.011] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.14it/s, train_loss=0.011]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.14it/s, train_loss=0.00533]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.23it/s, train_loss=0.00533]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.23it/s, train_loss=0.0136] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.30it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.30it/s, train_loss=0.0533]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.23it/s, train_loss=0.0533]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.23it/s, train_loss=0.0311]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.07it/s, train_loss=0.0311]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.07it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.10it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.10it/s, train_loss=0.01] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.24it/s, train_loss=0.01]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.24it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.13it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.13it/s, train_loss=0.0563]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.12it/s, train_loss=0.0563]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.12it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.06it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.06it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.93it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.93it/s, train_loss=0.24]  \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.98it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.98it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.93it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.93it/s, train_loss=0.00584]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.87it/s, train_loss=0.00584]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.87it/s, train_loss=0.0123] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.75it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.75it/s, train_loss=0.0815]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.04it/s, train_loss=0.0815]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.04it/s, train_loss=0.0588]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.10it/s, train_loss=0.0588]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.10it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.15it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.15it/s, train_loss=0.13]  \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.02it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.02it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.15it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.15it/s, train_loss=0.0932]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.19it/s, train_loss=0.0932]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.19it/s, train_loss=0.114] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.26it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.26it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.17it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.17it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.06it/s, train_loss=0.276]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.06it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.96it/s, train_loss=0.197]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.96it/s, train_loss=0.00736]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.97it/s, train_loss=0.00736]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.97it/s, train_loss=0.0862] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.04it/s, train_loss=0.0862]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.04it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.91it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.91it/s, train_loss=0.277] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.77it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.77it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.74it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.74it/s, train_loss=0.193]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98 average loss: 0.0805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  89%|████████▉ | 98/110 [40:39<04:56, 24.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 98 current AUC: 0.9860 current accuracy: 0.8696 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 99/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.83it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:25,  4.83it/s, train_loss=0.483] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.14it/s, train_loss=0.483]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.14it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.97it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  4.97it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.02it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:23,  5.02it/s, train_loss=0.00999]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.84it/s, train_loss=0.00999]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.84it/s, train_loss=0.0202] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.95it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.95it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.01it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.01it/s, train_loss=0.0761]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.09it/s, train_loss=0.0761]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.09it/s, train_loss=0.234] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.36it/s, train_loss=0.234]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:21,  5.36it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:20,  5.36it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:20,  5.36it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.50it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:20,  5.50it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.10it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.10it/s, train_loss=0.167] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.22it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.22it/s, train_loss=0.0364]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=0.0364]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=0.0788]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:22,  4.85it/s, train_loss=0.0788]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.85it/s, train_loss=0.194] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.76it/s, train_loss=0.194]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.76it/s, train_loss=0.0441]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.80it/s, train_loss=0.0441]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.80it/s, train_loss=0.24]  \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.88it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.88it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.173]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.14it/s, train_loss=0.0934]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.07it/s, train_loss=0.0934]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.07it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.96it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.96it/s, train_loss=0.0336]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.99it/s, train_loss=0.0336]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.99it/s, train_loss=0.0224]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.92it/s, train_loss=0.0224]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.92it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.15it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.15it/s, train_loss=0.0261]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.14it/s, train_loss=0.0261]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.14it/s, train_loss=0.0947]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.17it/s, train_loss=0.0947]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.17it/s, train_loss=0.331] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.10it/s, train_loss=0.331]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.10it/s, train_loss=0.00453]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.00it/s, train_loss=0.00453]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.00it/s, train_loss=0.117]  \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.90it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.90it/s, train_loss=0.0462]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  4.85it/s, train_loss=0.0462]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.85it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.86it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.86it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.05it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.05it/s, train_loss=0.00878]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.89it/s, train_loss=0.00878]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.89it/s, train_loss=0.0225] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.88it/s, train_loss=0.0225]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:18,  4.88it/s, train_loss=0.191] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.71it/s, train_loss=0.191]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.71it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.84it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.84it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.79it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.79it/s, train_loss=0.0415]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.75it/s, train_loss=0.0415]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.75it/s, train_loss=0.0367]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.64it/s, train_loss=0.0367]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:17,  4.64it/s, train_loss=0.0563]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.72it/s, train_loss=0.0563]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.72it/s, train_loss=0.0196]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.89it/s, train_loss=0.0196]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.89it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.11it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.11it/s, train_loss=0.0376]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.85it/s, train_loss=0.0376]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.85it/s, train_loss=0.228] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.72it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:16,  4.72it/s, train_loss=0.0505]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.77it/s, train_loss=0.0505]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:16,  4.77it/s, train_loss=0.0864]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.88it/s, train_loss=0.0864]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.88it/s, train_loss=0.0329]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.97it/s, train_loss=0.0329]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.97it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.89it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.89it/s, train_loss=0.386] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.23it/s, train_loss=0.386]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:13,  5.23it/s, train_loss=0.00855]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.23it/s, train_loss=0.00855]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.23it/s, train_loss=0.0121] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:12,  5.54it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:12,  5.54it/s, train_loss=0.0481]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.26it/s, train_loss=0.0481]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.26it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.18it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.18it/s, train_loss=0.00398]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.20it/s, train_loss=0.00398]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  5.20it/s, train_loss=0.0375] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.01it/s, train_loss=0.0375]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.01it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.92it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.92it/s, train_loss=0.00859]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.18it/s, train_loss=0.00859]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.18it/s, train_loss=0.00793]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:11,  5.34it/s, train_loss=0.00793]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:11,  5.34it/s, train_loss=0.0404] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.32it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.32it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.51it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.51it/s, train_loss=0.102] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.49it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.49it/s, train_loss=0.0358]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:10,  5.52it/s, train_loss=0.0358]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:10,  5.52it/s, train_loss=0.103] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.45it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.45it/s, train_loss=0.00496]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.41it/s, train_loss=0.00496]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.41it/s, train_loss=0.013]  \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.27it/s, train_loss=0.013]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.27it/s, train_loss=0.01] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.02it/s, train_loss=0.01]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.02it/s, train_loss=0.0717]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.96it/s, train_loss=0.0717]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.96it/s, train_loss=0.119] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.37it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.37it/s, train_loss=0.0424]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.24it/s, train_loss=0.0424]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.24it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.16it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.16it/s, train_loss=0.00551]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.12it/s, train_loss=0.00551]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.12it/s, train_loss=0.00484]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.26it/s, train_loss=0.00484]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.26it/s, train_loss=0.00509]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.09it/s, train_loss=0.00509]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.09it/s, train_loss=0.346]  \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.10it/s, train_loss=0.346]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.10it/s, train_loss=0.00637]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.07it/s, train_loss=0.00637]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.07it/s, train_loss=0.103]  \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.91it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.91it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.98it/s, train_loss=0.0369]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.98it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.89it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.89it/s, train_loss=0.00868]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.95it/s, train_loss=0.00868]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.95it/s, train_loss=0.00444]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.69it/s, train_loss=0.00444]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.69it/s, train_loss=0.00448]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.66it/s, train_loss=0.00448]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.66it/s, train_loss=0.202]  \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.77it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.77it/s, train_loss=0.0849]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.85it/s, train_loss=0.0849]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.85it/s, train_loss=0.0728]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.17it/s, train_loss=0.0728]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.17it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.12it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.12it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.41it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.41it/s, train_loss=0.00891]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.55it/s, train_loss=0.00891]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.55it/s, train_loss=0.0248] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.45it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.45it/s, train_loss=0.00267]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.24it/s, train_loss=0.00267]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.24it/s, train_loss=0.057]  \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.38it/s, train_loss=0.057]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.38it/s, train_loss=0.0654]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.17it/s, train_loss=0.0654]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.17it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.18it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.18it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.23it/s, train_loss=0.0393]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.23it/s, train_loss=0.0163]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.46it/s, train_loss=0.0163]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.46it/s, train_loss=0.0245]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:04,  5.50it/s, train_loss=0.0245]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:04,  5.50it/s, train_loss=0.0551]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:04,  5.27it/s, train_loss=0.0551]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.27it/s, train_loss=0.207] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.12it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.23it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.23it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.30it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.30it/s, train_loss=0.014] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.17it/s, train_loss=0.014]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.17it/s, train_loss=0.0947]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.11it/s, train_loss=0.0947]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.11it/s, train_loss=0.0301]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.05it/s, train_loss=0.0301]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.05it/s, train_loss=0.0456]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.14it/s, train_loss=0.0456]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.14it/s, train_loss=0.04]  \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.01it/s, train_loss=0.04]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.01it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.14it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.14it/s, train_loss=0.00477]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.18it/s, train_loss=0.00477]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.18it/s, train_loss=0.0144] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.99it/s, train_loss=0.0144]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.99it/s, train_loss=0.249] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.99it/s, train_loss=0.249]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.99it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.87it/s, train_loss=0.207]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.87it/s, train_loss=0.0939]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.01it/s, train_loss=0.0939]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.01it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.12it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.12it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.22it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.22it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.88it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.88it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.98it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.98it/s, train_loss=0.00647]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.09it/s, train_loss=0.00647]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.09it/s, train_loss=0.0585] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.14it/s, train_loss=0.0585]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.14it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.13it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.13it/s, train_loss=0.0589]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.85it/s, train_loss=0.0589]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.85it/s, train_loss=0.226] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.77it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.77it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.91it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.91it/s, train_loss=0.0963]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.86it/s, train_loss=0.0963]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  4.86it/s, train_loss=0.118] \n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99 average loss: 0.0707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  90%|█████████ | 99/110 [41:04<04:31, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 99 current AUC: 0.9951 current accuracy: 0.8882 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 100/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.00611]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.39it/s, train_loss=0.00611]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.39it/s, train_loss=0.035]  \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.22it/s, train_loss=0.035]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.22it/s, train_loss=0.00566]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.81it/s, train_loss=0.00566]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.81it/s, train_loss=0.0695] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.92it/s, train_loss=0.0695]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.92it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.09it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.09it/s, train_loss=0.00551]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.10it/s, train_loss=0.00551]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.10it/s, train_loss=0.0396] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.87it/s, train_loss=0.0396]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.87it/s, train_loss=0.18]  \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.84it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.84it/s, train_loss=0.0283]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.97it/s, train_loss=0.0283]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  4.97it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.95it/s, train_loss=0.0817]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.95it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.93it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.93it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.90it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.90it/s, train_loss=0.224] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.78it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.78it/s, train_loss=0.0173]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.95it/s, train_loss=0.0173]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  4.95it/s, train_loss=0.185] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.04it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.04it/s, train_loss=0.00859]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.13it/s, train_loss=0.00859]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.13it/s, train_loss=0.373]  \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.27it/s, train_loss=0.373]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.27it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.15it/s, train_loss=0.0373]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.15it/s, train_loss=0.00264]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.19it/s, train_loss=0.00264]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.19it/s, train_loss=0.0423] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.30it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.30it/s, train_loss=0.145] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.22it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.22it/s, train_loss=0.0509]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.94it/s, train_loss=0.0509]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.94it/s, train_loss=0.00525]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.85it/s, train_loss=0.00525]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.85it/s, train_loss=0.154]  \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.07it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.07it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  5.10it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  5.10it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.93it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.93it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.96it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.96it/s, train_loss=0.0519]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.0519]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.03it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.07it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.07it/s, train_loss=0.00841]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.07it/s, train_loss=0.00841]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.07it/s, train_loss=0.0462] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.19it/s, train_loss=0.0462]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.19it/s, train_loss=0.038] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.21it/s, train_loss=0.038]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.21it/s, train_loss=0.00796]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.43it/s, train_loss=0.00796]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.43it/s, train_loss=0.00587]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.28it/s, train_loss=0.00587]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.28it/s, train_loss=0.0199] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.08it/s, train_loss=0.0199]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.08it/s, train_loss=0.00554]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.13it/s, train_loss=0.00554]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.13it/s, train_loss=0.055]  \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.95it/s, train_loss=0.055]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.95it/s, train_loss=0.00776]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:18,  4.62it/s, train_loss=0.00776]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:18,  4.62it/s, train_loss=0.0478] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:18,  4.59it/s, train_loss=0.0478]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:18,  4.59it/s, train_loss=0.127] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.58it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.58it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.84it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.84it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.88it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.88it/s, train_loss=0.409] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.88it/s, train_loss=0.409]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.88it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.03it/s, train_loss=0.0235]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  5.03it/s, train_loss=0.029] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.87it/s, train_loss=0.029]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.87it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.93it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.93it/s, train_loss=0.153] \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.83it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:15,  4.83it/s, train_loss=0.0545]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.0545]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  4.97it/s, train_loss=0.0354]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.99it/s, train_loss=0.0354]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  4.99it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.08it/s, train_loss=0.0143]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.08it/s, train_loss=0.0343]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.24it/s, train_loss=0.0343]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.24it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.14it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.14it/s, train_loss=0.017] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.91it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.91it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.87it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  4.87it/s, train_loss=0.00561]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.98it/s, train_loss=0.00561]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.98it/s, train_loss=0.0202] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.18it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.18it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=0.00504]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.00504]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.26it/s, train_loss=0.676]  \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.27it/s, train_loss=0.676]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.27it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.18it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.18it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.19it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.19it/s, train_loss=0.13] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.26it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.26it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.13it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.13it/s, train_loss=0.00675]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.01it/s, train_loss=0.00675]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.01it/s, train_loss=0.0397] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.00it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.00it/s, train_loss=0.017] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.89it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.89it/s, train_loss=0.0888]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.0888]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.95it/s, train_loss=0.213] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.82it/s, train_loss=0.213]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.82it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.91it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.91it/s, train_loss=0.0526]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.14it/s, train_loss=0.0526]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.14it/s, train_loss=0.0158]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.00it/s, train_loss=0.0158]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.00it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.92it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.92it/s, train_loss=0.0255]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.91it/s, train_loss=0.0255]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.91it/s, train_loss=0.0357]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.98it/s, train_loss=0.0357]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.98it/s, train_loss=0.176] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.99it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.99it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.00it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.00it/s, train_loss=0.0479]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.08it/s, train_loss=0.0479]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.08it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.10it/s, train_loss=0.0161]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.10it/s, train_loss=0.348] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.16it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.16it/s, train_loss=0.00267]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.17it/s, train_loss=0.00267]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.17it/s, train_loss=0.00228]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.86it/s, train_loss=0.00228]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.86it/s, train_loss=0.0928] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.85it/s, train_loss=0.0928]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.85it/s, train_loss=0.0768]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.07it/s, train_loss=0.0768]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.07it/s, train_loss=0.102] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.08it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.08it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  5.03it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.03it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.88it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.88it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.85it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.85it/s, train_loss=0.198] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.85it/s, train_loss=0.198]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:07,  4.85it/s, train_loss=0.00366]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.98it/s, train_loss=0.00366]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.98it/s, train_loss=0.0347] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.88it/s, train_loss=0.0347]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.88it/s, train_loss=0.0872]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.99it/s, train_loss=0.0872]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.99it/s, train_loss=0.00617]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.01it/s, train_loss=0.00617]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.01it/s, train_loss=0.0107] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.79it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:06,  4.79it/s, train_loss=0.206] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.80it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.80it/s, train_loss=0.0026]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.77it/s, train_loss=0.0026]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.77it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.94it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.94it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.71it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.71it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.80it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:05,  4.80it/s, train_loss=0.00388]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.82it/s, train_loss=0.00388]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:20<00:04,  4.82it/s, train_loss=0.0996] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.84it/s, train_loss=0.0996]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  4.84it/s, train_loss=0.0471]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.97it/s, train_loss=0.0471]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.97it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.13it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.13it/s, train_loss=0.00523]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.12it/s, train_loss=0.00523]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.12it/s, train_loss=0.0154] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.19it/s, train_loss=0.0154]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.19it/s, train_loss=0.112] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.14it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.14it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.13it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.13it/s, train_loss=0.152] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.05it/s, train_loss=0.152]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.05it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.94it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.94it/s, train_loss=0.022] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.99it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.99it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.07it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.07it/s, train_loss=0.00678]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.04it/s, train_loss=0.00678]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.04it/s, train_loss=0.121]  \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.04it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.33it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.33it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.25it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.25it/s, train_loss=0.0454]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.10it/s, train_loss=0.0454]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.10it/s, train_loss=0.0238]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.34it/s, train_loss=0.0238]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.34it/s, train_loss=0.179] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.41it/s, train_loss=0.179]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.41it/s, train_loss=0.0354]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.41it/s, train_loss=0.0354]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.41it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.98it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.98it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.00it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  5.00it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.85it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.85it/s, train_loss=0.0515]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 average loss: 0.0702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  91%|█████████ | 100/110 [41:29<04:07, 24.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 100 current AUC: 0.9962 current accuracy: 0.9379 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 101/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.96it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.96it/s, train_loss=0.116] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.30it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.30it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.35it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.35it/s, train_loss=0.0715]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.04it/s, train_loss=0.0715]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.04it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.04it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.04it/s, train_loss=0.00495]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.98it/s, train_loss=0.00495]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.98it/s, train_loss=0.0742] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.97it/s, train_loss=0.0742]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.97it/s, train_loss=0.0314]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.86it/s, train_loss=0.0314]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.86it/s, train_loss=0.00828]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.89it/s, train_loss=0.00828]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.89it/s, train_loss=0.0211] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.81it/s, train_loss=0.0211]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.81it/s, train_loss=0.0836]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.87it/s, train_loss=0.0836]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.87it/s, train_loss=0.242] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.92it/s, train_loss=0.242]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.92it/s, train_loss=0.0719]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.07it/s, train_loss=0.0719]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.07it/s, train_loss=0.0242]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.04it/s, train_loss=0.0242]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  5.04it/s, train_loss=0.0487]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.87it/s, train_loss=0.0487]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.87it/s, train_loss=0.027] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.67it/s, train_loss=0.027]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:22,  4.67it/s, train_loss=0.00877]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.80it/s, train_loss=0.00877]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.80it/s, train_loss=0.0167] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.82it/s, train_loss=0.0167]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.82it/s, train_loss=0.109] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.79it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:21,  4.79it/s, train_loss=0.00832]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.75it/s, train_loss=0.00832]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.75it/s, train_loss=0.00666]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.72it/s, train_loss=0.00666]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:21,  4.72it/s, train_loss=0.00243]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.81it/s, train_loss=0.00243]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.81it/s, train_loss=0.0192] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.75it/s, train_loss=0.0192]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.75it/s, train_loss=0.00347]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.90it/s, train_loss=0.00347]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:19,  4.90it/s, train_loss=0.243]  \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.98it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.98it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.01it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  5.01it/s, train_loss=0.00848]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.98it/s, train_loss=0.00848]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.98it/s, train_loss=0.0116] \n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.04it/s, train_loss=0.0116]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.04it/s, train_loss=0.00365]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.16it/s, train_loss=0.00365]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  5.16it/s, train_loss=0.0103] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.04it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.04it/s, train_loss=0.291] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.06it/s, train_loss=0.291]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.06it/s, train_loss=0.00907]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.18it/s, train_loss=0.00907]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.18it/s, train_loss=0.055]  \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.01it/s, train_loss=0.055]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.01it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.98it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  4.98it/s, train_loss=0.0812]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.98it/s, train_loss=0.0812]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.98it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.93it/s, train_loss=0.0202]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.93it/s, train_loss=0.35]  \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.98it/s, train_loss=0.35]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.98it/s, train_loss=0.0957]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.02it/s, train_loss=0.0957]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.02it/s, train_loss=0.224] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.05it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:16,  5.05it/s, train_loss=0.0421]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.14it/s, train_loss=0.0421]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.14it/s, train_loss=0.0733]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.96it/s, train_loss=0.0733]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.96it/s, train_loss=0.0558]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.20it/s, train_loss=0.0558]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.20it/s, train_loss=0.00246]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.00it/s, train_loss=0.00246]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.00it/s, train_loss=0.0321] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.92it/s, train_loss=0.0321]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  4.92it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.91it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.91it/s, train_loss=0.313] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.98it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.98it/s, train_loss=0.00776]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.07it/s, train_loss=0.00776]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.07it/s, train_loss=0.131]  \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.05it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.05it/s, train_loss=0.0354]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  4.87it/s, train_loss=0.0354]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:10<00:14,  4.87it/s, train_loss=0.00718]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.89it/s, train_loss=0.00718]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.89it/s, train_loss=0.0344] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.08it/s, train_loss=0.0344]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.08it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.11it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.11it/s, train_loss=0.0697]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.11it/s, train_loss=0.0697]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.11it/s, train_loss=0.356] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.03it/s, train_loss=0.356]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:11<00:13,  5.03it/s, train_loss=0.0846]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.91it/s, train_loss=0.0846]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.91it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.99it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.99it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.08it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.08it/s, train_loss=0.0854]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.0854]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.254] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.01it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:12<00:12,  5.01it/s, train_loss=0.00728]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.25it/s, train_loss=0.00728]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.25it/s, train_loss=0.0898] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.29it/s, train_loss=0.0898]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.29it/s, train_loss=0.0418]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.20it/s, train_loss=0.0418]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.20it/s, train_loss=0.0278]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.12it/s, train_loss=0.0278]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.12it/s, train_loss=0.0943]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.10it/s, train_loss=0.0943]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.10it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:10,  5.29it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:10,  5.29it/s, train_loss=0.309] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.31it/s, train_loss=0.309]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.31it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.10it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.10it/s, train_loss=0.00664]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.02it/s, train_loss=0.00664]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.02it/s, train_loss=0.104]  \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.04it/s, train_loss=0.104]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:10,  5.04it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.00it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.00it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.01it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.01it/s, train_loss=0.00593]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.24it/s, train_loss=0.00593]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.24it/s, train_loss=0.0203] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.21it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.21it/s, train_loss=0.158] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.14it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.14it/s, train_loss=0.00748]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.10it/s, train_loss=0.00748]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.10it/s, train_loss=0.103]  \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.01it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.01it/s, train_loss=0.0758]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.89it/s, train_loss=0.0758]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:09,  4.89it/s, train_loss=0.00815]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.66it/s, train_loss=0.00815]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:09,  4.66it/s, train_loss=0.202]  \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.82it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:16<00:08,  4.82it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.94it/s, train_loss=0.277]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.94it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.70it/s, train_loss=0.0148]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.70it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.88it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.88it/s, train_loss=0.0768]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.05it/s, train_loss=0.0768]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.05it/s, train_loss=0.0302]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.01it/s, train_loss=0.0302]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:17<00:07,  5.01it/s, train_loss=0.142] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.10it/s, train_loss=0.142]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  5.10it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.10it/s, train_loss=0.0129]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.10it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.0547]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.93it/s, train_loss=0.0547]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.93it/s, train_loss=0.187] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.96it/s, train_loss=0.187]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  4.96it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.00it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.00it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.84it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.84it/s, train_loss=0.287] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.82it/s, train_loss=0.287]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.82it/s, train_loss=0.0225]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.84it/s, train_loss=0.0225]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.84it/s, train_loss=0.00732]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.81it/s, train_loss=0.00732]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.81it/s, train_loss=0.0135] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.84it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.84it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.74it/s, train_loss=0.0791]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.74it/s, train_loss=0.00816]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.00816]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.96it/s, train_loss=0.158]  \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.15it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.15it/s, train_loss=0.0317]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.12it/s, train_loss=0.0317]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:20<00:04,  5.12it/s, train_loss=0.00502]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.25it/s, train_loss=0.00502]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.25it/s, train_loss=0.0786] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.12it/s, train_loss=0.0786]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.12it/s, train_loss=0.017] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.12it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.12it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.05it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.05it/s, train_loss=0.0966]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.00it/s, train_loss=0.0966]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:21<00:03,  5.00it/s, train_loss=0.00855]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.10it/s, train_loss=0.00855]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.10it/s, train_loss=0.0385] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.98it/s, train_loss=0.0385]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.98it/s, train_loss=0.158] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.15it/s, train_loss=0.158]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.15it/s, train_loss=0.00627]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.16it/s, train_loss=0.00627]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.16it/s, train_loss=0.205]  \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.10it/s, train_loss=0.205]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.10it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.25it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.25it/s, train_loss=0.0785]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.03it/s, train_loss=0.0785]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.03it/s, train_loss=0.00318]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  5.00it/s, train_loss=0.00318]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  5.00it/s, train_loss=0.015]  \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.85it/s, train_loss=0.015]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.85it/s, train_loss=0.0988]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.87it/s, train_loss=0.0988]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:23<00:01,  4.87it/s, train_loss=0.0277]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.77it/s, train_loss=0.0277]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.77it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.91it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.91it/s, train_loss=0.0997]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.98it/s, train_loss=0.0997]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.98it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.93it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.93it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.80it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.80it/s, train_loss=0.026] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.90it/s, train_loss=0.026]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.90it/s, train_loss=0.086]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.96it/s, train_loss=0.086]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.96it/s, train_loss=0.164]\n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101 average loss: 0.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  92%|█████████▏| 101/110 [41:54<03:43, 24.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 101 current AUC: 0.9971 current accuracy: 0.8882 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 102/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:19,  6.30it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:19,  6.30it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.14it/s, train_loss=0.0155]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.14it/s, train_loss=0.054] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.94it/s, train_loss=0.054]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.94it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.79it/s, train_loss=0.0423]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.79it/s, train_loss=0.0346]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  4.97it/s, train_loss=0.0346]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  4.97it/s, train_loss=0.0804]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.93it/s, train_loss=0.0804]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.93it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.05it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.05it/s, train_loss=0.0812]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.15it/s, train_loss=0.0812]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.15it/s, train_loss=0.00327]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.00it/s, train_loss=0.00327]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.00it/s, train_loss=0.0897] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.04it/s, train_loss=0.0897]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.04it/s, train_loss=0.00948]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.03it/s, train_loss=0.00948]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  5.03it/s, train_loss=0.00621]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.05it/s, train_loss=0.00621]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.05it/s, train_loss=0.0196] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.20it/s, train_loss=0.0196]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.20it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.96it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.96it/s, train_loss=0.339] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  4.93it/s, train_loss=0.339]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.93it/s, train_loss=0.0266]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.05it/s, train_loss=0.0266]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  5.05it/s, train_loss=0.0507]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.03it/s, train_loss=0.0507]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.03it/s, train_loss=0.0471]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.01it/s, train_loss=0.0471]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.01it/s, train_loss=0.137] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.81it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:21,  4.81it/s, train_loss=0.0525]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.79it/s, train_loss=0.0525]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:21,  4.79it/s, train_loss=0.317] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.93it/s, train_loss=0.317]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.93it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.97it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.97it/s, train_loss=0.0395]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.95it/s, train_loss=0.0395]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.95it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=0.0653]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=0.0437]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.25it/s, train_loss=0.0437]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.25it/s, train_loss=0.0449]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.17it/s, train_loss=0.0449]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.17it/s, train_loss=0.116] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.09it/s, train_loss=0.116]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.09it/s, train_loss=0.058]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.87it/s, train_loss=0.058]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.87it/s, train_loss=0.07] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.01it/s, train_loss=0.07]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.01it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.22it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.22it/s, train_loss=0.0231]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.05it/s, train_loss=0.0231]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  5.05it/s, train_loss=0.0899]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.10it/s, train_loss=0.0899]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.10it/s, train_loss=0.00945]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.19it/s, train_loss=0.00945]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.19it/s, train_loss=0.0215] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.16it/s, train_loss=0.0215]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.16it/s, train_loss=0.0681]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.04it/s, train_loss=0.0681]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.04it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.05it/s, train_loss=0.0203]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.05it/s, train_loss=0.0505]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.07it/s, train_loss=0.0505]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.07it/s, train_loss=0.00345]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.96it/s, train_loss=0.00345]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  4.96it/s, train_loss=0.218]  \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.90it/s, train_loss=0.218]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.90it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  4.97it/s, train_loss=0.354]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  4.97it/s, train_loss=0.00164]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.13it/s, train_loss=0.00164]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.13it/s, train_loss=0.0131] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.96it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.96it/s, train_loss=0.0301]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.97it/s, train_loss=0.0301]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  4.97it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.96it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  4.96it/s, train_loss=0.226] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.12it/s, train_loss=0.226]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.12it/s, train_loss=0.00733]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.23it/s, train_loss=0.00733]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.23it/s, train_loss=0.707]  \n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.20it/s, train_loss=0.707]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.20it/s, train_loss=0.701]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.13it/s, train_loss=0.701]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.13it/s, train_loss=0.0315]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.01it/s, train_loss=0.0315]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.01it/s, train_loss=0.00883]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.05it/s, train_loss=0.00883]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.05it/s, train_loss=0.00724]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.98it/s, train_loss=0.00724]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.98it/s, train_loss=0.00821]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.94it/s, train_loss=0.00821]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.94it/s, train_loss=0.18]   \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.08it/s, train_loss=0.18]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.08it/s, train_loss=0.094]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.87it/s, train_loss=0.094]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.87it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.81it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.81it/s, train_loss=0.0986]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.74it/s, train_loss=0.0986]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.74it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.98it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.98it/s, train_loss=0.154] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.19it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.19it/s, train_loss=0.56] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.05it/s, train_loss=0.56]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.05it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.86it/s, train_loss=0.0128]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.86it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.03it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.03it/s, train_loss=0.0178]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.05it/s, train_loss=0.0178]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.05it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.92it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.92it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.85it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.85it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.00it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.00it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.98it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.98it/s, train_loss=0.0626]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.08it/s, train_loss=0.0626]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.08it/s, train_loss=0.0102]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.14it/s, train_loss=0.0102]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.14it/s, train_loss=0.0768]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.13it/s, train_loss=0.0768]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.13it/s, train_loss=0.176] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.92it/s, train_loss=0.176]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.92it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.88it/s, train_loss=0.232]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.88it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.99it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.99it/s, train_loss=0.00796]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.19it/s, train_loss=0.00796]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.19it/s, train_loss=0.11]   \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.04it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.04it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.99it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.99it/s, train_loss=0.0754]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.98it/s, train_loss=0.0754]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.98it/s, train_loss=0.14]  \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.04it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.04it/s, train_loss=0.0384]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.09it/s, train_loss=0.0384]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.09it/s, train_loss=0.0593]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.08it/s, train_loss=0.0593]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.08it/s, train_loss=0.14]  \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.11it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.11it/s, train_loss=0.00795]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.04it/s, train_loss=0.00795]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.04it/s, train_loss=0.0316] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.80it/s, train_loss=0.0316]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.80it/s, train_loss=0.054] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.88it/s, train_loss=0.054]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.88it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.84it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.84it/s, train_loss=0.0576]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.92it/s, train_loss=0.0576]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.92it/s, train_loss=0.00483]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.96it/s, train_loss=0.00483]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.96it/s, train_loss=0.0669] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.91it/s, train_loss=0.0669]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.91it/s, train_loss=0.0389]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.01it/s, train_loss=0.0389]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.01it/s, train_loss=0.323] \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.10it/s, train_loss=0.323]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.10it/s, train_loss=0.0592]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.23it/s, train_loss=0.0592]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.23it/s, train_loss=0.06]  \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.08it/s, train_loss=0.06]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.08it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.95it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.95it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.86it/s, train_loss=0.0518]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.86it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.82it/s, train_loss=0.0264]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.82it/s, train_loss=0.124] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.91it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.91it/s, train_loss=0.0733]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.95it/s, train_loss=0.0733]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.95it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.0598]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.25it/s, train_loss=0.0136]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.25it/s, train_loss=0.0481]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.36it/s, train_loss=0.0481]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.36it/s, train_loss=0.0519]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.44it/s, train_loss=0.0519]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.44it/s, train_loss=0.0215]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.27it/s, train_loss=0.0215]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.27it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.39it/s, train_loss=0.0246]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.39it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.28it/s, train_loss=0.0434]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.28it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.14it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.14it/s, train_loss=0.0676]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.08it/s, train_loss=0.0676]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.08it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.05it/s, train_loss=0.0189]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.05it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.04it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.04it/s, train_loss=0.00587]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.90it/s, train_loss=0.00587]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.90it/s, train_loss=0.00358]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.86it/s, train_loss=0.00358]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.86it/s, train_loss=0.19]   \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.06it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.06it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.23it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.23it/s, train_loss=0.00849]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.19it/s, train_loss=0.00849]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.19it/s, train_loss=0.0479] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.22it/s, train_loss=0.0479]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.22it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.25it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.25it/s, train_loss=0.0072]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.21it/s, train_loss=0.0072]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  5.21it/s, train_loss=0.0045]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.15it/s, train_loss=0.0045]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.15it/s, train_loss=0.228] \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.92it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.92it/s, train_loss=0.00743]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.04it/s, train_loss=0.00743]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.04it/s, train_loss=0.0114] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.18it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.18it/s, train_loss=0.192] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.24it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.24it/s, train_loss=0.0386]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.18it/s, train_loss=0.0386]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.18it/s, train_loss=0.0402]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102 average loss: 0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  93%|█████████▎| 102/110 [42:18<03:18, 24.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 102 current AUC: 0.9960 current accuracy: 0.9068 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 103/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0284]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.57it/s, train_loss=0.0284]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:21,  5.57it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.16it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.16it/s, train_loss=0.332] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:20,  5.67it/s, train_loss=0.332]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:20,  5.67it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:20,  5.70it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:20,  5.70it/s, train_loss=0.00253]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.10it/s, train_loss=0.00253]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.10it/s, train_loss=0.0353] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.80it/s, train_loss=0.0353]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:24,  4.80it/s, train_loss=0.211] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.94it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.94it/s, train_loss=0.0199]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.76it/s, train_loss=0.0199]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.76it/s, train_loss=0.0316]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.83it/s, train_loss=0.0316]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.83it/s, train_loss=0.0726]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.03it/s, train_loss=0.0726]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.03it/s, train_loss=0.0288]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.17it/s, train_loss=0.0288]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.17it/s, train_loss=0.0581]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.23it/s, train_loss=0.0581]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.23it/s, train_loss=0.0668]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.02it/s, train_loss=0.0668]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.02it/s, train_loss=0.0284]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.16it/s, train_loss=0.0284]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.16it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  4.98it/s, train_loss=0.0361]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  4.98it/s, train_loss=0.018] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.28it/s, train_loss=0.018]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.28it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.37it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.37it/s, train_loss=0.0957]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.38it/s, train_loss=0.0957]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.38it/s, train_loss=0.0843]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.31it/s, train_loss=0.0843]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.31it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  5.09it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  5.09it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.06it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.06it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.85it/s, train_loss=0.418]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.85it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.93it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.93it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.20it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.20it/s, train_loss=0.00851]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.95it/s, train_loss=0.00851]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.95it/s, train_loss=0.014]  \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.91it/s, train_loss=0.014]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.91it/s, train_loss=0.0188]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.11it/s, train_loss=0.0188]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.11it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.10it/s, train_loss=0.0377]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.10it/s, train_loss=0.0204]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.17it/s, train_loss=0.0204]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.17it/s, train_loss=0.0221]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.20it/s, train_loss=0.0221]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.20it/s, train_loss=0.0611]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.88it/s, train_loss=0.0611]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.88it/s, train_loss=0.261] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.97it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.97it/s, train_loss=0.33] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.99it/s, train_loss=0.33]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  4.99it/s, train_loss=0.00349]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.89it/s, train_loss=0.00349]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  4.89it/s, train_loss=0.0225] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:18,  4.69it/s, train_loss=0.0225]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:18,  4.69it/s, train_loss=0.0234]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:19,  4.45it/s, train_loss=0.0234]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:19,  4.45it/s, train_loss=0.00681]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:18,  4.60it/s, train_loss=0.00681]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:18,  4.60it/s, train_loss=0.0101] \n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.79it/s, train_loss=0.0101]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.79it/s, train_loss=0.345] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.77it/s, train_loss=0.345]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.77it/s, train_loss=0.0158]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:17,  4.82it/s, train_loss=0.0158]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.82it/s, train_loss=0.201] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.80it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.80it/s, train_loss=0.00847]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.97it/s, train_loss=0.00847]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.97it/s, train_loss=0.171]  \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.83it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.83it/s, train_loss=0.0784]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:16,  4.84it/s, train_loss=0.0784]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:16,  4.84it/s, train_loss=0.44]  \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.94it/s, train_loss=0.44]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.94it/s, train_loss=0.0193]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.07it/s, train_loss=0.0193]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.07it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.11it/s, train_loss=0.0141]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.11it/s, train_loss=0.0521]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.18it/s, train_loss=0.0521]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.18it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.22it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.22it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.33it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.33it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.08it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.08it/s, train_loss=0.132] \n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.17it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.17it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.39it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.39it/s, train_loss=0.00194]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.12it/s, train_loss=0.00194]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.12it/s, train_loss=0.0309] \n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.99it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.99it/s, train_loss=0.607] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.90it/s, train_loss=0.607]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.90it/s, train_loss=0.0368]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.01it/s, train_loss=0.0368]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.01it/s, train_loss=0.368] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.03it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.03it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.86it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.86it/s, train_loss=0.00979]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.06it/s, train_loss=0.00979]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.06it/s, train_loss=0.384]  \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.01it/s, train_loss=0.384]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.01it/s, train_loss=0.0709]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=0.0709]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=0.109] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.78it/s, train_loss=0.109]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.78it/s, train_loss=0.0419]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.82it/s, train_loss=0.0419]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.82it/s, train_loss=0.165] \n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.90it/s, train_loss=0.165]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.90it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.06it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.06it/s, train_loss=0.0364]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.02it/s, train_loss=0.0364]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.02it/s, train_loss=0.147] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.27it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.27it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.15it/s, train_loss=0.155]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.15it/s, train_loss=0.0396]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:09,  5.23it/s, train_loss=0.0396]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:09,  5.23it/s, train_loss=0.244] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.07it/s, train_loss=0.244]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.07it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.27it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.27it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.92it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.92it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.04it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.04it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.12it/s, train_loss=0.0861]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.12it/s, train_loss=0.0501]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.06it/s, train_loss=0.0501]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.06it/s, train_loss=0.0428]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.11it/s, train_loss=0.0428]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.11it/s, train_loss=0.013] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.013]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.00it/s, train_loss=0.0646]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.0646]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.14it/s, train_loss=0.0704]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.93it/s, train_loss=0.0704]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.93it/s, train_loss=0.258] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.94it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.94it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.04it/s, train_loss=0.0405]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.04it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.93it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.93it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.83it/s, train_loss=0.215]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.83it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.72it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.72it/s, train_loss=0.0882]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.74it/s, train_loss=0.0882]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.74it/s, train_loss=0.235] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.79it/s, train_loss=0.235]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.79it/s, train_loss=0.0504]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.94it/s, train_loss=0.0504]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.94it/s, train_loss=0.00978]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.12it/s, train_loss=0.00978]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.12it/s, train_loss=0.0178] \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.29it/s, train_loss=0.0178]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  5.29it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.38it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.38it/s, train_loss=0.129] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.29it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.29it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.28it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.28it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.26it/s, train_loss=0.0267]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.26it/s, train_loss=0.111] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.27it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.27it/s, train_loss=0.00714]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.29it/s, train_loss=0.00714]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:04,  5.29it/s, train_loss=0.144]  \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.21it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.21it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.22it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.22it/s, train_loss=0.012] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.95it/s, train_loss=0.012]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.95it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.05it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.05it/s, train_loss=0.184] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.04it/s, train_loss=0.184]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.04it/s, train_loss=0.0319]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.01it/s, train_loss=0.0319]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.01it/s, train_loss=0.0739]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.97it/s, train_loss=0.0739]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.97it/s, train_loss=0.237] \n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.04it/s, train_loss=0.237]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.04it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.93it/s, train_loss=0.428]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  4.93it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.12it/s, train_loss=0.0177]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.12it/s, train_loss=0.0188]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.99it/s, train_loss=0.0188]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.99it/s, train_loss=0.0836]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.19it/s, train_loss=0.0836]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.19it/s, train_loss=0.028] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.91it/s, train_loss=0.028]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.91it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.81it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.81it/s, train_loss=0.014]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.02it/s, train_loss=0.014]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.02it/s, train_loss=0.0633]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.17it/s, train_loss=0.0633]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.17it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.28it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.28it/s, train_loss=0.098] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.06it/s, train_loss=0.098]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.06it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.10it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.10it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.24it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.24it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  5.00it/s, train_loss=0.0186]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  5.00it/s, train_loss=0.84]  \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.82it/s, train_loss=0.84]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.82it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.92it/s, train_loss=0.286]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.92it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.17it/s, train_loss=0.294]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.17it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.40it/s, train_loss=0.0135]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.40it/s, train_loss=0.0923]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103 average loss: 0.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  94%|█████████▎| 103/110 [42:43<02:53, 24.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 103 current AUC: 0.9912 current accuracy: 0.9068 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 104/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0384]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:27,  4.44it/s, train_loss=0.0384]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:27,  4.44it/s, train_loss=0.00891]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.65it/s, train_loss=0.00891]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.65it/s, train_loss=0.516]  \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:26,  4.54it/s, train_loss=0.516]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:26,  4.54it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.90it/s, train_loss=0.233]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.90it/s, train_loss=0.085]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.80it/s, train_loss=0.085]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.80it/s, train_loss=0.53] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.89it/s, train_loss=0.53]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.89it/s, train_loss=0.0087]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.92it/s, train_loss=0.0087]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.92it/s, train_loss=0.107] \n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.86it/s, train_loss=0.107]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.86it/s, train_loss=0.696]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.95it/s, train_loss=0.696]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  4.95it/s, train_loss=0.0784]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.95it/s, train_loss=0.0784]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.95it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.16it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.16it/s, train_loss=0.0645]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.08it/s, train_loss=0.0645]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.08it/s, train_loss=0.0942]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.91it/s, train_loss=0.0942]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.91it/s, train_loss=0.0577]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.05it/s, train_loss=0.0577]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  5.05it/s, train_loss=0.368] \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.27it/s, train_loss=0.368]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.27it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.25it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.25it/s, train_loss=0.00868]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.34it/s, train_loss=0.00868]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.34it/s, train_loss=0.0201] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.33it/s, train_loss=0.0201]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.33it/s, train_loss=0.224] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.00it/s, train_loss=0.224]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.00it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:19,  5.23it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:19,  5.23it/s, train_loss=0.0399]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.36it/s, train_loss=0.0399]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:18,  5.36it/s, train_loss=0.349] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.26it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.26it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.11it/s, train_loss=0.254]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  5.11it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.06it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.06it/s, train_loss=0.00655]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.25it/s, train_loss=0.00655]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.25it/s, train_loss=0.14]   \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.13it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.13it/s, train_loss=0.0751]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.28it/s, train_loss=0.0751]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.28it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.11it/s, train_loss=0.0482]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.11it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.87it/s, train_loss=0.0304]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.87it/s, train_loss=0.00591]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.15it/s, train_loss=0.00591]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.15it/s, train_loss=0.427]  \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.16it/s, train_loss=0.427]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.16it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.28it/s, train_loss=0.421]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.28it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.21it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.21it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.02it/s, train_loss=0.0328]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.02it/s, train_loss=0.0259]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.14it/s, train_loss=0.0259]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.14it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.13it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.13it/s, train_loss=0.48]  \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.32it/s, train_loss=0.48]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:15,  5.32it/s, train_loss=0.0384]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.0384]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.0878]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.16it/s, train_loss=0.0878]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.16it/s, train_loss=0.0525]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.04it/s, train_loss=0.0525]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.04it/s, train_loss=0.145] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.02it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.02it/s, train_loss=0.0302]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.93it/s, train_loss=0.0302]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.93it/s, train_loss=0.783] \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.86it/s, train_loss=0.783]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.86it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.01it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.01it/s, train_loss=0.0336]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.96it/s, train_loss=0.0336]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.96it/s, train_loss=0.0144]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.01it/s, train_loss=0.0144]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  5.01it/s, train_loss=0.0853]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.09it/s, train_loss=0.0853]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.09it/s, train_loss=0.156] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.10it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.10it/s, train_loss=0.0748]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.26it/s, train_loss=0.0748]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.26it/s, train_loss=0.00622]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.16it/s, train_loss=0.00622]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.16it/s, train_loss=0.0131] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.31it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.31it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:12,  5.46it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:12,  5.46it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.54it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:12,  5.54it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.30it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:12,  5.30it/s, train_loss=0.0268]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.44it/s, train_loss=0.0268]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.44it/s, train_loss=0.098] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:10<00:12,  5.23it/s, train_loss=0.098]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.23it/s, train_loss=0.19] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.15it/s, train_loss=0.0785]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.16it/s, train_loss=0.0785]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.16it/s, train_loss=0.0243]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.13it/s, train_loss=0.0243]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.13it/s, train_loss=0.228] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.25it/s, train_loss=0.228]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.25it/s, train_loss=0.0748]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:11<00:12,  4.86it/s, train_loss=0.0748]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.86it/s, train_loss=0.0184]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.85it/s, train_loss=0.0184]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.85it/s, train_loss=0.0358]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.08it/s, train_loss=0.0358]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.08it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.13it/s, train_loss=0.0217]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  5.13it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.97it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.97it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:12<00:11,  4.86it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.86it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.0901]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.93it/s, train_loss=0.251] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.10it/s, train_loss=0.251]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.10it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.23it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.23it/s, train_loss=0.012]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.04it/s, train_loss=0.012]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.04it/s, train_loss=0.0511]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:13<00:09,  5.15it/s, train_loss=0.0511]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.15it/s, train_loss=0.0198]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.82it/s, train_loss=0.0198]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.82it/s, train_loss=0.141] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.82it/s, train_loss=0.141]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.82it/s, train_loss=0.00719]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.01it/s, train_loss=0.00719]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.01it/s, train_loss=0.0712] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.89it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.89it/s, train_loss=0.0116]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:14<00:09,  4.94it/s, train_loss=0.0116]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.94it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.17it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.17it/s, train_loss=0.00449]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.04it/s, train_loss=0.00449]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.04it/s, train_loss=0.0224] \n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.07it/s, train_loss=0.0224]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.07it/s, train_loss=0.0927]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.92it/s, train_loss=0.0927]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.92it/s, train_loss=0.138] \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:08,  4.92it/s, train_loss=0.138]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  4.92it/s, train_loss=0.0066]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.97it/s, train_loss=0.0066]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:08,  4.97it/s, train_loss=0.13]  \n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.87it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:08,  4.87it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.79it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.79it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.84it/s, train_loss=0.297]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.84it/s, train_loss=0.0295]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.11it/s, train_loss=0.0295]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.11it/s, train_loss=0.412] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.412]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.94it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.96it/s, train_loss=0.0292]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.96it/s, train_loss=0.0386]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.83it/s, train_loss=0.0386]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.83it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.10it/s, train_loss=0.0682]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.10it/s, train_loss=0.00354]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.28it/s, train_loss=0.00354]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.28it/s, train_loss=0.0383] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.10it/s, train_loss=0.0383]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.10it/s, train_loss=0.00825]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.22it/s, train_loss=0.00825]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.22it/s, train_loss=0.077]  \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.19it/s, train_loss=0.077]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.19it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.97it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.97it/s, train_loss=0.0312]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.96it/s, train_loss=0.0312]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.96it/s, train_loss=0.0581]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.0581]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.04it/s, train_loss=0.153] \n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.153]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.10it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.98it/s, train_loss=0.0387]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.98it/s, train_loss=0.00281]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.09it/s, train_loss=0.00281]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.09it/s, train_loss=0.0206] \n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.91it/s, train_loss=0.0206]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.91it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.98it/s, train_loss=0.0397]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:04,  4.98it/s, train_loss=0.128] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.06it/s, train_loss=0.128]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.06it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.16it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.16it/s, train_loss=0.0679]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.12it/s, train_loss=0.0679]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.12it/s, train_loss=0.0802]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.21it/s, train_loss=0.0802]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.21it/s, train_loss=0.117] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.04it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.04it/s, train_loss=0.00474]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.05it/s, train_loss=0.00474]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.05it/s, train_loss=0.13]   \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.97it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.97it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.91it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.91it/s, train_loss=0.0721]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.90it/s, train_loss=0.0721]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.90it/s, train_loss=0.051] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.17it/s, train_loss=0.051]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.17it/s, train_loss=0.0265]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.33it/s, train_loss=0.0265]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.33it/s, train_loss=0.047] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.08it/s, train_loss=0.047]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.08it/s, train_loss=0.00657]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.22it/s, train_loss=0.00657]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.22it/s, train_loss=0.0765] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.27it/s, train_loss=0.0765]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.27it/s, train_loss=0.16]  \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.0693]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.12it/s, train_loss=0.0693]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.12it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.14it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.14it/s, train_loss=0.0275]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.03it/s, train_loss=0.0275]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.03it/s, train_loss=0.00826]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.00it/s, train_loss=0.00826]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.00it/s, train_loss=0.0818] \n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104 average loss: 0.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  95%|█████████▍| 104/110 [43:08<02:28, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 104 current AUC: 0.9932 current accuracy: 0.8944 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 105/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0713]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.30it/s, train_loss=0.0713]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.30it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.19it/s, train_loss=0.0212]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.19it/s, train_loss=0.135] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.19it/s, train_loss=0.135]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.19it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.14it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.14it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:21,  5.50it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:21,  5.50it/s, train_loss=0.0407]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.32it/s, train_loss=0.0407]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:21,  5.32it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.11it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.11it/s, train_loss=0.00326]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.04it/s, train_loss=0.00326]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.04it/s, train_loss=0.0747] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.13it/s, train_loss=0.0747]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.13it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  4.91it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.91it/s, train_loss=0.0207]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.92it/s, train_loss=0.0207]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.92it/s, train_loss=0.00445]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.97it/s, train_loss=0.00445]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.97it/s, train_loss=0.0871] \n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.09it/s, train_loss=0.0871]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.09it/s, train_loss=0.13]  \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.00it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.04it/s, train_loss=0.0503]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.04it/s, train_loss=0.00472]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.26it/s, train_loss=0.00472]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.26it/s, train_loss=0.112]  \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.21it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.21it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.00it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.00it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.00it/s, train_loss=0.0322]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.00it/s, train_loss=0.0324]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.92it/s, train_loss=0.0324]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.92it/s, train_loss=0.0626]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.82it/s, train_loss=0.0626]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.82it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.80it/s, train_loss=0.0341]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.80it/s, train_loss=0.00828]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.90it/s, train_loss=0.00828]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.90it/s, train_loss=0.00234]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.86it/s, train_loss=0.00234]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.86it/s, train_loss=0.0297] \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:19,  4.85it/s, train_loss=0.0297]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:19,  4.85it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.80it/s, train_loss=0.0162]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.80it/s, train_loss=0.139] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.96it/s, train_loss=0.139]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.96it/s, train_loss=0.00996]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.95it/s, train_loss=0.00996]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.95it/s, train_loss=0.0412] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.84it/s, train_loss=0.0412]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.84it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.90it/s, train_loss=0.0233]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  4.90it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.76it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.76it/s, train_loss=0.327] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.91it/s, train_loss=0.327]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:18,  4.91it/s, train_loss=0.0827]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.85it/s, train_loss=0.0827]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:18,  4.85it/s, train_loss=0.018] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.00it/s, train_loss=0.018]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:17,  5.00it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.94it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.94it/s, train_loss=0.039] \n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.95it/s, train_loss=0.039]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.95it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.98it/s, train_loss=0.0401]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.98it/s, train_loss=0.0375]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.80it/s, train_loss=0.0375]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.80it/s, train_loss=0.113] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:17,  4.81it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:17,  4.81it/s, train_loss=0.091]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.82it/s, train_loss=0.091]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:17,  4.82it/s, train_loss=0.0827]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.06it/s, train_loss=0.0827]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  5.06it/s, train_loss=0.00803]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.05it/s, train_loss=0.00803]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.05it/s, train_loss=0.532]  \n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.24it/s, train_loss=0.532]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.24it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.06it/s, train_loss=0.124]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:15,  5.06it/s, train_loss=0.00722]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.10it/s, train_loss=0.00722]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.10it/s, train_loss=0.0249] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.29it/s, train_loss=0.0249]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.29it/s, train_loss=0.00934]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.36it/s, train_loss=0.00934]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.36it/s, train_loss=0.113]  \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.17it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.17it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.09it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.09it/s, train_loss=0.00511]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.98it/s, train_loss=0.00511]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.98it/s, train_loss=0.0635] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.09it/s, train_loss=0.0635]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.09it/s, train_loss=0.0408]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.06it/s, train_loss=0.0408]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.06it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.13it/s, train_loss=0.0691]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.13it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.96it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  4.96it/s, train_loss=0.0568]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.26it/s, train_loss=0.0568]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.26it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.15it/s, train_loss=0.0711]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.15it/s, train_loss=0.137] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.10it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.10it/s, train_loss=0.0531]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.12it/s, train_loss=0.0531]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.12it/s, train_loss=0.02]  \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.32it/s, train_loss=0.02]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.32it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.21it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.21it/s, train_loss=0.00938]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.39it/s, train_loss=0.00938]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.39it/s, train_loss=0.0338] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:10,  5.57it/s, train_loss=0.0338]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:10,  5.57it/s, train_loss=0.022] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.37it/s, train_loss=0.022]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:10,  5.37it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.31it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.31it/s, train_loss=0.0582]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.14it/s, train_loss=0.0582]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.14it/s, train_loss=0.26]  \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.27it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:10,  5.27it/s, train_loss=0.0468]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.18it/s, train_loss=0.0468]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.18it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.16it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.16it/s, train_loss=0.03]  \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.03it/s, train_loss=0.03]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.03it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  4.91it/s, train_loss=0.211]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  4.91it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.98it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.98it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.0299]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.96it/s, train_loss=0.0154]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.09it/s, train_loss=0.0154]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.09it/s, train_loss=0.0266]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.04it/s, train_loss=0.0266]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.04it/s, train_loss=0.00988]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.91it/s, train_loss=0.00988]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.91it/s, train_loss=0.062]  \n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.08it/s, train_loss=0.062]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.08it/s, train_loss=0.0534]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.08it/s, train_loss=0.0534]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.08it/s, train_loss=0.0443]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.92it/s, train_loss=0.0443]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.92it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.99it/s, train_loss=0.0146]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  4.99it/s, train_loss=0.00263]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.12it/s, train_loss=0.00263]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.12it/s, train_loss=0.121]  \n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.02it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:08,  5.02it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.08it/s, train_loss=0.102]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.08it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.10it/s, train_loss=0.127]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.10it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.95it/s, train_loss=0.0159]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.95it/s, train_loss=0.505] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.93it/s, train_loss=0.505]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.93it/s, train_loss=0.484]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.83it/s, train_loss=0.484]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.83it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.97it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.97it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.89it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.89it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.90it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.90it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.88it/s, train_loss=0.0168]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.88it/s, train_loss=0.00921]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.76it/s, train_loss=0.00921]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.76it/s, train_loss=0.378]  \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.90it/s, train_loss=0.378]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.90it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.0109]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.192] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.99it/s, train_loss=0.192]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.99it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.83it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.83it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.94it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.94it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.92it/s, train_loss=0.0631]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.92it/s, train_loss=0.00354]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.07it/s, train_loss=0.00354]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.07it/s, train_loss=0.0071] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.39it/s, train_loss=0.0071]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.39it/s, train_loss=0.0581]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.13it/s, train_loss=0.0581]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.13it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.07it/s, train_loss=0.0716]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.07it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.04it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.04it/s, train_loss=0.202] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.96it/s, train_loss=0.202]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.96it/s, train_loss=0.00959]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.95it/s, train_loss=0.00959]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  4.95it/s, train_loss=0.055]  \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.08it/s, train_loss=0.055]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.08it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.04it/s, train_loss=0.264]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.04it/s, train_loss=0.0678]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.01it/s, train_loss=0.0678]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.01it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.24it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.24it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.19it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.19it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.14it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.14it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  5.30it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  5.30it/s, train_loss=0.00585]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.38it/s, train_loss=0.00585]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.38it/s, train_loss=0.0226] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.35it/s, train_loss=0.0226]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.35it/s, train_loss=0.151] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.14it/s, train_loss=0.00601]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.13it/s, train_loss=0.00601]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.13it/s, train_loss=0.0601] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.98it/s, train_loss=0.0601]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.98it/s, train_loss=0.14]  \n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.13it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.13it/s, train_loss=0.098]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=0.098]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=0.0064]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.99it/s, train_loss=0.0064]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.99it/s, train_loss=0.00821]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  4.86it/s, train_loss=0.00821]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.86it/s, train_loss=0.0834] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.90it/s, train_loss=0.0834]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.90it/s, train_loss=1.12]  \n",
      "\u001b[A                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105 average loss: 0.0807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  95%|█████████▌| 105/110 [43:32<02:03, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 105 current AUC: 0.9928 current accuracy: 0.8696 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 106/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.50it/s, train_loss=0.0106]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:22,  5.50it/s, train_loss=0.00358]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.63it/s, train_loss=0.00358]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.63it/s, train_loss=0.0409] \n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.27it/s, train_loss=0.0409]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.27it/s, train_loss=0.321] \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.90it/s, train_loss=0.321]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:01<00:24,  4.90it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.82it/s, train_loss=0.0799]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:24,  4.82it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.05it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.05it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.05it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.05it/s, train_loss=0.00708]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.00708]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.114]  \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.92it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  4.92it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.95it/s, train_loss=0.307]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.95it/s, train_loss=0.793]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.94it/s, train_loss=0.793]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.94it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.90it/s, train_loss=0.208]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.90it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.74it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:22,  4.74it/s, train_loss=0.0577]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  4.98it/s, train_loss=0.0577]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:21,  4.98it/s, train_loss=0.0256]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.05it/s, train_loss=0.0256]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.05it/s, train_loss=0.402] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.97it/s, train_loss=0.402]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.97it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.07it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.07it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.12it/s, train_loss=0.103]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.12it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.03it/s, train_loss=0.0685]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:20,  5.03it/s, train_loss=0.0512]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.88it/s, train_loss=0.0512]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.88it/s, train_loss=0.312] \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.90it/s, train_loss=0.312]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.90it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.90it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.90it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.96it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:19,  4.96it/s, train_loss=0.459] \n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.89it/s, train_loss=0.459]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:05<00:20,  4.89it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.79it/s, train_loss=0.231]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.79it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.78it/s, train_loss=0.493]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.78it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.83it/s, train_loss=0.464]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.83it/s, train_loss=0.0269]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.99it/s, train_loss=0.0269]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  4.99it/s, train_loss=0.0358]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  4.91it/s, train_loss=0.0358]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:18,  4.91it/s, train_loss=0.0745]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.21it/s, train_loss=0.0745]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.21it/s, train_loss=0.136] \n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.22it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.22it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.04it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.04it/s, train_loss=0.212] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.32it/s, train_loss=0.212]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.32it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.19it/s, train_loss=0.0273]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.19it/s, train_loss=0.181] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:16,  5.35it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:16,  5.35it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.25it/s, train_loss=0.154]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.25it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.23it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.23it/s, train_loss=0.065]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.12it/s, train_loss=0.065]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.12it/s, train_loss=0.00799]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.20it/s, train_loss=0.00799]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:15,  5.20it/s, train_loss=0.0407] \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.24it/s, train_loss=0.0407]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.24it/s, train_loss=0.114] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.93it/s, train_loss=0.114]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.93it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.02it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.02it/s, train_loss=0.0875]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.21it/s, train_loss=0.0875]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.21it/s, train_loss=0.0828]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.19it/s, train_loss=0.0828]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.19it/s, train_loss=0.0848]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.16it/s, train_loss=0.0848]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.16it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.34it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.34it/s, train_loss=0.00833]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.26it/s, train_loss=0.00833]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.26it/s, train_loss=0.199]  \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.21it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.21it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:13,  5.20it/s, train_loss=0.227]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:13,  5.20it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.12it/s, train_loss=0.049]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.12it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.88it/s, train_loss=0.181]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.88it/s, train_loss=0.00353]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.85it/s, train_loss=0.00353]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:14,  4.85it/s, train_loss=0.246]  \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.78it/s, train_loss=0.246]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:14,  4.78it/s, train_loss=0.0507]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  4.99it/s, train_loss=0.0507]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  4.99it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.97it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.97it/s, train_loss=0.19]  \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.93it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.93it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.0363]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.01it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.0688]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  4.98it/s, train_loss=0.449] \n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.97it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.97it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.06it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.06it/s, train_loss=0.0255]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.98it/s, train_loss=0.0255]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.98it/s, train_loss=0.011] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.79it/s, train_loss=0.011]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:12,  4.79it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.97it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.97it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.09it/s, train_loss=0.185]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.09it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.99it/s, train_loss=0.115]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.99it/s, train_loss=0.0242]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.09it/s, train_loss=0.0242]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:10,  5.09it/s, train_loss=0.13]  \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.15it/s, train_loss=0.13]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:10,  5.15it/s, train_loss=0.00623]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.23it/s, train_loss=0.00623]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.23it/s, train_loss=0.0412] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.11it/s, train_loss=0.0412]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.11it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.23it/s, train_loss=0.0213]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.23it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=0.0123]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=0.199] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.20it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.20it/s, train_loss=0.16] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.11it/s, train_loss=0.16]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  5.11it/s, train_loss=0.0163]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:08,  5.33it/s, train_loss=0.0163]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:08,  5.33it/s, train_loss=0.00444]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.34it/s, train_loss=0.00444]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.34it/s, train_loss=0.687]  \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.23it/s, train_loss=0.687]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.23it/s, train_loss=0.091]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.13it/s, train_loss=0.091]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.13it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.08it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.08it/s, train_loss=0.159] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.16it/s, train_loss=0.159]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.16it/s, train_loss=0.0508]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.16it/s, train_loss=0.0508]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.16it/s, train_loss=0.121] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=0.121]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.07it/s, train_loss=0.0256]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.07it/s, train_loss=0.0256]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.07it/s, train_loss=0.144] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.19it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.19it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.33it/s, train_loss=0.126]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.33it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  5.11it/s, train_loss=0.0398]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  5.11it/s, train_loss=0.0445]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.93it/s, train_loss=0.0445]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.93it/s, train_loss=0.0629]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.91it/s, train_loss=0.0629]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.91it/s, train_loss=0.0669]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.99it/s, train_loss=0.0669]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.99it/s, train_loss=0.00765]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.29it/s, train_loss=0.00765]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  5.29it/s, train_loss=0.15]   \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:06,  5.11it/s, train_loss=0.15]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  5.11it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.03it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.91it/s, train_loss=0.0272]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.91it/s, train_loss=0.0496]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.11it/s, train_loss=0.0496]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.11it/s, train_loss=0.01]  \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.18it/s, train_loss=0.01]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.18it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  5.04it/s, train_loss=0.257]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  5.04it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.14it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.14it/s, train_loss=0.079]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.28it/s, train_loss=0.079]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.28it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.19it/s, train_loss=0.201]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.19it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.441]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.02it/s, train_loss=0.0543]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.10it/s, train_loss=0.0543]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.10it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.05it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.05it/s, train_loss=0.0566]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.0566]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.00it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.06it/s, train_loss=0.0271]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.06it/s, train_loss=0.755] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.97it/s, train_loss=0.755]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  4.97it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.89it/s, train_loss=0.0274]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.89it/s, train_loss=0.0451]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.83it/s, train_loss=0.0451]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.83it/s, train_loss=0.00759]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.99it/s, train_loss=0.00759]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.99it/s, train_loss=0.0761] \n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.07it/s, train_loss=0.0761]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.07it/s, train_loss=0.0428]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.96it/s, train_loss=0.0428]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.96it/s, train_loss=0.0883]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.98it/s, train_loss=0.0883]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.98it/s, train_loss=0.0277]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.92it/s, train_loss=0.0277]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.92it/s, train_loss=0.0396]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.99it/s, train_loss=0.0396]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.99it/s, train_loss=0.0628]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.88it/s, train_loss=0.0628]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.88it/s, train_loss=0.0366]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.03it/s, train_loss=0.0366]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.03it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.00it/s, train_loss=0.0436]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.00it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.05it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.05it/s, train_loss=0.24]  \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=0.24]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.99it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.02it/s, train_loss=0.0446]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.02it/s, train_loss=0.00525]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.13it/s, train_loss=0.00525]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.13it/s, train_loss=0.0156] \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.12it/s, train_loss=0.0156]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.12it/s, train_loss=0.0385]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.85it/s, train_loss=0.0385]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106 average loss: 0.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  96%|█████████▋| 106/110 [43:57<01:38, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 106 current AUC: 0.9941 current accuracy: 0.9255 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 107/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.93it/s, train_loss=0.113]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:24,  4.93it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.77it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:25,  4.77it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.11it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.11it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.15it/s, train_loss=0.0176]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.15it/s, train_loss=0.274] \n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.09it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.09it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.06it/s, train_loss=0.0117]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.06it/s, train_loss=0.137] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.89it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.89it/s, train_loss=0.021]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.12it/s, train_loss=0.021]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.12it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  5.07it/s, train_loss=0.0103]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:22,  5.07it/s, train_loss=0.0588]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.86it/s, train_loss=0.0588]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.86it/s, train_loss=0.0139]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.99it/s, train_loss=0.0139]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.99it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.99it/s, train_loss=0.0227]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.99it/s, train_loss=0.0505]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.02it/s, train_loss=0.0505]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.02it/s, train_loss=0.00978]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.02it/s, train_loss=0.00978]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.02it/s, train_loss=0.00952]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:21,  5.07it/s, train_loss=0.00952]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:21,  5.07it/s, train_loss=0.0181] \n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.97it/s, train_loss=0.0181]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:21,  4.97it/s, train_loss=0.0821]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.93it/s, train_loss=0.0821]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.93it/s, train_loss=0.225] \n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.83it/s, train_loss=0.225]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:21,  4.83it/s, train_loss=0.0378]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:21,  4.86it/s, train_loss=0.0378]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:21,  4.86it/s, train_loss=0.417] \n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.90it/s, train_loss=0.417]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.90it/s, train_loss=0.0545]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.87it/s, train_loss=0.0545]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.87it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.72it/s, train_loss=0.0435]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:21,  4.72it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.86it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.86it/s, train_loss=0.0995]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=0.0995]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  5.01it/s, train_loss=0.00861]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.33it/s, train_loss=0.00861]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.33it/s, train_loss=0.023]  \n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.15it/s, train_loss=0.023]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.15it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.27it/s, train_loss=0.0285]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:18,  5.27it/s, train_loss=0.0472]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.23it/s, train_loss=0.0472]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:17,  5.23it/s, train_loss=0.0055]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.39it/s, train_loss=0.0055]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:17,  5.39it/s, train_loss=0.0936]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:17,  5.33it/s, train_loss=0.0936]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:17,  5.33it/s, train_loss=0.00456]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:16,  5.42it/s, train_loss=0.00456]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:16,  5.42it/s, train_loss=0.0208] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.19it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.19it/s, train_loss=0.00381]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.27it/s, train_loss=0.00381]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:16,  5.27it/s, train_loss=0.0366] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.16it/s, train_loss=0.0366]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.16it/s, train_loss=0.299] \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.07it/s, train_loss=0.299]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.07it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.09it/s, train_loss=0.0187]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.09it/s, train_loss=0.334] \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.01it/s, train_loss=0.334]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.01it/s, train_loss=0.0864]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.94it/s, train_loss=0.0864]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.94it/s, train_loss=0.00892]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.00it/s, train_loss=0.00892]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.00it/s, train_loss=0.017]  \n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.15it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.15it/s, train_loss=0.0287]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.84it/s, train_loss=0.0287]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:16,  4.84it/s, train_loss=0.0021]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.83it/s, train_loss=0.0021]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:16,  4.83it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.88it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:16,  4.88it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.02it/s, train_loss=0.0349]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.02it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  5.03it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  5.03it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.99it/s, train_loss=0.0191]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.99it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.08it/s, train_loss=0.0174]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.08it/s, train_loss=0.151] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.02it/s, train_loss=0.151]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.02it/s, train_loss=0.00825]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.05it/s, train_loss=0.00825]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:14,  5.05it/s, train_loss=0.536]  \n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.02it/s, train_loss=0.536]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.02it/s, train_loss=1.03] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.87it/s, train_loss=1.03]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.87it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.02it/s, train_loss=0.693]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.02it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.00it/s, train_loss=0.0371]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.00it/s, train_loss=0.0921]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.15it/s, train_loss=0.0921]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.15it/s, train_loss=0.0454]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:12,  5.18it/s, train_loss=0.0454]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:12,  5.18it/s, train_loss=0.253] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.09it/s, train_loss=0.253]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.09it/s, train_loss=0.00386]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.01it/s, train_loss=0.00386]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.01it/s, train_loss=0.0199] \n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.06it/s, train_loss=0.0199]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.06it/s, train_loss=0.0303]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.00it/s, train_loss=0.0303]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.00it/s, train_loss=0.00432]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.20it/s, train_loss=0.00432]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.20it/s, train_loss=0.0293] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.03it/s, train_loss=0.0293]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  5.03it/s, train_loss=0.0455]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.98it/s, train_loss=0.0455]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.98it/s, train_loss=0.0651]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.20it/s, train_loss=0.0651]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.20it/s, train_loss=0.122] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.93it/s, train_loss=0.122]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.93it/s, train_loss=0.041]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.83it/s, train_loss=0.041]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.83it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.78it/s, train_loss=0.214]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.78it/s, train_loss=0.00408]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.66it/s, train_loss=0.00408]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.66it/s, train_loss=0.0868] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.81it/s, train_loss=0.0868]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.81it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.06it/s, train_loss=0.0433]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  5.06it/s, train_loss=0.1]   \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.02it/s, train_loss=0.1]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.02it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.96it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.96it/s, train_loss=0.143] \n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.17it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.20it/s, train_loss=0.0431]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.20it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:08,  5.39it/s, train_loss=0.0313]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:08,  5.39it/s, train_loss=0.203] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.18it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.18it/s, train_loss=0.0795]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.46it/s, train_loss=0.0795]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.46it/s, train_loss=0.0358]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.39it/s, train_loss=0.0358]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.39it/s, train_loss=0.167] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.19it/s, train_loss=0.167]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.19it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.06it/s, train_loss=0.275]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.06it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.14it/s, train_loss=0.469]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  5.14it/s, train_loss=0.0256]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.25it/s, train_loss=0.0256]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.25it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.15it/s, train_loss=0.0122]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.15it/s, train_loss=0.0224]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.36it/s, train_loss=0.0224]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.36it/s, train_loss=0.0586]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.39it/s, train_loss=0.0586]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.39it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.33it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.33it/s, train_loss=0.0336]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:06,  5.28it/s, train_loss=0.0336]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.28it/s, train_loss=0.245] \n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.19it/s, train_loss=0.245]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.19it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.15it/s, train_loss=0.274]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.15it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.37it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  5.37it/s, train_loss=0.00562]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.36it/s, train_loss=0.00562]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.36it/s, train_loss=0.0536] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.36it/s, train_loss=0.0536]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.36it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.22it/s, train_loss=0.0362]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.22it/s, train_loss=0.033] \n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.15it/s, train_loss=0.033]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.15it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.95it/s, train_loss=0.403]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.95it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.93it/s, train_loss=0.174]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.93it/s, train_loss=0.0915]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:18<00:05,  4.84it/s, train_loss=0.0915]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.84it/s, train_loss=0.0776]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.85it/s, train_loss=0.0776]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.85it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.83it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.83it/s, train_loss=0.186] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.77it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  4.77it/s, train_loss=0.0515]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.84it/s, train_loss=0.0515]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.84it/s, train_loss=0.0296]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.16it/s, train_loss=0.0296]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.16it/s, train_loss=0.0402]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.02it/s, train_loss=0.0402]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.02it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.14it/s, train_loss=0.0151]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.14it/s, train_loss=0.0833]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.20it/s, train_loss=0.0833]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.20it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.05it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.05it/s, train_loss=0.209] \n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.95it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.95it/s, train_loss=0.0465]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.18it/s, train_loss=0.0465]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:02,  5.18it/s, train_loss=0.112] \n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.17it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.17it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.20it/s, train_loss=0.133]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.20it/s, train_loss=0.523]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.06it/s, train_loss=0.523]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.06it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.97it/s, train_loss=0.278]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.97it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.81it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.81it/s, train_loss=0.0318]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.89it/s, train_loss=0.0318]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.89it/s, train_loss=0.263] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.91it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.91it/s, train_loss=0.032]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.93it/s, train_loss=0.032]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.93it/s, train_loss=0.5]  \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.95it/s, train_loss=0.5]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.95it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.95it/s, train_loss=0.678]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.95it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.10it/s, train_loss=0.0457]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.10it/s, train_loss=0.0184]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.10it/s, train_loss=0.0184]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.10it/s, train_loss=0.0811]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.06it/s, train_loss=0.0811]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.06it/s, train_loss=0.00936]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.01it/s, train_loss=0.00936]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.01it/s, train_loss=0.0284] \n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107 average loss: 0.1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  97%|█████████▋| 107/110 [44:21<01:14, 24.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 107 current AUC: 0.9918 current accuracy: 0.8447 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 108/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.14it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.14it/s, train_loss=0.514] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.37it/s, train_loss=0.514]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:22,  5.37it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.17it/s, train_loss=0.171]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:23,  5.17it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.76it/s, train_loss=0.182]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:24,  4.76it/s, train_loss=0.00703]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.05it/s, train_loss=0.00703]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.05it/s, train_loss=0.0259] \n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.90it/s, train_loss=0.0259]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:23,  4.90it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.17it/s, train_loss=0.0712]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.17it/s, train_loss=0.0459]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.07it/s, train_loss=0.0459]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:22,  5.07it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.87it/s, train_loss=0.0104]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.87it/s, train_loss=0.106] \n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.94it/s, train_loss=0.106]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  4.94it/s, train_loss=0.0181]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.07it/s, train_loss=0.0181]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:21,  5.07it/s, train_loss=0.0708]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.19it/s, train_loss=0.0708]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.19it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.22it/s, train_loss=0.0467]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:20,  5.22it/s, train_loss=0.00812]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.14it/s, train_loss=0.00812]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:21,  5.14it/s, train_loss=0.137]  \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.24it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.24it/s, train_loss=0.0866]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.25it/s, train_loss=0.0866]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.25it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.27it/s, train_loss=0.0714]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:19,  5.27it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.32it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:19,  5.32it/s, train_loss=0.147] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.96it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  4.96it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.87it/s, train_loss=0.132]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.87it/s, train_loss=0.00997]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.97it/s, train_loss=0.00997]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:20,  4.97it/s, train_loss=0.0134] \n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.03it/s, train_loss=0.0134]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:19,  5.03it/s, train_loss=0.0437]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.86it/s, train_loss=0.0437]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.86it/s, train_loss=0.0589]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.81it/s, train_loss=0.0589]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:20,  4.81it/s, train_loss=0.08]  \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:20,  4.72it/s, train_loss=0.08]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:20,  4.72it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.60it/s, train_loss=0.0111]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:20,  4.60it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:20,  4.56it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:20,  4.56it/s, train_loss=0.0134]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.76it/s, train_loss=0.0134]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.76it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.73it/s, train_loss=0.0223]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:06<00:19,  4.73it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:19,  4.61it/s, train_loss=0.0808]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:19,  4.61it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.55it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:19,  4.55it/s, train_loss=0.243] \n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:19,  4.65it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:19,  4.65it/s, train_loss=0.0108]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:19,  4.68it/s, train_loss=0.0108]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:19,  4.68it/s, train_loss=0.129] \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:18,  4.74it/s, train_loss=0.129]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:07<00:18,  4.74it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.86it/s, train_loss=0.119]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  4.86it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.88it/s, train_loss=0.0112]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  4.88it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=0.0661]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:17,  4.94it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.0125]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:16,  5.04it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.15it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:08<00:16,  5.15it/s, train_loss=0.00975]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.27it/s, train_loss=0.00975]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.27it/s, train_loss=0.0218] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.22it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.22it/s, train_loss=0.0194]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.0194]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.23it/s, train_loss=0.0699]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.25it/s, train_loss=0.0699]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.25it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:14,  5.21it/s, train_loss=0.0205]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:09<00:14,  5.21it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.27it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.27it/s, train_loss=0.248] \n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.31it/s, train_loss=0.248]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.31it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.33it/s, train_loss=0.0185]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.33it/s, train_loss=0.0222]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.20it/s, train_loss=0.0222]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:14,  5.20it/s, train_loss=0.00836]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.24it/s, train_loss=0.00836]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:13,  5.24it/s, train_loss=0.00654]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  5.10it/s, train_loss=0.00654]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  5.10it/s, train_loss=0.348]  \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.19it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:13,  5.19it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.23it/s, train_loss=0.0276]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:13,  5.23it/s, train_loss=0.0959]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.15it/s, train_loss=0.0959]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.15it/s, train_loss=0.169] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.01it/s, train_loss=0.169]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.01it/s, train_loss=0.00912]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.09it/s, train_loss=0.00912]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.09it/s, train_loss=0.00406]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.96it/s, train_loss=0.00406]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.96it/s, train_loss=0.0291] \n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.16it/s, train_loss=0.0291]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.16it/s, train_loss=0.0465]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.12it/s, train_loss=0.0465]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.12it/s, train_loss=0.259] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.07it/s, train_loss=0.259]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:12,  5.07it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  5.14it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  5.14it/s, train_loss=0.261] \n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.28it/s, train_loss=0.261]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.28it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.01it/s, train_loss=0.0578]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.0578]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.02it/s, train_loss=0.0941]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.74it/s, train_loss=0.0941]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:12,  4.74it/s, train_loss=0.0279]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.78it/s, train_loss=0.0279]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.78it/s, train_loss=0.0789]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.75it/s, train_loss=0.0789]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.75it/s, train_loss=0.2]   \n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.80it/s, train_loss=0.2]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.80it/s, train_loss=0.099]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.90it/s, train_loss=0.099]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.90it/s, train_loss=0.00928]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.97it/s, train_loss=0.00928]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.97it/s, train_loss=0.0606] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.03it/s, train_loss=0.0606]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.03it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.01it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  5.01it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.09it/s, train_loss=0.0169]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:09,  5.09it/s, train_loss=0.0225]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.92it/s, train_loss=0.0225]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  4.92it/s, train_loss=0.258] \n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.97it/s, train_loss=0.258]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.97it/s, train_loss=0.0465]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  5.03it/s, train_loss=0.0465]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  5.03it/s, train_loss=0.00624]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.06it/s, train_loss=0.00624]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  5.06it/s, train_loss=0.111]  \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.00it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.00it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.99it/s, train_loss=0.449]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  4.99it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.00it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.00it/s, train_loss=0.047] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  4.98it/s, train_loss=0.047]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:08,  4.98it/s, train_loss=0.0828]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.23it/s, train_loss=0.0828]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.23it/s, train_loss=0.136] \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.08it/s, train_loss=0.136]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.08it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.98it/s, train_loss=0.0138]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  4.98it/s, train_loss=0.0226]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.03it/s, train_loss=0.0226]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.03it/s, train_loss=0.325] \n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.92it/s, train_loss=0.325]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:07,  4.92it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.80it/s, train_loss=0.146]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.80it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.95it/s, train_loss=0.0282]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.95it/s, train_loss=0.243] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.07it/s, train_loss=0.243]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.07it/s, train_loss=0.0441]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.87it/s, train_loss=0.0441]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:18<00:06,  4.87it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.75it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.75it/s, train_loss=0.0835]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.82it/s, train_loss=0.0835]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.82it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.91it/s, train_loss=0.0426]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.91it/s, train_loss=0.0275]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.93it/s, train_loss=0.0275]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.93it/s, train_loss=0.00453]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.96it/s, train_loss=0.00453]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:19<00:05,  4.96it/s, train_loss=0.0587] \n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.94it/s, train_loss=0.0587]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.94it/s, train_loss=0.00268]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.95it/s, train_loss=0.00268]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.95it/s, train_loss=0.0215] \n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.99it/s, train_loss=0.0215]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.99it/s, train_loss=0.0184]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.08it/s, train_loss=0.0184]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.08it/s, train_loss=0.015] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.19it/s, train_loss=0.015]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.19it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.23it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:20<00:04,  5.23it/s, train_loss=0.00447]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.30it/s, train_loss=0.00447]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:03,  5.30it/s, train_loss=0.0797] \n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.52it/s, train_loss=0.0797]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.52it/s, train_loss=0.0949]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.43it/s, train_loss=0.0949]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.43it/s, train_loss=0.00812]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.41it/s, train_loss=0.00812]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.41it/s, train_loss=0.0311] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.17it/s, train_loss=0.0311]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:21<00:03,  5.17it/s, train_loss=0.0538]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.15it/s, train_loss=0.0538]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.15it/s, train_loss=0.156] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.97it/s, train_loss=0.156]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.97it/s, train_loss=0.0469]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.05it/s, train_loss=0.0469]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.05it/s, train_loss=0.00688]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.14it/s, train_loss=0.00688]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.14it/s, train_loss=0.0394] \n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.10it/s, train_loss=0.0394]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  5.10it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.90it/s, train_loss=0.0345]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.90it/s, train_loss=0.00376]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.95it/s, train_loss=0.00376]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.95it/s, train_loss=0.0657] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.91it/s, train_loss=0.0657]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  4.91it/s, train_loss=0.013] \n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.84it/s, train_loss=0.013]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.84it/s, train_loss=0.0551]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  4.87it/s, train_loss=0.0551]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:23<00:01,  4.87it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.88it/s, train_loss=0.0179]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.88it/s, train_loss=0.0769]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.80it/s, train_loss=0.0769]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.80it/s, train_loss=0.123] \n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.88it/s, train_loss=0.123]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  4.88it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  4.71it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:24<00:00,  4.71it/s, train_loss=0.00532]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.61it/s, train_loss=0.00532]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:24<00:00,  4.61it/s, train_loss=0.117]  \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.58it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  4.58it/s, train_loss=0.0878]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108 average loss: 0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  98%|█████████▊| 108/110 [44:46<00:49, 24.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 108 current AUC: 0.9940 current accuracy: 0.9068 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 109/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.15it/s, train_loss=0.429]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:23,  5.15it/s, train_loss=0.00977]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.00977]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:23,  5.15it/s, train_loss=0.00574]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.96it/s, train_loss=0.00574]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:24,  4.96it/s, train_loss=0.047]  \n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.11it/s, train_loss=0.047]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:23,  5.11it/s, train_loss=0.0206]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:23,  5.00it/s, train_loss=0.0206]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:23,  5.00it/s, train_loss=0.00788]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.06it/s, train_loss=0.00788]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.06it/s, train_loss=0.0114] \n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.96it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:23,  4.96it/s, train_loss=0.0149]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.0149]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.95it/s, train_loss=0.0519]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.95it/s, train_loss=0.0519]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:22,  4.95it/s, train_loss=0.00617]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:01<00:22,  5.08it/s, train_loss=0.00617]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:22,  5.08it/s, train_loss=0.0857] \n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.99it/s, train_loss=0.0857]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.99it/s, train_loss=0.172] \n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.13it/s, train_loss=0.172]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:21,  5.13it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.12it/s, train_loss=0.143]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:21,  5.12it/s, train_loss=0.00713]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.28it/s, train_loss=0.00713]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:20,  5.28it/s, train_loss=0.553]  \n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:02<00:20,  5.35it/s, train_loss=0.553]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:20,  5.35it/s, train_loss=0.0116]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.39it/s, train_loss=0.0116]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:19,  5.39it/s, train_loss=0.0173]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.13it/s, train_loss=0.0173]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:20,  5.13it/s, train_loss=0.0259]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.09it/s, train_loss=0.0259]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.09it/s, train_loss=0.00629]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.02it/s, train_loss=0.00629]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:20,  5.02it/s, train_loss=0.00518]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:03<00:20,  4.98it/s, train_loss=0.00518]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.98it/s, train_loss=0.005]  \n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.23it/s, train_loss=0.005]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.23it/s, train_loss=0.0164]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.31it/s, train_loss=0.0164]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:18,  5.31it/s, train_loss=0.206] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.29it/s, train_loss=0.206]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:18,  5.29it/s, train_loss=0.00682]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.37it/s, train_loss=0.00682]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:18,  5.37it/s, train_loss=0.643]  \n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.29it/s, train_loss=0.643]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.29it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.83it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:19,  4.83it/s, train_loss=0.0472]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.76it/s, train_loss=0.0472]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:19,  4.76it/s, train_loss=0.00206]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.72it/s, train_loss=0.00206]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:19,  4.72it/s, train_loss=0.0302] \n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.72it/s, train_loss=0.0302]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:19,  4.72it/s, train_loss=0.147] \n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:19,  4.81it/s, train_loss=0.147]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:19,  4.81it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.97it/s, train_loss=0.108]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:18,  4.97it/s, train_loss=0.00707]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.20it/s, train_loss=0.00707]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.20it/s, train_loss=0.0207] \n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.15it/s, train_loss=0.0207]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.15it/s, train_loss=0.00726]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.15it/s, train_loss=0.00726]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:17,  5.15it/s, train_loss=0.028]  \n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.08it/s, train_loss=0.028]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.08it/s, train_loss=0.00496]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.03it/s, train_loss=0.00496]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:17,  5.03it/s, train_loss=0.111]  \n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.20it/s, train_loss=0.111]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.20it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.28it/s, train_loss=0.0172]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:15,  5.28it/s, train_loss=0.105] \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.18it/s, train_loss=0.105]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  5.18it/s, train_loss=0.0918]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:15,  5.36it/s, train_loss=0.0918]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:15,  5.36it/s, train_loss=0.0854]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.09it/s, train_loss=0.0854]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.09it/s, train_loss=0.148] \n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.09it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.09it/s, train_loss=0.00694]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.00694]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.09it/s, train_loss=0.00792]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.13it/s, train_loss=0.00792]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.13it/s, train_loss=0.0474] \n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:15,  4.86it/s, train_loss=0.0474]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:15,  4.86it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.94it/s, train_loss=0.0248]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:15,  4.94it/s, train_loss=0.0359]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.07it/s, train_loss=0.0359]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.07it/s, train_loss=0.157] \n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.83it/s, train_loss=0.157]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.83it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.83it/s, train_loss=0.017]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.83it/s, train_loss=0.0449]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.85it/s, train_loss=0.0449]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.85it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.95it/s, train_loss=0.0113]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.95it/s, train_loss=0.00407]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.89it/s, train_loss=0.00407]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.89it/s, train_loss=0.0126] \n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.96it/s, train_loss=0.0126]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  4.96it/s, train_loss=0.018] \n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.03it/s, train_loss=0.018]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.03it/s, train_loss=0.00651]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.08it/s, train_loss=0.00651]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.08it/s, train_loss=0.013]  \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.94it/s, train_loss=0.013]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:13,  4.94it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.87it/s, train_loss=0.036]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:13,  4.87it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.95it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  4.95it/s, train_loss=0.011] \n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.77it/s, train_loss=0.011]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:13,  4.77it/s, train_loss=0.0722]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:12,  4.85it/s, train_loss=0.0722]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:12,  4.85it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.90it/s, train_loss=0.0237]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:12,  4.90it/s, train_loss=0.026] \n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.92it/s, train_loss=0.026]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:12,  4.92it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.97it/s, train_loss=0.313]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  4.97it/s, train_loss=0.015]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.97it/s, train_loss=0.015]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:11,  4.97it/s, train_loss=0.0204]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  4.95it/s, train_loss=0.0204]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  4.95it/s, train_loss=0.272] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.76it/s, train_loss=0.272]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  4.76it/s, train_loss=0.00926]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.78it/s, train_loss=0.00926]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.78it/s, train_loss=0.0579] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.68it/s, train_loss=0.0579]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.68it/s, train_loss=0.131] \n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:11,  4.62it/s, train_loss=0.131]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:14<00:11,  4.62it/s, train_loss=0.024]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:11,  4.69it/s, train_loss=0.024]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:11,  4.69it/s, train_loss=0.0221]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.93it/s, train_loss=0.0221]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:10,  4.93it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.85it/s, train_loss=0.0541]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.85it/s, train_loss=0.0796]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.76it/s, train_loss=0.0796]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:10,  4.76it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.87it/s, train_loss=0.0152]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:15<00:09,  4.87it/s, train_loss=0.016] \n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.92it/s, train_loss=0.016]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.92it/s, train_loss=0.00656]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.14it/s, train_loss=0.00656]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:08,  5.14it/s, train_loss=0.00863]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.32it/s, train_loss=0.00863]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.32it/s, train_loss=0.0165] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.22it/s, train_loss=0.0165]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.22it/s, train_loss=0.00278]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.23it/s, train_loss=0.00278]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:08,  5.23it/s, train_loss=0.304]  \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:07,  5.38it/s, train_loss=0.304]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:16<00:07,  5.38it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.47it/s, train_loss=0.148]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.47it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.35it/s, train_loss=0.0228]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.35it/s, train_loss=0.0266]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.40it/s, train_loss=0.0266]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.40it/s, train_loss=0.239] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.36it/s, train_loss=0.239]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  5.36it/s, train_loss=0.0721]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:06,  5.44it/s, train_loss=0.0721]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:17<00:06,  5.44it/s, train_loss=0.0783]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.50it/s, train_loss=0.0783]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:06,  5.50it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.42it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:06,  5.42it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.47it/s, train_loss=0.0244]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  5.47it/s, train_loss=0.17]  \n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:05,  5.57it/s, train_loss=0.17]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:05,  5.57it/s, train_loss=0.0648]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.69it/s, train_loss=0.0648]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:05,  5.69it/s, train_loss=0.222] \n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:17<00:05,  5.55it/s, train_loss=0.222]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:05,  5.55it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.23it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:05,  5.23it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  5.01it/s, train_loss=0.144] \n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.93it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  4.93it/s, train_loss=0.0706]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  4.91it/s, train_loss=0.0706]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  4.91it/s, train_loss=0.013] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.78it/s, train_loss=0.013]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.78it/s, train_loss=0.0198]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=0.0198]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:05,  4.88it/s, train_loss=0.0095]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.0095]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  4.95it/s, train_loss=0.0167]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.10it/s, train_loss=0.0167]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.10it/s, train_loss=0.046] \n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.84it/s, train_loss=0.046]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  4.84it/s, train_loss=0.0262]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  4.96it/s, train_loss=0.0262]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  4.96it/s, train_loss=0.00167]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.08it/s, train_loss=0.00167]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.08it/s, train_loss=0.0874] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.12it/s, train_loss=0.0874]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  5.12it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.01it/s, train_loss=0.0216]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.01it/s, train_loss=0.0804]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.00it/s, train_loss=0.0804]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.00it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  4.96it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  4.96it/s, train_loss=0.335] \n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.93it/s, train_loss=0.335]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.93it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.95it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  4.95it/s, train_loss=0.0108]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.85it/s, train_loss=0.0108]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  4.85it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  4.84it/s, train_loss=0.0406]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:22<00:02,  4.84it/s, train_loss=0.00304]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.80it/s, train_loss=0.00304]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.80it/s, train_loss=0.14]   \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.03it/s, train_loss=0.14]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:01,  5.03it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.01it/s, train_loss=0.186]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.01it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.03it/s, train_loss=0.241]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  5.03it/s, train_loss=0.00219]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.25it/s, train_loss=0.00219]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.25it/s, train_loss=0.0321] \n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  5.14it/s, train_loss=0.0321]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  5.14it/s, train_loss=0.0647]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.0647]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:00,  5.16it/s, train_loss=0.00402]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.20it/s, train_loss=0.00402]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.20it/s, train_loss=0.0677] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.29it/s, train_loss=0.0677]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.29it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.19it/s, train_loss=0.0214]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.19it/s, train_loss=0.26]  \n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.07it/s, train_loss=0.26]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.07it/s, train_loss=0.0239]\n",
      "\u001b[Aining Batches: 100%|██████████| 122/122 [00:24<00:00,  5.94it/s, train_loss=0.0239]\n",
      "\u001b[A                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109 average loss: 0.0711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  99%|█████████▉| 109/110 [45:11<00:24, 24.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 109 current AUC: 0.9983 current accuracy: 0.9503 best AUC: 0.9991 at epoch: 94\n",
      "----------\n",
      "epoch 110/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "\u001b[Aining Batches:   0%|          | 0/122 [00:00<?, ?it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.57it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:   1%|          | 1/122 [00:00<00:26,  4.57it/s, train_loss=0.11] \n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.86it/s, train_loss=0.11]\n",
      "\u001b[Aining Batches:   2%|▏         | 2/122 [00:00<00:24,  4.86it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.32it/s, train_loss=0.0121]\n",
      "\u001b[Aining Batches:   2%|▏         | 3/122 [00:00<00:22,  5.32it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.36it/s, train_loss=0.0619]\n",
      "\u001b[Aining Batches:   3%|▎         | 4/122 [00:00<00:22,  5.36it/s, train_loss=0.0124]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:00<00:22,  5.28it/s, train_loss=0.0124]\n",
      "\u001b[Aining Batches:   4%|▍         | 5/122 [00:01<00:22,  5.28it/s, train_loss=0.0021]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.24it/s, train_loss=0.0021]\n",
      "\u001b[Aining Batches:   5%|▍         | 6/122 [00:01<00:22,  5.24it/s, train_loss=0.0413]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.06it/s, train_loss=0.0413]\n",
      "\u001b[Aining Batches:   6%|▌         | 7/122 [00:01<00:22,  5.06it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.91it/s, train_loss=0.0309]\n",
      "\u001b[Aining Batches:   7%|▋         | 8/122 [00:01<00:23,  4.91it/s, train_loss=0.164] \n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:01<00:23,  4.71it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:   7%|▋         | 9/122 [00:02<00:23,  4.71it/s, train_loss=0.0887]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.86it/s, train_loss=0.0887]\n",
      "\u001b[Aining Batches:   8%|▊         | 10/122 [00:02<00:23,  4.86it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.87it/s, train_loss=0.0114]\n",
      "\u001b[Aining Batches:   9%|▉         | 11/122 [00:02<00:22,  4.87it/s, train_loss=0.0193]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.91it/s, train_loss=0.0193]\n",
      "\u001b[Aining Batches:  10%|▉         | 12/122 [00:02<00:22,  4.91it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:23,  4.73it/s, train_loss=0.0404]\n",
      "\u001b[Aining Batches:  11%|█         | 13/122 [00:02<00:23,  4.73it/s, train_loss=0.144] \n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:02<00:22,  4.87it/s, train_loss=0.144]\n",
      "\u001b[Aining Batches:  11%|█▏        | 14/122 [00:03<00:22,  4.87it/s, train_loss=0.0316]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.83it/s, train_loss=0.0316]\n",
      "\u001b[Aining Batches:  12%|█▏        | 15/122 [00:03<00:22,  4.83it/s, train_loss=0.00707]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.06it/s, train_loss=0.00707]\n",
      "\u001b[Aining Batches:  13%|█▎        | 16/122 [00:03<00:20,  5.06it/s, train_loss=0.0197] \n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.96it/s, train_loss=0.0197]\n",
      "\u001b[Aining Batches:  14%|█▍        | 17/122 [00:03<00:21,  4.96it/s, train_loss=0.0911]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.07it/s, train_loss=0.0911]\n",
      "\u001b[Aining Batches:  15%|█▍        | 18/122 [00:03<00:20,  5.07it/s, train_loss=0.101] \n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:03<00:19,  5.22it/s, train_loss=0.101]\n",
      "\u001b[Aining Batches:  16%|█▌        | 19/122 [00:04<00:19,  5.22it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.95it/s, train_loss=0.137]\n",
      "\u001b[Aining Batches:  16%|█▋        | 20/122 [00:04<00:20,  4.95it/s, train_loss=0.00822]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.07it/s, train_loss=0.00822]\n",
      "\u001b[Aining Batches:  17%|█▋        | 21/122 [00:04<00:19,  5.07it/s, train_loss=0.00568]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.99it/s, train_loss=0.00568]\n",
      "\u001b[Aining Batches:  18%|█▊        | 22/122 [00:04<00:20,  4.99it/s, train_loss=0.0142] \n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.92it/s, train_loss=0.0142]\n",
      "\u001b[Aining Batches:  19%|█▉        | 23/122 [00:04<00:20,  4.92it/s, train_loss=0.0633]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.93it/s, train_loss=0.0633]\n",
      "\u001b[Aining Batches:  20%|█▉        | 24/122 [00:04<00:19,  4.93it/s, train_loss=0.0283]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:04<00:18,  5.17it/s, train_loss=0.0283]\n",
      "\u001b[Aining Batches:  20%|██        | 25/122 [00:05<00:18,  5.17it/s, train_loss=0.0089]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.32it/s, train_loss=0.0089]\n",
      "\u001b[Aining Batches:  21%|██▏       | 26/122 [00:05<00:18,  5.32it/s, train_loss=0.209] \n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.36it/s, train_loss=0.209]\n",
      "\u001b[Aining Batches:  22%|██▏       | 27/122 [00:05<00:17,  5.36it/s, train_loss=0.0139]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.21it/s, train_loss=0.0139]\n",
      "\u001b[Aining Batches:  23%|██▎       | 28/122 [00:05<00:18,  5.21it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.16it/s, train_loss=0.0422]\n",
      "\u001b[Aining Batches:  24%|██▍       | 29/122 [00:05<00:18,  5.16it/s, train_loss=0.0069]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:05<00:18,  5.08it/s, train_loss=0.0069]\n",
      "\u001b[Aining Batches:  25%|██▍       | 30/122 [00:06<00:18,  5.08it/s, train_loss=0.0609]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.0609]\n",
      "\u001b[Aining Batches:  25%|██▌       | 31/122 [00:06<00:17,  5.14it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.29it/s, train_loss=0.0127]\n",
      "\u001b[Aining Batches:  26%|██▌       | 32/122 [00:06<00:17,  5.29it/s, train_loss=0.00836]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.17it/s, train_loss=0.00836]\n",
      "\u001b[Aining Batches:  27%|██▋       | 33/122 [00:06<00:17,  5.17it/s, train_loss=0.199]  \n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.35it/s, train_loss=0.199]\n",
      "\u001b[Aining Batches:  28%|██▊       | 34/122 [00:06<00:16,  5.35it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:06<00:17,  5.03it/s, train_loss=0.125]\n",
      "\u001b[Aining Batches:  29%|██▊       | 35/122 [00:07<00:17,  5.03it/s, train_loss=0.0317]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.20it/s, train_loss=0.0317]\n",
      "\u001b[Aining Batches:  30%|██▉       | 36/122 [00:07<00:16,  5.20it/s, train_loss=0.00629]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.20it/s, train_loss=0.00629]\n",
      "\u001b[Aining Batches:  30%|███       | 37/122 [00:07<00:16,  5.20it/s, train_loss=0.00353]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.90it/s, train_loss=0.00353]\n",
      "\u001b[Aining Batches:  31%|███       | 38/122 [00:07<00:17,  4.90it/s, train_loss=0.263]  \n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.98it/s, train_loss=0.263]\n",
      "\u001b[Aining Batches:  32%|███▏      | 39/122 [00:07<00:16,  4.98it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:07<00:16,  5.02it/s, train_loss=0.0208]\n",
      "\u001b[Aining Batches:  33%|███▎      | 40/122 [00:08<00:16,  5.02it/s, train_loss=0.168] \n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.21it/s, train_loss=0.168]\n",
      "\u001b[Aining Batches:  34%|███▎      | 41/122 [00:08<00:15,  5.21it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.28it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  34%|███▍      | 42/122 [00:08<00:15,  5.28it/s, train_loss=0.0494]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.23it/s, train_loss=0.0494]\n",
      "\u001b[Aining Batches:  35%|███▌      | 43/122 [00:08<00:15,  5.23it/s, train_loss=0.203] \n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.17it/s, train_loss=0.203]\n",
      "\u001b[Aining Batches:  36%|███▌      | 44/122 [00:08<00:15,  5.17it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:08<00:14,  5.15it/s, train_loss=0.0584]\n",
      "\u001b[Aining Batches:  37%|███▋      | 45/122 [00:09<00:14,  5.15it/s, train_loss=0.0663]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.08it/s, train_loss=0.0663]\n",
      "\u001b[Aining Batches:  38%|███▊      | 46/122 [00:09<00:14,  5.08it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.02it/s, train_loss=0.0232]\n",
      "\u001b[Aining Batches:  39%|███▊      | 47/122 [00:09<00:14,  5.02it/s, train_loss=0.0767]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.85it/s, train_loss=0.0767]\n",
      "\u001b[Aining Batches:  39%|███▉      | 48/122 [00:09<00:15,  4.85it/s, train_loss=0.112] \n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.73it/s, train_loss=0.112]\n",
      "\u001b[Aining Batches:  40%|████      | 49/122 [00:09<00:15,  4.73it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:09<00:14,  4.87it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  41%|████      | 50/122 [00:10<00:14,  4.87it/s, train_loss=0.189] \n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.93it/s, train_loss=0.189]\n",
      "\u001b[Aining Batches:  42%|████▏     | 51/122 [00:10<00:14,  4.93it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.92it/s, train_loss=0.0281]\n",
      "\u001b[Aining Batches:  43%|████▎     | 52/122 [00:10<00:14,  4.92it/s, train_loss=0.0444]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.06it/s, train_loss=0.0444]\n",
      "\u001b[Aining Batches:  43%|████▎     | 53/122 [00:10<00:13,  5.06it/s, train_loss=0.0323]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.05it/s, train_loss=0.0323]\n",
      "\u001b[Aining Batches:  44%|████▍     | 54/122 [00:10<00:13,  5.05it/s, train_loss=0.0184]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:10<00:13,  5.13it/s, train_loss=0.0184]\n",
      "\u001b[Aining Batches:  45%|████▌     | 55/122 [00:11<00:13,  5.13it/s, train_loss=0.011] \n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.20it/s, train_loss=0.011]\n",
      "\u001b[Aining Batches:  46%|████▌     | 56/122 [00:11<00:12,  5.20it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.11it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  47%|████▋     | 57/122 [00:11<00:12,  5.11it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.20it/s, train_loss=0.0252]\n",
      "\u001b[Aining Batches:  48%|████▊     | 58/122 [00:11<00:12,  5.20it/s, train_loss=0.0287]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.25it/s, train_loss=0.0287]\n",
      "\u001b[Aining Batches:  48%|████▊     | 59/122 [00:11<00:11,  5.25it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:11<00:11,  5.18it/s, train_loss=0.0379]\n",
      "\u001b[Aining Batches:  49%|████▉     | 60/122 [00:12<00:11,  5.18it/s, train_loss=0.0378]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.33it/s, train_loss=0.0378]\n",
      "\u001b[Aining Batches:  50%|█████     | 61/122 [00:12<00:11,  5.33it/s, train_loss=0.00653]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.11it/s, train_loss=0.00653]\n",
      "\u001b[Aining Batches:  51%|█████     | 62/122 [00:12<00:11,  5.11it/s, train_loss=0.0339] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.16it/s, train_loss=0.0339]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 63/122 [00:12<00:11,  5.16it/s, train_loss=0.195] \n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.29it/s, train_loss=0.195]\n",
      "\u001b[Aining Batches:  52%|█████▏    | 64/122 [00:12<00:10,  5.29it/s, train_loss=0.0041]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:12<00:11,  5.14it/s, train_loss=0.0041]\n",
      "\u001b[Aining Batches:  53%|█████▎    | 65/122 [00:13<00:11,  5.14it/s, train_loss=0.219] \n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.01it/s, train_loss=0.219]\n",
      "\u001b[Aining Batches:  54%|█████▍    | 66/122 [00:13<00:11,  5.01it/s, train_loss=0.0284]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.86it/s, train_loss=0.0284]\n",
      "\u001b[Aining Batches:  55%|█████▍    | 67/122 [00:13<00:11,  4.86it/s, train_loss=0.503] \n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.74it/s, train_loss=0.503]\n",
      "\u001b[Aining Batches:  56%|█████▌    | 68/122 [00:13<00:11,  4.74it/s, train_loss=0.0258]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.95it/s, train_loss=0.0258]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 69/122 [00:13<00:10,  4.95it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:13<00:10,  5.14it/s, train_loss=0.0218]\n",
      "\u001b[Aining Batches:  57%|█████▋    | 70/122 [00:14<00:10,  5.14it/s, train_loss=0.149] \n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.17it/s, train_loss=0.149]\n",
      "\u001b[Aining Batches:  58%|█████▊    | 71/122 [00:14<00:09,  5.17it/s, train_loss=0.00356]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.93it/s, train_loss=0.00356]\n",
      "\u001b[Aining Batches:  59%|█████▉    | 72/122 [00:14<00:10,  4.93it/s, train_loss=0.0795] \n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.08it/s, train_loss=0.0795]\n",
      "\u001b[Aining Batches:  60%|█████▉    | 73/122 [00:14<00:09,  5.08it/s, train_loss=0.0841]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.88it/s, train_loss=0.0841]\n",
      "\u001b[Aining Batches:  61%|██████    | 74/122 [00:14<00:09,  4.88it/s, train_loss=0.00875]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:14<00:09,  4.97it/s, train_loss=0.00875]\n",
      "\u001b[Aining Batches:  61%|██████▏   | 75/122 [00:15<00:09,  4.97it/s, train_loss=0.00768]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.91it/s, train_loss=0.00768]\n",
      "\u001b[Aining Batches:  62%|██████▏   | 76/122 [00:15<00:09,  4.91it/s, train_loss=0.0119] \n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.08it/s, train_loss=0.0119]\n",
      "\u001b[Aining Batches:  63%|██████▎   | 77/122 [00:15<00:08,  5.08it/s, train_loss=0.348] \n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.34it/s, train_loss=0.348]\n",
      "\u001b[Aining Batches:  64%|██████▍   | 78/122 [00:15<00:08,  5.34it/s, train_loss=0.00706]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:07,  5.55it/s, train_loss=0.00706]\n",
      "\u001b[Aining Batches:  65%|██████▍   | 79/122 [00:15<00:07,  5.55it/s, train_loss=0.0219] \n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.23it/s, train_loss=0.0219]\n",
      "\u001b[Aining Batches:  66%|██████▌   | 80/122 [00:15<00:08,  5.23it/s, train_loss=0.00755]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:15<00:07,  5.30it/s, train_loss=0.00755]\n",
      "\u001b[Aining Batches:  66%|██████▋   | 81/122 [00:16<00:07,  5.30it/s, train_loss=0.19]   \n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.36it/s, train_loss=0.19]\n",
      "\u001b[Aining Batches:  67%|██████▋   | 82/122 [00:16<00:07,  5.36it/s, train_loss=0.0546]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.40it/s, train_loss=0.0546]\n",
      "\u001b[Aining Batches:  68%|██████▊   | 83/122 [00:16<00:07,  5.40it/s, train_loss=0.506] \n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.95it/s, train_loss=0.506]\n",
      "\u001b[Aining Batches:  69%|██████▉   | 84/122 [00:16<00:07,  4.95it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.75it/s, train_loss=0.0308]\n",
      "\u001b[Aining Batches:  70%|██████▉   | 85/122 [00:16<00:07,  4.75it/s, train_loss=0.00647]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:16<00:07,  4.79it/s, train_loss=0.00647]\n",
      "\u001b[Aining Batches:  70%|███████   | 86/122 [00:17<00:07,  4.79it/s, train_loss=0.00455]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.90it/s, train_loss=0.00455]\n",
      "\u001b[Aining Batches:  71%|███████▏  | 87/122 [00:17<00:07,  4.90it/s, train_loss=0.0107] \n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.92it/s, train_loss=0.0107]\n",
      "\u001b[Aining Batches:  72%|███████▏  | 88/122 [00:17<00:06,  4.92it/s, train_loss=0.00597]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.96it/s, train_loss=0.00597]\n",
      "\u001b[Aining Batches:  73%|███████▎  | 89/122 [00:17<00:06,  4.96it/s, train_loss=0.193]  \n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:17<00:06,  4.80it/s, train_loss=0.193]\n",
      "\u001b[Aining Batches:  74%|███████▍  | 90/122 [00:18<00:06,  4.80it/s, train_loss=0.00686]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.90it/s, train_loss=0.00686]\n",
      "\u001b[Aining Batches:  75%|███████▍  | 91/122 [00:18<00:06,  4.90it/s, train_loss=0.0286] \n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.74it/s, train_loss=0.0286]\n",
      "\u001b[Aining Batches:  75%|███████▌  | 92/122 [00:18<00:06,  4.74it/s, train_loss=0.0555]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.89it/s, train_loss=0.0555]\n",
      "\u001b[Aining Batches:  76%|███████▌  | 93/122 [00:18<00:05,  4.89it/s, train_loss=0.00411]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.12it/s, train_loss=0.00411]\n",
      "\u001b[Aining Batches:  77%|███████▋  | 94/122 [00:18<00:05,  5.12it/s, train_loss=0.00698]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:18<00:05,  5.08it/s, train_loss=0.00698]\n",
      "\u001b[Aining Batches:  78%|███████▊  | 95/122 [00:19<00:05,  5.08it/s, train_loss=0.0859] \n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.95it/s, train_loss=0.0859]\n",
      "\u001b[Aining Batches:  79%|███████▊  | 96/122 [00:19<00:05,  4.95it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.10it/s, train_loss=0.0236]\n",
      "\u001b[Aining Batches:  80%|███████▉  | 97/122 [00:19<00:04,  5.10it/s, train_loss=0.0196]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.17it/s, train_loss=0.0196]\n",
      "\u001b[Aining Batches:  80%|████████  | 98/122 [00:19<00:04,  5.17it/s, train_loss=0.273] \n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.13it/s, train_loss=0.273]\n",
      "\u001b[Aining Batches:  81%|████████  | 99/122 [00:19<00:04,  5.13it/s, train_loss=0.0686]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.07it/s, train_loss=0.0686]\n",
      "\u001b[Aining Batches:  82%|████████▏ | 100/122 [00:19<00:04,  5.07it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:19<00:04,  5.07it/s, train_loss=0.0925]\n",
      "\u001b[Aining Batches:  83%|████████▎ | 101/122 [00:20<00:04,  5.07it/s, train_loss=0.00546]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.02it/s, train_loss=0.00546]\n",
      "\u001b[Aining Batches:  84%|████████▎ | 102/122 [00:20<00:03,  5.02it/s, train_loss=0.0183] \n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.98it/s, train_loss=0.0183]\n",
      "\u001b[Aining Batches:  84%|████████▍ | 103/122 [00:20<00:03,  4.98it/s, train_loss=0.0954]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.06it/s, train_loss=0.0954]\n",
      "\u001b[Aining Batches:  85%|████████▌ | 104/122 [00:20<00:03,  5.06it/s, train_loss=0.117] \n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.00it/s, train_loss=0.117]\n",
      "\u001b[Aining Batches:  86%|████████▌ | 105/122 [00:20<00:03,  5.00it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:20<00:03,  5.02it/s, train_loss=0.145]\n",
      "\u001b[Aining Batches:  87%|████████▋ | 106/122 [00:21<00:03,  5.02it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.84it/s, train_loss=0.019]\n",
      "\u001b[Aining Batches:  88%|████████▊ | 107/122 [00:21<00:03,  4.84it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.01it/s, train_loss=0.0612]\n",
      "\u001b[Aining Batches:  89%|████████▊ | 108/122 [00:21<00:02,  5.01it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.01it/s, train_loss=0.0131]\n",
      "\u001b[Aining Batches:  89%|████████▉ | 109/122 [00:21<00:02,  5.01it/s, train_loss=0.0562]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.08it/s, train_loss=0.0562]\n",
      "\u001b[Aining Batches:  90%|█████████ | 110/122 [00:21<00:02,  5.08it/s, train_loss=0.0243]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:21<00:02,  4.92it/s, train_loss=0.0243]\n",
      "\u001b[Aining Batches:  91%|█████████ | 111/122 [00:22<00:02,  4.92it/s, train_loss=0.349] \n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.95it/s, train_loss=0.349]\n",
      "\u001b[Aining Batches:  92%|█████████▏| 112/122 [00:22<00:02,  4.95it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.06it/s, train_loss=0.0115]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 113/122 [00:22<00:01,  5.06it/s, train_loss=0.00299]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.96it/s, train_loss=0.00299]\n",
      "\u001b[Aining Batches:  93%|█████████▎| 114/122 [00:22<00:01,  4.96it/s, train_loss=0.183]  \n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.12it/s, train_loss=0.183]\n",
      "\u001b[Aining Batches:  94%|█████████▍| 115/122 [00:22<00:01,  5.12it/s, train_loss=0.0058]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:22<00:01,  4.99it/s, train_loss=0.0058]\n",
      "\u001b[Aining Batches:  95%|█████████▌| 116/122 [00:23<00:01,  4.99it/s, train_loss=0.0975]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.96it/s, train_loss=0.0975]\n",
      "\u001b[Aining Batches:  96%|█████████▌| 117/122 [00:23<00:01,  4.96it/s, train_loss=0.0253]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.07it/s, train_loss=0.0253]\n",
      "\u001b[Aining Batches:  97%|█████████▋| 118/122 [00:23<00:00,  5.07it/s, train_loss=0.048] \n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.00it/s, train_loss=0.048]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 119/122 [00:23<00:00,  5.00it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.05it/s, train_loss=0.164]\n",
      "\u001b[Aining Batches:  98%|█████████▊| 120/122 [00:23<00:00,  5.05it/s, train_loss=0.0916]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:23<00:00,  5.12it/s, train_loss=0.0916]\n",
      "\u001b[Aining Batches:  99%|█████████▉| 121/122 [00:24<00:00,  5.12it/s, train_loss=0.037] \n",
      "\u001b[A                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110 average loss: 0.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 110/110 [45:36<00:00, 24.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "current epoch: 110 current AUC: 0.9943 current accuracy: 0.8944 best AUC: 0.9991 at epoch: 94\n",
      "train completed, best_metric: 0.9991 at epoch: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "writer = SummaryWriter()\n",
    "\n",
    "start_time = time.time()\n",
    "process = psutil.Process()\n",
    "start_cpu = process.cpu_times()\n",
    "start_mem = process.memory_info().rss / 1024**2  # В MB\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "for epoch in tqdm(range(max_epochs), desc=\"Epochs\"):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    batch_iter = tqdm(train_loader, desc=\"Training Batches\", leave=False)\n",
    "    \n",
    "    for batch_data in batch_iter:\n",
    "        step += 1\n",
    "        images, labels = batch_data['images'].to(device), batch_data['label'][:, 0].type(torch.LongTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_dataset) // train_loader.batch_size\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "        batch_iter.set_postfix(train_loss=loss.item())\n",
    "        \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "            y = torch.tensor([], dtype=torch.long, device=device)\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = (\n",
    "                    val_data['images'].to(device),\n",
    "                    val_data['label'][:, 0].type(torch.LongTensor).to(device),\n",
    "                )\n",
    "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
    "                y = torch.cat([y, val_labels], dim=0)\n",
    "            y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
    "            print('1')\n",
    "            y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
    "            auc_metric(y_pred_act, y_onehot)\n",
    "            result = auc_metric.aggregate()\n",
    "            auc_metric.reset()\n",
    "            del y_pred_act, y_onehot\n",
    "            metric_values.append(result)\n",
    "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
    "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
    "            if result > best_metric:\n",
    "                best_metric = result\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model_3d_pretrained.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current AUC: {result:.4f}\"\n",
    "                f\" current accuracy: {acc_metric:.4f}\"\n",
    "                f\" best AUC: {best_metric:.4f}\"\n",
    "                f\" at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "            writer.add_scalar(\"val_accuracy\", acc_metric, epoch + 1)\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 2736.26 seconds\n",
      "CPU time used: 32589.39 seconds\n",
      "Memory used: 3994.71 MB\n",
      "GPU Memory Used: 530.81 MB\n",
      "Max GPU Memory Used: 3608.29 MB\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "end_cpu = process.cpu_times()\n",
    "end_mem = process.memory_info().rss / 1024**2\n",
    "\n",
    "cpu_time = (end_cpu.user + end_cpu.system) - (start_cpu.user + start_cpu.system)\n",
    "memory_used = end_mem - start_mem\n",
    "\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"CPU time used: {cpu_time:.2f} seconds\")\n",
    "print(f\"Memory used: {memory_used:.2f} MB\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    print(f\"GPU Memory Used: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"Max GPU Memory Used: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val AUC\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRAM currently used: 530.81 MB\n",
      "Max VRAM used during training: 3608.29 MB\n"
     ]
    }
   ],
   "source": [
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    vram_used = torch.cuda.memory_allocated() / 1024**2\n",
    "    vram_max_used = torch.cuda.max_memory_allocated() / 1024**2\n",
    "\n",
    "    print(f\"VRAM currently used: {vram_used:.2f} MB\")\n",
    "    print(f\"Max VRAM used during training: {vram_max_used:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.9815\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model_3d_pretrained.pth\"), weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_predicted = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "    y = torch.tensor([], dtype=torch.long, device=device)\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data['images'],\n",
    "            test_data['label'][:, 0].type(torch.LongTensor),\n",
    "        )\n",
    "\n",
    "        output = model(test_images.to(device))\n",
    "        pred = output.argmax(dim=1)\n",
    "        \n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_predicted.append(pred[i].item())\n",
    "\n",
    "        y_pred = torch.cat([y_pred, output], dim=0)\n",
    "        y = torch.cat([y, test_labels.to(device)], dim=0)\n",
    "\n",
    "    # Evaluate AUC and accuracy\n",
    "    y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
    "    y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
    "    auc_metric(y_pred_act, y_onehot)\n",
    "    result = auc_metric.aggregate()\n",
    "    auc_metric.reset()\n",
    "\n",
    "    print(f\"Validation AUC: {result:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9857    1.0000    0.9928        69\n",
      "           1     0.6909    0.5588    0.6179        68\n",
      "           2     0.6579    0.7246    0.6897        69\n",
      "           3     0.5692    0.5692    0.5692        65\n",
      "           4     0.5797    0.6154    0.5970        65\n",
      "           5     0.9143    0.9697    0.9412        66\n",
      "           6     0.9630    0.9286    0.9455        28\n",
      "           7     1.0000    1.0000    1.0000        21\n",
      "           8     1.0000    1.0000    1.0000        21\n",
      "           9     0.9697    0.9275    0.9481        69\n",
      "          10     0.9571    0.9710    0.9640        69\n",
      "\n",
      "    accuracy                         0.8148       610\n",
      "   macro avg     0.8443    0.8423    0.8423       610\n",
      "weighted avg     0.8153    0.8148    0.8138       610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_predicted, target_names=info['label'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRAM currently used: 531.43 MB\n",
      "Max VRAM used during training: 3608.29 MB\n"
     ]
    }
   ],
   "source": [
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    vram_used = torch.cuda.memory_allocated() / 1024**2\n",
    "    vram_max_used = torch.cuda.max_memory_allocated() / 1024**2\n",
    "\n",
    "    print(f\"VRAM currently used: {vram_used:.2f} MB\")\n",
    "    print(f\"Max VRAM used during training: {vram_max_used:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
