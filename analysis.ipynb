{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e11ee1-790d-47c3-841e-5fc237a45b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23bf741b-622a-4b47-ac2b-0cba71bf9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metrics(file_path, has_auc=False):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if has_auc:\n",
    "        metrics = {\n",
    "        'accuracy': df.loc[df.index[-4], 'precision'],\n",
    "        'precision': df.loc[df.index[-3], 'precision'],\n",
    "        'recall': df.loc[df.index[-3], 'recall'],\n",
    "        'f1_macro': df.loc[df.index[-3], 'f1-score'],\n",
    "        'auc': df.loc[df.index[-1], 'precision']\n",
    "    }\n",
    "    else:\n",
    "        metrics = {\n",
    "        'accuracy': df.loc[df.index[-3], 'precision'],\n",
    "        'precision': df.loc[df.index[-2], 'precision'],\n",
    "        'recall': df.loc[df.index[-2], 'recall'],\n",
    "        'f1_macro': df.loc[df.index[-2], 'f1-score']\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd1a8e19-8ce4-4bce-bfcb-62f39cb553a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['axial_random_pretrained', 'coronal_random_pretrained', \n",
    "               'sagittal_random_pretrained', 'combined_pretrained_random',\n",
    "               'weighted_pretrained_random', 'balanced_pretrained_random']\n",
    "csv_files = {\n",
    "    model: glob.glob(f\"reports/{model}*.csv\") for model in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "431a467a-dde2-4512-a317-9a09d8f2966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for model, files in csv_files.items():\n",
    "    model_metrics = []\n",
    "    for file in files:\n",
    "        metrics = extract_metrics(file, has_auc=(model in ['combined_pretrained_random', \n",
    "                                                           'weighted_pretrained_random',\n",
    "                                                           'balanced_pretrained_random']))\n",
    "        model_metrics.append(metrics)\n",
    "    results[model] = pd.DataFrame(model_metrics)\n",
    "\n",
    "summary = {}\n",
    "for model, metrics_df in results.items():\n",
    "    summary[model] = {\n",
    "        'mean': metrics_df.mean(),\n",
    "        'std': metrics_df.std()\n",
    "    }\n",
    "\n",
    "comparison = {}\n",
    "for metric in ['accuracy', 'recall', 'precision', 'f1_macro']:\n",
    "    comparison[metric] = {\n",
    "        'before_combined': [summary[model]['mean'][metric] for model in model_names[:-3]],\n",
    "        'combined': summary['combined_pretrained_random']['mean'][metric],\n",
    "        'weighted': summary['weighted_pretrained_random']['mean'][metric],\n",
    "        'balanced': summary['balanced_pretrained_random']['mean'][metric]\n",
    "    }\n",
    "    \n",
    "\n",
    "if 'auc' in summary['combined_pretrained_random']['mean']:\n",
    "    comparison['auc'] = {\n",
    "        'before_combined': None,\n",
    "        'combined': summary['combined_pretrained_random']['mean']['auc'],\n",
    "        'weighted': summary['weighted_pretrained_random']['mean']['auc'],\n",
    "        'balanced': summary['balanced_pretrained_random']['mean']['auc']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7164808f-db41-4d06-ac27-413628dd4a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: axial_random_pretrained\n",
      "Mean:\n",
      "accuracy     0.831148\n",
      "precision    0.854023\n",
      "recall       0.850242\n",
      "f1_macro     0.848143\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.014965\n",
      "precision    0.009397\n",
      "recall       0.009318\n",
      "f1_macro     0.009477\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: coronal_random_pretrained\n",
      "Mean:\n",
      "accuracy     0.888934\n",
      "precision    0.901600\n",
      "recall       0.897297\n",
      "f1_macro     0.897999\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.008399\n",
      "precision    0.010795\n",
      "recall       0.010027\n",
      "f1_macro     0.010279\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: sagittal_random_pretrained\n",
      "Mean:\n",
      "accuracy     0.761066\n",
      "precision    0.783351\n",
      "recall       0.765608\n",
      "f1_macro     0.769336\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.017369\n",
      "precision    0.017706\n",
      "recall       0.020716\n",
      "f1_macro     0.018475\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: combined_pretrained_random\n",
      "Mean:\n",
      "accuracy     0.838525\n",
      "precision    0.861601\n",
      "recall       0.856445\n",
      "f1_macro     0.856498\n",
      "auc          0.987775\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.017631\n",
      "precision    0.015056\n",
      "recall       0.016359\n",
      "f1_macro     0.015652\n",
      "auc          0.001097\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: weighted_pretrained_random\n",
      "Mean:\n",
      "accuracy     0.839754\n",
      "precision    0.863930\n",
      "recall       0.854693\n",
      "f1_macro     0.856928\n",
      "auc          0.987300\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.006042\n",
      "precision    0.006838\n",
      "recall       0.008757\n",
      "f1_macro     0.006970\n",
      "auc          0.000804\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: balanced_pretrained_random\n",
      "Mean:\n",
      "accuracy     0.795902\n",
      "precision    0.836142\n",
      "recall       0.817724\n",
      "f1_macro     0.818363\n",
      "auc          0.980725\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.007392\n",
      "precision    0.007429\n",
      "recall       0.005157\n",
      "f1_macro     0.009390\n",
      "auc          0.000988\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Comparison of metrics:\n",
      "Metric: accuracy\n",
      "Before combined: [0.8311475409836065, 0.8889344262295082, 0.7610655737704918]\n",
      "Combined: 0.8385245901639344\n",
      "Weighted: 0.8397540983606557\n",
      "Balanced: 0.7959016393442622\n",
      "========================================\n",
      "Metric: recall\n",
      "Before combined: [0.8502423756201948, 0.8972971692339281, 0.7656080085921984]\n",
      "Combined: 0.8564454881706685\n",
      "Weighted: 0.8546926567968186\n",
      "Balanced: 0.8177235623788751\n",
      "========================================\n",
      "Metric: precision\n",
      "Before combined: [0.8540234167016392, 0.9015996369893889, 0.7833512166518001]\n",
      "Combined: 0.8616010045486427\n",
      "Weighted: 0.8639299228784166\n",
      "Balanced: 0.8361420412376528\n",
      "========================================\n",
      "Metric: f1_macro\n",
      "Before combined: [0.8481434776334118, 0.8979991384689163, 0.7693357339812326]\n",
      "Combined: 0.8564983311577257\n",
      "Weighted: 0.8569284833105637\n",
      "Balanced: 0.8183634542462519\n",
      "========================================\n",
      "Metric: auc\n",
      "Before combined: None\n",
      "Combined: 0.9877750000000001\n",
      "Weighted: 0.9873000000000001\n",
      "Balanced: 0.9807250000000001\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for model, stats in summary.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Mean:\\n{stats['mean']}\")\n",
    "    print(f\"Std:\\n{stats['std']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"Comparison of metrics:\")\n",
    "for metric, values in comparison.items():\n",
    "    print(f\"Metric: {metric}\")\n",
    "    print(f\"Before combined: {values['before_combined']}\")\n",
    "    print(f\"Combined: {values['combined']}\")\n",
    "    print(f\"Weighted: {values['weighted']}\")\n",
    "    print(f\"Balanced: {values['balanced']}\")\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4121534-a549-41fc-8b64-ff2c64ce46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['axial_random_unpretrained', 'coronal_random_unpretrained', \n",
    "               'sagittal_random_unpretrained', 'combined_unpretrained_random',\n",
    "               'weighted_unpretrained_random', 'balanced_unpretrained_random']\n",
    "csv_files = {\n",
    "    model: glob.glob(f\"reports/{model}*.csv\")\n",
    "    for model in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8362e97c-a5a7-44f6-be9c-b61f36d7ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for model, files in csv_files.items():\n",
    "    model_metrics = []\n",
    "    for file in files:\n",
    "        metrics = extract_metrics(file, has_auc=(model in ['combined_unpretrained_random', \n",
    "                                                           'weighted_unpretrained_random',\n",
    "                                                           'balanced_unpretrained_random']))\n",
    "        model_metrics.append(metrics)\n",
    "    results[model] = pd.DataFrame(model_metrics)\n",
    "\n",
    "summary = {}\n",
    "for model, metrics_df in results.items():\n",
    "    summary[model] = {\n",
    "        'mean': metrics_df.mean(),\n",
    "        'std': metrics_df.std()\n",
    "    }\n",
    "\n",
    "comparison = {}\n",
    "for metric in ['accuracy', 'recall', 'precision', 'f1_macro']:\n",
    "    comparison[metric] = {\n",
    "        'before_combined': [summary[model]['mean'][metric] for model in model_names[:-3]],\n",
    "        'combined': summary['combined_unpretrained_random']['mean'][metric],\n",
    "        'weighted': summary['weighted_unpretrained_random']['mean'][metric],\n",
    "        'balanced': summary['balanced_unpretrained_random']['mean'][metric]\n",
    "    }\n",
    "\n",
    "if 'auc' in summary['combined_unpretrained_random']['mean']:\n",
    "    comparison['auc'] = {\n",
    "        'before_combined': None,\n",
    "        'combined': summary['combined_unpretrained_random']['mean']['auc'],\n",
    "        'weighted': summary['weighted_unpretrained_random']['mean']['auc'],\n",
    "        'balanced': summary['weighted_unpretrained_random']['mean']['auc']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f504866a-951f-4120-9576-213f5b607de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: axial_random_unpretrained\n",
      "Mean:\n",
      "accuracy     0.829098\n",
      "precision    0.855832\n",
      "recall       0.848292\n",
      "f1_macro     0.846654\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.007733\n",
      "precision    0.010961\n",
      "recall       0.009560\n",
      "f1_macro     0.012129\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: coronal_random_unpretrained\n",
      "Mean:\n",
      "accuracy     0.246721\n",
      "precision    0.267198\n",
      "recall       0.241287\n",
      "f1_macro     0.225915\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.007146\n",
      "precision    0.047879\n",
      "recall       0.017088\n",
      "f1_macro     0.025552\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: sagittal_random_unpretrained\n",
      "Mean:\n",
      "accuracy     0.252049\n",
      "precision    0.285371\n",
      "recall       0.224872\n",
      "f1_macro     0.216803\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.034319\n",
      "precision    0.080010\n",
      "recall       0.033514\n",
      "f1_macro     0.036888\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: combined_unpretrained_random\n",
      "Mean:\n",
      "accuracy     0.924180\n",
      "precision    0.936605\n",
      "recall       0.934197\n",
      "f1_macro     0.934447\n",
      "auc          0.996925\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.010486\n",
      "precision    0.007716\n",
      "recall       0.010338\n",
      "f1_macro     0.009663\n",
      "auc          0.000680\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: weighted_unpretrained_random\n",
      "Mean:\n",
      "accuracy     0.923770\n",
      "precision    0.936535\n",
      "recall       0.932960\n",
      "f1_macro     0.933876\n",
      "auc          0.996875\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.008087\n",
      "precision    0.006456\n",
      "recall       0.008543\n",
      "f1_macro     0.007320\n",
      "auc          0.000395\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: balanced_unpretrained_random\n",
      "Mean:\n",
      "accuracy     0.918033\n",
      "precision    0.931207\n",
      "recall       0.930212\n",
      "f1_macro     0.930024\n",
      "auc          0.995700\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.004637\n",
      "precision    0.004997\n",
      "recall       0.004506\n",
      "f1_macro     0.004700\n",
      "auc          0.000821\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Comparison of metrics:\n",
      "Metric: accuracy\n",
      "Before combined: [0.8290983606557377, 0.24672131147540982, 0.2520491803278688]\n",
      "Combined: 0.9241803278688525\n",
      "Weighted: 0.9237704918032786\n",
      "Balanced: 0.918032786885246\n",
      "========================================\n",
      "Metric: recall\n",
      "Before combined: [0.8482918161045341, 0.24128742198667796, 0.2248721072773619]\n",
      "Combined: 0.9341971211768934\n",
      "Weighted: 0.9329595305879892\n",
      "Balanced: 0.930211647803487\n",
      "========================================\n",
      "Metric: precision\n",
      "Before combined: [0.85583201221502, 0.2671978481688286, 0.28537058279376293]\n",
      "Combined: 0.9366046611584831\n",
      "Weighted: 0.9365348716544405\n",
      "Balanced: 0.931206840747038\n",
      "========================================\n",
      "Metric: f1_macro\n",
      "Before combined: [0.8466536139951888, 0.22591515849863475, 0.21680279255528]\n",
      "Combined: 0.9344469813170645\n",
      "Weighted: 0.9338755591922137\n",
      "Balanced: 0.9300242024985398\n",
      "========================================\n",
      "Metric: auc\n",
      "Before combined: None\n",
      "Combined: 0.9969250000000001\n",
      "Weighted: 0.9968750000000001\n",
      "Balanced: 0.9968750000000001\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for model, stats in summary.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Mean:\\n{stats['mean']}\")\n",
    "    print(f\"Std:\\n{stats['std']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"Comparison of metrics:\")\n",
    "for metric, values in comparison.items():\n",
    "    print(f\"Metric: {metric}\")\n",
    "    print(f\"Before combined: {values['before_combined']}\")\n",
    "    print(f\"Combined: {values['combined']}\")\n",
    "    print(f\"Weighted: {values['weighted']}\")\n",
    "    print(f\"Balanced: {values['balanced']}\")\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4a4d7-ab77-455d-80d3-f16df7cbbf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9adb059-0c2b-4134-8efd-87335f3102eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['axial_full_pretrained', 'coronal_full_pretrained', \n",
    "               'sagittal_full_pretrained', 'combined_pretrained_full',\n",
    "               'weighted_pretrained_full', 'balanced_pretrained_full']\n",
    "csv_files = {\n",
    "    model: glob.glob(f\"reports/{model}*.csv\") for model in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b8b278a-a492-4e89-93bf-956f1549f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for model, files in csv_files.items():\n",
    "    model_metrics = []\n",
    "    for file in files:\n",
    "        metrics = extract_metrics(file, has_auc=(model in ['combined_pretrained_full', \n",
    "                                                           'weighted_pretrained_full',\n",
    "                                                           'balanced_pretrained_full']))\n",
    "        model_metrics.append(metrics)\n",
    "    results[model] = pd.DataFrame(model_metrics)\n",
    "\n",
    "summary = {}\n",
    "for model, metrics_df in results.items():\n",
    "    summary[model] = {\n",
    "        'mean': metrics_df.mean(),\n",
    "        'std': metrics_df.std()\n",
    "    }\n",
    "\n",
    "comparison = {}\n",
    "for metric in ['accuracy', 'recall', 'precision', 'f1_macro']:\n",
    "    comparison[metric] = {\n",
    "        'before_combined': [summary[model]['mean'][metric] for model in model_names[:-3]],\n",
    "        'combined': summary['combined_pretrained_full']['mean'][metric],\n",
    "        'weighted': summary['weighted_pretrained_full']['mean'][metric],\n",
    "        'balanced': summary['balanced_pretrained_full']['mean'][metric]\n",
    "    }\n",
    "    \n",
    "\n",
    "if 'auc' in summary['combined_pretrained_full']['mean']:\n",
    "    comparison['auc'] = {\n",
    "        'before_combined': None,\n",
    "        'combined': summary['combined_pretrained_full']['mean']['auc'],\n",
    "        'weighted': summary['weighted_pretrained_full']['mean']['auc'],\n",
    "        'balanced': summary['balanced_pretrained_full']['mean']['auc']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18af7eda-412b-448c-823f-5e9c5d3eb00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'axial_full_pretrained':    accuracy  precision    recall  f1_macro\n",
       " 0  0.891803   0.910704  0.907551  0.906310\n",
       " 1  0.878689   0.901231  0.896321  0.893980\n",
       " 2  0.877049   0.897379  0.896975  0.894865\n",
       " 3  0.890164   0.906265  0.901306  0.902863\n",
       " 4  0.875410   0.896903  0.894510  0.893456,\n",
       " 'coronal_full_pretrained':    accuracy  precision    recall  f1_macro\n",
       " 0  0.757377   0.793671  0.786049  0.786363\n",
       " 1  0.791803   0.819429  0.827271  0.821356\n",
       " 2  0.768852   0.804935  0.792724  0.790103\n",
       " 3  0.786885   0.810174  0.816484  0.811031\n",
       " 4  0.806557   0.835693  0.830452  0.831860,\n",
       " 'sagittal_full_pretrained':    accuracy  precision    recall  f1_macro\n",
       " 0  0.791803   0.821128  0.813919  0.812940\n",
       " 1  0.747541   0.770569  0.776469  0.772070\n",
       " 2  0.768852   0.815040  0.797742  0.794803\n",
       " 3  0.786885   0.808863  0.801353  0.803516\n",
       " 4  0.800000   0.837958  0.829380  0.831105,\n",
       " 'combined_pretrained_full':    accuracy  precision    recall  f1_macro     auc\n",
       " 0  0.829508   0.857946  0.854466  0.852572  0.9858\n",
       " 1  0.814754   0.841503  0.836217  0.835102  0.9840\n",
       " 2  0.822951   0.860245  0.841982  0.844863  0.9866\n",
       " 3  0.847541   0.868584  0.874484  0.868515  0.9872\n",
       " 4  0.831148   0.863442  0.856117  0.854457  0.9848,\n",
       " 'weighted_pretrained_full':    accuracy  precision    recall  f1_macro     auc\n",
       " 0  0.839344   0.872744  0.855256  0.858540  0.9864\n",
       " 1  0.821311   0.854929  0.842530  0.843206  0.9843\n",
       " 2  0.821311   0.858688  0.843273  0.845691  0.9846\n",
       " 3  0.819672   0.841098  0.849265  0.841799  0.9856\n",
       " 4  0.826230   0.863190  0.843996  0.847523  0.9858,\n",
       " 'balanced_pretrained_full':    accuracy  precision    recall  f1_macro     auc\n",
       " 0  0.800000   0.830714  0.828057  0.822988  0.9719\n",
       " 1  0.795082   0.820803  0.823358  0.816896  0.9761\n",
       " 2  0.777049   0.817404  0.778574  0.789988  0.9790\n",
       " 3  0.773770   0.814340  0.806451  0.807785  0.9724}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08e7d714-a16a-48b4-beff-52ac0e80b6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: axial_full_pretrained\n",
      "Mean:\n",
      "accuracy     0.882623\n",
      "precision    0.902496\n",
      "recall       0.899332\n",
      "f1_macro     0.898295\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.007741\n",
      "precision    0.005930\n",
      "recall       0.005228\n",
      "f1_macro     0.005893\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: coronal_full_pretrained\n",
      "Mean:\n",
      "accuracy     0.782295\n",
      "precision    0.812780\n",
      "recall       0.810596\n",
      "f1_macro     0.808143\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.019376\n",
      "precision    0.015833\n",
      "recall       0.020180\n",
      "f1_macro     0.019655\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: sagittal_full_pretrained\n",
      "Mean:\n",
      "accuracy     0.779016\n",
      "precision    0.810712\n",
      "recall       0.803772\n",
      "f1_macro     0.802887\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.020975\n",
      "precision    0.024922\n",
      "recall       0.019662\n",
      "f1_macro     0.021867\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: combined_pretrained_full\n",
      "Mean:\n",
      "accuracy     0.829180\n",
      "precision    0.858344\n",
      "recall       0.852653\n",
      "f1_macro     0.851102\n",
      "auc          0.985680\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.012124\n",
      "precision    0.010225\n",
      "recall       0.014798\n",
      "f1_macro     0.012365\n",
      "auc          0.001301\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: weighted_pretrained_full\n",
      "Mean:\n",
      "accuracy     0.825574\n",
      "precision    0.858130\n",
      "recall       0.846864\n",
      "f1_macro     0.847352\n",
      "auc          0.985340\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.008081\n",
      "precision    0.011617\n",
      "recall       0.005387\n",
      "f1_macro     0.006633\n",
      "auc          0.000871\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: balanced_pretrained_full\n",
      "Mean:\n",
      "accuracy     0.786475\n",
      "precision    0.820815\n",
      "recall       0.809110\n",
      "f1_macro     0.809415\n",
      "auc          0.974850\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.013003\n",
      "precision    0.007107\n",
      "recall       0.022372\n",
      "f1_macro     0.014379\n",
      "auc          0.003341\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Comparison of metrics:\n",
      "Metric: accuracy\n",
      "Before combined: [0.8826229508196721, 0.7822950819672132, 0.7790163934426229]\n",
      "Combined: 0.8291803278688524\n",
      "Weighted: 0.8255737704918034\n",
      "Balanced: 0.7864754098360657\n",
      "========================================\n",
      "Metric: recall\n",
      "Before combined: [0.8993324020782753, 0.8105960303356259, 0.803772439294411]\n",
      "Combined: 0.8526529984004991\n",
      "Weighted: 0.8468638298073314\n",
      "Balanced: 0.8091100531259796\n",
      "========================================\n",
      "Metric: precision\n",
      "Before combined: [0.902496421940975, 0.8127803876698987, 0.8107115635490064]\n",
      "Combined: 0.8583438485202913\n",
      "Weighted: 0.8581295677831772\n",
      "Balanced: 0.8208153210021701\n",
      "========================================\n",
      "Metric: f1_macro\n",
      "Before combined: [0.8982947205429765, 0.8081426011647931, 0.8028868466754335]\n",
      "Combined: 0.8511017970000407\n",
      "Weighted: 0.8473517755844547\n",
      "Balanced: 0.8094146148996576\n",
      "========================================\n",
      "Metric: auc\n",
      "Before combined: None\n",
      "Combined: 0.98568\n",
      "Weighted: 0.9853400000000001\n",
      "Balanced: 0.97485\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for model, stats in summary.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Mean:\\n{stats['mean']}\")\n",
    "    print(f\"Std:\\n{stats['std']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"Comparison of metrics:\")\n",
    "for metric, values in comparison.items():\n",
    "    print(f\"Metric: {metric}\")\n",
    "    print(f\"Before combined: {values['before_combined']}\")\n",
    "    print(f\"Combined: {values['combined']}\")\n",
    "    print(f\"Weighted: {values['weighted']}\")\n",
    "    print(f\"Balanced: {values['balanced']}\")\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c5cbe8a-ef5b-4a4d-a95b-d31d4dc6d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['axial_full_unpretrained', 'coronal_full_unpretrained', \n",
    "               'sagittal_full_unpretrained', 'combined_unpretrained_full',\n",
    "               'weighted_unpretrained_full', 'balanced_unpretrained_full']\n",
    "csv_files = {\n",
    "    model: glob.glob(f\"reports/{model}*.csv\")\n",
    "    for model in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41629d0b-9eaf-42b5-ba08-f74811ca48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for model, files in csv_files.items():\n",
    "    model_metrics = []\n",
    "    for file in files:\n",
    "        metrics = extract_metrics(file, has_auc=(model in ['combined_unpretrained_full', \n",
    "                                                           'weighted_unpretrained_full',\n",
    "                                                           'balanced_unpretrained_full']))\n",
    "        model_metrics.append(metrics)\n",
    "    results[model] = pd.DataFrame(model_metrics)\n",
    "\n",
    "summary = {}\n",
    "for model, metrics_df in results.items():\n",
    "    summary[model] = {\n",
    "        'mean': metrics_df.mean(),\n",
    "        'std': metrics_df.std()\n",
    "    }\n",
    "\n",
    "comparison = {}\n",
    "for metric in ['accuracy', 'recall', 'precision', 'f1_macro']:\n",
    "    comparison[metric] = {\n",
    "        'before_combined': [summary[model]['mean'][metric] for model in model_names[:-3]],\n",
    "        'combined': summary['combined_unpretrained_full']['mean'][metric],\n",
    "        'weighted': summary['weighted_unpretrained_full']['mean'][metric],\n",
    "        'balanced': summary['balanced_unpretrained_full']['mean'][metric]\n",
    "    }\n",
    "\n",
    "if 'auc' in summary['combined_unpretrained_full']['mean']:\n",
    "    comparison['auc'] = {\n",
    "        'before_combined': None,\n",
    "        'combined': summary['combined_unpretrained_full']['mean']['auc'],\n",
    "        'weighted': summary['weighted_unpretrained_full']['mean']['auc'],\n",
    "        'balanced': summary['weighted_unpretrained_full']['mean']['auc']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e433c88-9aa0-4de6-bf80-a4f81cdab85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: axial_full_unpretrained\n",
      "Mean:\n",
      "accuracy     0.848852\n",
      "precision    0.867896\n",
      "recall       0.871860\n",
      "f1_macro     0.865378\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.036956\n",
      "precision    0.038436\n",
      "recall       0.029807\n",
      "f1_macro     0.036927\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: coronal_full_unpretrained\n",
      "Mean:\n",
      "accuracy     0.251803\n",
      "precision    0.245402\n",
      "recall       0.234964\n",
      "f1_macro     0.210006\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.027738\n",
      "precision    0.051340\n",
      "recall       0.037789\n",
      "f1_macro     0.042270\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: sagittal_full_unpretrained\n",
      "Mean:\n",
      "accuracy     0.540328\n",
      "precision    0.552636\n",
      "recall       0.524105\n",
      "f1_macro     0.522612\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.043460\n",
      "precision    0.036677\n",
      "recall       0.058027\n",
      "f1_macro     0.056773\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: combined_unpretrained_full\n",
      "Mean:\n",
      "accuracy     0.868852\n",
      "precision    0.891408\n",
      "recall       0.885931\n",
      "f1_macro     0.886766\n",
      "auc          0.990420\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.027111\n",
      "precision    0.023351\n",
      "recall       0.023508\n",
      "f1_macro     0.024181\n",
      "auc          0.003056\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: weighted_unpretrained_full\n",
      "Mean:\n",
      "accuracy     0.869508\n",
      "precision    0.889730\n",
      "recall       0.883414\n",
      "f1_macro     0.884518\n",
      "auc          0.990320\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.018927\n",
      "precision    0.018460\n",
      "recall       0.015853\n",
      "f1_macro     0.016935\n",
      "auc          0.002351\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Model: balanced_unpretrained_full\n",
      "Mean:\n",
      "accuracy     0.890574\n",
      "precision    0.910135\n",
      "recall       0.906879\n",
      "f1_macro     0.907007\n",
      "auc          0.992750\n",
      "dtype: float64\n",
      "Std:\n",
      "accuracy     0.006188\n",
      "precision    0.004780\n",
      "recall       0.005778\n",
      "f1_macro     0.004821\n",
      "auc          0.000819\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Comparison of metrics:\n",
      "Metric: accuracy\n",
      "Before combined: [0.8488524590163934, 0.25180327868852453, 0.5403278688524591]\n",
      "Combined: 0.8688524590163933\n",
      "Weighted: 0.8695081967213113\n",
      "Balanced: 0.8905737704918033\n",
      "========================================\n",
      "Metric: recall\n",
      "Before combined: [0.87186037553859, 0.23496350197117458, 0.5241053637519576]\n",
      "Combined: 0.8859307444473685\n",
      "Weighted: 0.883414200307946\n",
      "Balanced: 0.906878665394127\n",
      "========================================\n",
      "Metric: precision\n",
      "Before combined: [0.8678962055630908, 0.24540231925114572, 0.5526363079196349]\n",
      "Combined: 0.8914082610420115\n",
      "Weighted: 0.8897298909144441\n",
      "Balanced: 0.9101354195399867\n",
      "========================================\n",
      "Metric: f1_macro\n",
      "Before combined: [0.8653781093680598, 0.21000615988973634, 0.5226117055275348]\n",
      "Combined: 0.8867660548061599\n",
      "Weighted: 0.8845179766714801\n",
      "Balanced: 0.9070065217262917\n",
      "========================================\n",
      "Metric: auc\n",
      "Before combined: None\n",
      "Combined: 0.99042\n",
      "Weighted: 0.99032\n",
      "Balanced: 0.99032\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for model, stats in summary.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Mean:\\n{stats['mean']}\")\n",
    "    print(f\"Std:\\n{stats['std']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"Comparison of metrics:\")\n",
    "for metric, values in comparison.items():\n",
    "    print(f\"Metric: {metric}\")\n",
    "    print(f\"Before combined: {values['before_combined']}\")\n",
    "    print(f\"Combined: {values['combined']}\")\n",
    "    print(f\"Weighted: {values['weighted']}\")\n",
    "    print(f\"Balanced: {values['balanced']}\")\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d43e86-df61-4d7b-b8b8-31906ec87a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c242a369-1736-42f5-8c50-20e74dc2fcf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
